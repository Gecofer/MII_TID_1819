---
title:
author:
- "Alejandro Campoy Nieves"
- "Gema Correa Fernández"
- "Luis Gallego Quero"
- "Jonathan Martín Valera"
- "Andrea Morales Garzón"
date: "14 de noviembre de 2018"
output:
  pdf_document:
    keep_tex: true
lang: es-ES
geometry: margin=1in
header-includes:
  - \usepackage{fancyhdr}
  - \fancyfoot[CO,CE]{My footer}
  - \usepackage{color}
  - \usepackage{colortbl}
  - \usepackage{multicol}
  - \usepackage{multirow}
---

<!-------------------------------------------------------------Portada------------------------------------------------------------->

\thispagestyle{empty}

\begin{center} \huge \textbf{Tratamiento Inteligente de datos} \end{center}
\vspace{0.3cm}
\begin{center} \huge \textbf{(TID)} \end{center}
\vspace{1.7cm}
\begin{center} \Large \textbf{\textsc{Prácticas de la asignatura}} \end{center}
\vspace{0.2cm}
\begin{center} \large \textbf{2018-2019} \end{center}

\vspace{2.5cm}

\textbf{\large En colaboración con:}
\vspace{0.2cm}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{imagenes/logoUGR.jpg}
    \label{imagen2}
\end{figure}

\vspace{2.5cm}

\hspace{8.5cm}{\large \textbf{Participantes}}

\vspace{0.25cm}

\hspace{8.5cm}{Alejandro Campoy Nieves:  \href{mailto:alejandroac79@correo.ugr.es}{\textcolor{blue}{\underline{alejandroac79@correo.ugr.es}}}}

\vspace{0.15cm}

\hspace{8.5cm}{Gema Correa Fernández:  \href{mailto:gecorrea@correo.ugr.es}{\textcolor{blue}{\underline{gecorrea@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Luis Gallego Quero:  \href{mailto:lgaq94@correo.ugr.es}{\textcolor{blue}{\underline{lgaq94@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Jonathan Martín Valera:  \href{mailto:jmv742@correo.ugr.es}{\textcolor{blue}{\underline{jmv742@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Andrea Morales Garzón:  \href{mailto:andreamgmg@correo.ugr.es}{\textcolor{blue}{\underline{andreamgmg@correo.ugr.es}}} }

\vspace{0.15cm}

\newpage

<!------------------------------------------------------------Indices--------------------------------------------------------------->

\thispagestyle{empty}
\tableofcontents
\newpage

\thispagestyle{empty}
\listoffigures
\newpage

\thispagestyle{empty}
\listoftables
\newpage

\pagestyle{fancy}
\fancyhf{}
\lhead{Proyecto: Técnicas aplicadas para análisis inteligente de datos}
\rhead{\thepage}
\setcounter{page}{1}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(3) # semilla para obtención de los mismos resultados
getwd()     # para saber el directorio de trabajo
```

```{r, include=FALSE}
source("librerias.R")
```

<!-----------------------------------------0. Paquetes necesarios ------------------------------------------------------>

# Descripción de los paquetes necesarios

A continuación, se describen los paquetes necesarios para el desarollo del proyecto:

- [`arules`](https://cran.r-project.org/web/packages/arules/arules.pdf) : Paquete que proporciona la infraestructura para representar, manipular y analizar datos y patrones de transacción (conjuntos de elementos frecuentes y reglas de asociación). Se puede instalar usando : _install.packages("arules")_.

- [`arulesViz`](https://cran.r-project.org/web/packages/arulesViz/arulesViz.pdf) : Paquete que extiende el paquete 'arules' con varias técnicas de visualización para reglas de asociación y conjuntos de elementos. El paquete también incluye varias visualizaciones interactivas para la exploración de reglas. Se puede instalar usando : _install.packages("arulesViz")_.

- [`car`](https://cran.r-project.org/web/packages/car/car.pdf) : Paquete que nos propociona distintas funciones. : _install.packages("car")_.

- [`cluster`](https://cran.r-project.org/web/packages/cluster/cluster.pdf) : Paquete que nos proporciona métodos para el análisis de clusters.  : _install.packages("cluster")_.

- [`caret`](https://cran.r-project.org/web/packages/caret/caret.pdf) : Paquete para entrenamiento de clasificación y regresión. Se puede instalar usando : _install.packages("quanteda")_.

- [`dbscan`](https://cran.r-project.org/web/packages/dbscan/dbscan.pdf) : Paquete que proporciona implementaciones de varios algoritmos basados en densidad de la familia DBSCAN para datos espaciales. Se puede instalar usando : _install.packages("dbscan")_.

- [`devtools`](https://cran.r-project.org/web/packages/devtools/devtools.pdf) : Paquete que contiene una colección de herramientas de desarrollo de paquetes, usando conjuntamento con `rword2vec`, para obtener la agrupación de sinónimos. Se puede instalar usando : _install.packages("devtools")_.

- [`dplyr`](https://cran.r-project.org/web/packages/dplyr/dplyr.pdf) : Paquete que agiliza el trabajo con los datos. Se puede instalar usando : _install.packages("dplyr")_.

- [`e1071`](https://cran.r-project.org/web/packages/e1071/e1071.pdf) : Paquete para realizar _fuzzy clustering_, clasificador de _Naive Bayes_... Se puede instalar usando : _install.packages("e1071")_.

- [`fclust`](https://cran.r-project.org/web/packages/fclust/fclust.pdf) : Paquete que nos proporciona algoritmos para la agrupación difusa, índices de validez de clústeres y gráficos para la validez de estos. Además de la visualización de los resultados de la agrupación difusa. : _install.packages("fclust")_.

- [`factoextra`](https://cran.r-project.org/web/packages/factoextra/factoextra.pdf) : Proporciona algunas funciones sencillas para extraer y visualizar la producción de análisis de datos multivariados. : _install.packages("factoextra")_.

- [`ggpubr`](https://cran.r-project.org/web/packages/ggpubr/ggpubr.pdf) : Paquete que proporciona algunas funciones de fácil manejo para crear y personalizar gráficos listos para ser usados en _ggplot2_. : _install.packages("ggpubr")_.

- [`ggplot2`](https://cran.r-project.org/web/packages/ggplot2/ggplot2.pdf) : Paquete para realizar gráficas. Se puede instalar usando : _install.packages("ggplot2")_.

- [`glmnet`](enlace) : Paquete que nos proporciona rocedimientos eficaces para la adaptación de la red para la regresión lineal, los modelos de regresión logística y multinomial, la regresión de Poisson y el modelo de Cox. : _install.packages("glmnet")_.

- [`igraph`](https://cran.r-project.org/web/packages/igraph/igraph.pdf) : Paquete que nos proporciona procesos para gráficos simples y análisis de redes. Puede manejar gráficos grandes muy bien, gráficos aleatorios y gráficos regulares, además de visualización de estos. : _install.packages("igraph")_.

- [`MASS`](https://cran.r-project.org/web/packages/MASS/MASS.pdf) : Paquete que nos propociona funciones y conjuntos de datos de soporte. : _install.packages("MASS")_.

- [`magrittr`](https://cran.r-project.org/web/packages/magrittr/magrittr.pdf) : Paquete que proporciona un mecanismo para encadenar comandos con \%>\%. Se puede instalar usando : _install.packages("magrittr")_.

- [`NLP`](https://cran.r-project.org/web/packages/NLP/NLP.pdf) : Paquete con clases básicas y métodos para el procesamiento del lenguaje natural. Se puede instalar usando : _install.packages("NLP")_.

- [`ppclust`](https://cran.r-project.org/web/packages/ppclust/ppclust.pdf) : Paquete que nos permite la agrupación de particiones de un conjunto de datos en subconjuntos o clústeres no superpuestos mediante el uso de los algoritmos de agrupación probabilística basados en prototipos. : _install.packages("ppclust")_.

- [`plyr`](https://cran.r-project.org/web/packages/plyr/plyr.pdf) : Paquete que nos ofrece herramientas para dividir, aplicar y combinar datos. Se puede instalar usando : _install.packages("plyr")_.

- [`proxy`](https://cran.r-project.org/web/packages/proxy/proxy.pdf) : Paquete que proporciona un _framework_ para cálculo eficiente. Se puede instalar usando : _install.packages("proxy")_. 

- [`quanteda`](https://cran.r-project.org/web/packages/quanteda/quanteda.pdf) : Paquete para análisis cuantitativo de texto en R, usado para gestionar corpus, crear y manipular tokens y n-gramas, analizar palabras clave..., representando visualmente el texto y los análisis de texto. Se puede instalar usando : _install.packages("quanteda")_.

- [`rlm`](https://cran.r-project.org/web/packages/rlm/rlm.pdf) : Paquete que nos propociona una adaptación robusta de un modelo lineal que puede responder en forma de matriz. : _install.packages("rlm")_.

- [`rattle`](https://cran.r-project.org/web/packages/rattle/rattle.pdf) : Paquete que permite al usuario cargar rápidamente datos desde un archivo CSV, transformarlos y explorarlos, construir y evaluar modelos, y además, exportarlos. : _install.packages("rattle")_.

- [`randomForest`](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf) : Paquete que nos proporciona clasificación y regresión basada en árboles usando entradas aleatorias. : _install.packages("randomForest")_.

- [`RColorBrewer`](https://cran.r-project.org/web/packages/RColorBrewer/RColorBrewer.pdf) : Paquete que proporciona paletas de colores. Se puede instalar usando : _install.packages("wordcloud")_.

- [`rlist`](https://cran.r-project.org/web/packages/rlist/rlist.pdf) : Paquete que proporciona un conjunto de funciones para la manipulación de datos en forma de lista. Se puede instalar usando : _install.packages("rlist")_.

- [`ROCR`](https://cran.r-project.org/web/packages/ROCR/ROCR.pdf) : Paquete que nos permite hacer uso de gráficos ROC (curva ROC), entre otros. Se puede instalar usando : _install.packages("ROCR")_.

- [`RTextTools`](https://cran.r-project.org/web/packages/RTextTools/RTextTools.pdf) : Paquete para realizar clasificación automática de textos mediante aprendizaje supervisado. Se puede instalar usando : _install.packages("RTextTools")_.

- [`rword2vec`](https://github.com/mukul13/rword2vec) : Paquete que toma un corpus de texto como entrada y produce los vectores de palabra como salida, usado especialmente para obtener las distancias que existen entre un término y los términos semejantes en el texto de formación (aprende la representación vectorial de las palabras). Se puede instalar usando : _install\_github("mukul13/rword2vec")_. 

- [`stargazer`](https://cran.r-project.org/web/packages/stargazer/stargazer.pdf) : Paquete que produce código LaTeX, código HTML/CSS y texto ASCII para tablas bien formateadas que contienen resultados del análisis de regresión de varios modelos en paralelo, así como un resumen de estadísticas. : _install.packages("stargazer")_.

- [`SnowballC`](https://cran.r-project.org/web/packages/SnowballC/SnowballC.pdf) : Paquete adicional para minería de datos, implementa un algoritmo que permite reducir el número de términos con lo que trabajar, es decir, agrupa aquellos términos que contienen la misma raíz. El paquete soporta los siguientes idiomas: alemán, danés, español, finlandés, francés, húngaro, inglés, italiano, noruego, portugués, rumano, ruso, sueco y turco. Se puede instalar usando : _install.packages("SnowballC")_.

- [`tidytext`](https://cran.r-project.org/web/packages/tidytext/tidytext.pdf) : Paquete para minería de textos para procesamiento de textos y análisis de sentimientos usando `dplyr`, `ggplot2`, y otras herramientas ordenadas. Se puede instalar usando : _install.packages("tidytext")_.

- [`tm`](https://cran.r-project.org/web/packages/tm/tm.pdf) : Paquete específico para minería de datos, permite procesar datos de tipo texto. Se puede instalar usando : _install.packages("tm")_.

- [`tseries`](https://cran.r-project.org/web/packages/tseries/tseries.pdf) : Paquete para análisis de series temporales y computación financiera. Se puede instalar usando : _install.packages("tseries")_.

- [`wesanderson`](https://cran.r-project.org/web/packages/wesanderson/wesanderson.pdf) : Paquete que proporciona paletas de colores. Se puede instalar usando : _install.packages("wesanderson")_.

- [`wordcloud`](https://cran.r-project.org/web/packages/wordcloud/wordcloud.pdf) : Paquete para crear gráficas de nubes de palabras, permitiendo visualizar las diferencias y similitudes entre documentos. Se puede instalar usando : _install.packages("wordcloud")_.

\newpage

<!---------------------------- 1. Comprender el problema a resolver ---------------------------------->

# 1. Comprender el problema a resolver

El _dataset_ [**Drug Review Dataset**](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29), proporcionado por [*UCI Machine Learning Repository*](https://archive.ics.uci.edu/ml/index.php), contiene una exhaustiva base de datos de medicamentos específicos, en la cual, el conjunto de datos muestra revisiones de pacientes sobre medicamentos específicos para unas condiciones particulares. Dichas revisiones se encuentran desglosadas en función del tema que se esté tratando: beneficios, efectos secundarios y comentarios generales. De igual modo, se dispone de una calificación de satisfacción general, es decir, de una calificación en base a los efectos secundarios del medicamento y de otra, en base a la efectividad del mismo.

En este proyecto nos centraremos en el **análisis y experiencia qué tienen los usuarios con ciertos tipos de medicamentos**, para la realización y aplicación de las técnicas explicadas a lo largo del curso. Para ello, se proponen los siguientes objetivos principales:

 - Realizar un análisis de sentimientos a partir de la experiencia de dichos usuarios en el uso de ciertos medicamentos, como por ejemplo ver la efectividad del medicamento cuánto está relacionado con los efectos secundarios o beneficios del mismo.
 
 - Comparar la efectividad o efectos secundarios del medicamento, de acuerdo a la puntuación del medicamento según el paciente.
 
 - Compatibilizar dicho modelo de datos con otros conjuntos de datos aportados en [**Drugs.com**](https://www.drugs.com/).

Las características de este conjunto de datos vienen descritas en la siguiente tabla \ref{tabla:preseleccion}:

<!--- Tabla --->

\begin{table}[h]
	\begin{center}
		\begin{tabular}{|>{\columncolor[rgb]{0.94,0.97,1.0}}l|c|}
			\hline 
			\textbf{Características del Data Set} & Multivariable, texto \\ \hline
			\textbf{Características de los atributos} & Entero \\ \hline
			\textbf{Tareas asociadas} & Clasificación, regresión, clustering \\ \hline
			\textbf{Número de instancias} & 4143 \\ \hline
			\textbf{Número de atributos} & 8 \\ \hline
			\textbf{Valores vacíos} & N/A \\ \hline
			\textbf{Área} & N/A \\ \hline
			\textbf{Fecha de donación} & 10/02/2018 \\ \hline
			\textbf{Veces visualizado} & 16759 \\ \hline
		\end{tabular}
		\caption{Información del conjunto de datos}
		\label{tabla:preseleccion}
	\end{center}
\end{table}

Los datos se dividen en un conjunto train (75%) y otro conjunto test (25%) y se almacenan en dos archivos _.tsv_ (tab-separated-values), respectivamente. Los atributos que tenemos en este dataset son:

1. **urlDrugName** (categorical): nombre del medicamento/fármaco
2. **rating** (numerical): clasificación o puntuación del 1 a 10 del medicamento según el paciente
3. **effectiveness** (categorical): clasificación de la efectividad del medicamento según el paciente (5 posibles valores)
4. **sideEffects** (categorical): clasificación de los efectos secundarios del medicamento según el paciente (5 posibles valores)
5. **condition** (categorical): nombre de la condición (diagnóstico)
6. **benefitsReview** (text): opinión del paciente sobre los beneficios
7. **sideEffectsReview** (text): opinión del paciente sobre los efectos secundarios
8. **commentsReview** (text): comentario general del paciente

<!----------------------------2. Preprocesamiento de datos------------------------------------>

# 2. Preprocesamiento de datos

En este apartado, pondremos los datos a punto para la aplicación de diversas técnicas. Por tanto, para poder analizar dicho _dataset_ y realizar el preprocesamiento al mismo, lo primero que se va hacer es leer el conjunto de datos _train_ y _test_. Una vez leídos, se procederán a aplicar las siguientes técnicas con el fin de limpiar los datos:

1. Lectura del dataset
2. Eliminación de columnas que información irrelevante para el análisis
3. Eliminación de filas que no proporcionan información alguna
4. Cuantificación de variables
5. Representación gráfica de los datos
6. Creación del corpus
7. Representación gráfica de las frecuencias
8. Correlación
9. Eliminar signos de puntuación
10. Conversión de las mayúsculas en minúsculas
11. Eliminación de Stopwords
12. Agrupación de sinónimos
13. TF-IDF
14. Stemming
15. Borrar espacios en blanco innecesarios
16. Valores perdidos
17. Term Document Matrix
18. Sparsity
19.
20.
21.
22.
23.

\newpage 

<!-------------------------------------------------------------------------------------------->

## 2.1. Lectura del dataset

A continuación, mediante la función `read.table(...)` procedemos a la lectura de los datos explicados previamente:

### 2.1.1. Lectura de datos train

Se va a proceder a la lectura del conjunto de datos de entrenamiento.

```{r, warning=FALSE}
# Lectura de datos train
datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",
                          quote = "\"", header=TRUE)
```

Disponemos de una matriz de 3107 filas x 9 columnas, asimismo vamos a ver un ejemplo de cómo está distribuida la información. Por ejemplo, para la tercera fila encontramos la siguiente información:

\begin{table}[h]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{X} & \textbf{urlDrugName} & \textbf{rating} & \textbf{effectiveness} 
      & \textbf{sideEffects} &\textbf{condition} \\ \hline
      1146 & ponstel & 10 & Highly Effective & No Side Effects & menstrual cramps  \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de entrenamiento I}
  \label{tabla:datos_trainI}
\end{table}

\begin{table}[h]
  \centering
    \begin{tabular}{|m{5cm}|m{3cm}|m{7cm}|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{benefitsReview} & \textbf{sideEffectsReview} & \textbf{commentsReview} \\ \hline
      I was used to having cramps so badly that they would leave me balled up in bed for at least 2 days. The Ponstel doesn't take the pain away completely, but takes the edge off so much that normal activities were possible. Definitely a miracle medication!! & Heavier bleeding and clotting than normal. & I took 2 pills at the onset of my menstrual cramps and then every 8-12 hours took 1 pill as needed for about 3-4 days until cramps were over. If cramps are bad, make sure to take every 8 hours on the dot because the medication stops working suddenly and unfortunately takes about an hour to an hour and a half to kick back in.. if cramps are only moderate, taking every 12 hours is okay. \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de entrenamiento II}
  \label{tabla:datos_trainII}
\end{table}

De las tablas \ref{tabla:datos_trainI} y \ref{tabla:datos_trainII} podemos extraer que el medicamento \textbf{ponstel} con identificador \textbf{1146}, tiene la máxima puntuación por parte del paciente (\textbf{rating = 10}), el cual tiene un alto nivel de efectividad (\textbf{Highly Effective}) sin efectos secundarios (\textbf{No Side Effects}), usado para dolores menstruales (\textbf{menstrual cramps}), en donde el paciente dice que de estar tumbado en la cama con dolores ha pasado a poder realizar actividades cotidianas sin ningún impedimento. Además, asegura que tomar este medicamento le ha supuesto un sangrado más abundante y coagulación de lo normal. La dosis del medicamento oscila entre una píldora cada 8-12 horas durante 3-4 días.

```{r, warning=FALSE, include=FALSE}
# Visualizar las 5 primeras filas para los datos train
head(datos_train, 5) 
# Resumen sobre los datos train
summary(datos_train) 
```

### 2.1.2. Lectura de datos test

Se va a proceder a la lectura del conjunto de datos de prueba.

```{r, warning=FALSE}
# Lectura de datos test
datos_test <- read.table("./datos/drugLibTest_raw.tsv", sep="\t", comment.char="",
                         quote = "\"", header=TRUE)
```

Disponemos una matriz de 1036 filas x 9 columnas, asimismo vamos a ver un ejemplo de cómo está distribuida la información. Por ejemplo, para la primera fila encontramos la siguiente información:

```{r, warning=FALSE, include=FALSE}
# Visualizar las 5 primeras filas para los datos test
head(datos_test, 5) 
# información sobre los datos test
summary(datos_test) 
```

De las tablas \ref{tabla:datos_testI} y \ref{tabla:datos_testII} podemos extraer que el medicamento \textbf{biaxin} con identificador \textbf{1366}, tiene una puntuación de 9 por parte del paciente (\textbf{rating = 9}), el cual tiene un nivel considerable de efectividad (\textbf{Considerably Effective}) con efectos secundarios leves (\textbf{Mild Side Effects}), usado para la infección sinusal   (\textbf{sinus infection}), en donde el paciente dice que no está muy seguro de si el antibiótico ha destruido las bacterias que causan su infección sinusal. Además, asegura que tomar este medicamento le da algo de dolor de espalda y algunas náuseas. El paciente tomó los antibióticos durante 14 días y la infección sinusal desapareció al sexto día.

\begin{table}[h]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{X} & \textbf{urlDrugName} & \textbf{rating} & \textbf{effectiveness} 
      & \textbf{sideEffects} &\textbf{condition} \\ \hline
      1366 & biaxin & 9 & Considerably Effective & Mild Side Effects & sinus infection  \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de prueba I}
  \label{tabla:datos_testI}
\end{table}

\begin{table}[h]
  \centering
    \begin{tabular}{|m{7cm}|m{3cm}|m{5cm}|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{benefitsReview} & \textbf{sideEffectsReview} & \textbf{commentsReview} \\ \hline
      The antibiotic may have destroyed bacteria causing my sinus infection. But it may also have been caused by a virus, so its hard to say. & Some back pain, some nauseau. & Took the antibiotics for 14 days. Sinus infection was gone after the 6th day. \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de prueba II}
  \label{tabla:datos_testII}
\end{table}


```{r lectura, warning=FALSE, eval=FALSE, include=FALSE}
View(datos_train)    # vista de la tabla
View(datos_test)    # vista de la tabla
```

<!-------------------------------------------------------------------------------------------->

<!--- ## 2.2. Falta de datos, categorización, normalización, reducción de dimensionalidad. --->

<!--- Borrar si añgún atributo no nos da información como un ID, hacer una transformación con los atributos asimétricos, ya que son necesarios para la aplicación de algunos métodos de aprendizaje sensibles a distancias. Se consideran asimétricos cuando el valor skewness se aleja de 0, podemos eliminar las variables con varianza 0 o muy próximas. --->

Una vez leídos nuestros datos, procedemos a la transformación y preprocesamiento de los mismos. En donde la representación del documento se llevará a cabo utilizando palabras, después de un debido filtrado para minimizar la dimensión del espacio de trabajo.

## 2.2. Preprocesamiento de los datos

Dado que la representación total del documento puede tener una alta dimensión, se va a proceder a construir un corpus, necesario para la aplicación de métodos de limpieza y esructuración del texto de entrada e identificación de un subconjunto simplificado de las características del documento, con el fin de poder ser representado en un análisis posterior.

<!-------------------------------------------------------------------------------------------->

### 2.2.1. Eliminar columnas

El primer paso que vamos a realizar es la **eliminación de columnas**, las cuales contienen información irrelevante para nuestro análisis.

#### Eliminar columna ID

Al conjunto de datos utilizado se le ha añadido de forma automática una novena columna, que representa un ID para cada uno de los datos con los que estamos trabajando. Como este ID no nos aporta información alguna, hemos decidido quitarla directamente del _dataframe_. Esta columna se corresponde con la primera columna, por lo cuál, debemos eliminar la columna que se corresponde con la posición 1. Los cambios que hacemos en el _dataset_ deben modificarse tanto en el conjunto de test como train para que los resultados sean consistentes.

```{r}
datos_train = datos_train[-1] # Eliminar columna para el ID en el train
datos_test = datos_test[-1] # Eliminar columna para el ID en el test
```

#### Eliminar columna de commentsReview

Consideramos que la información contenida en _commentsReview_ no es de nuestro interés. En este atributo se almacena texto, en el cual los consumidores de los medicamentos suelen poner en la mayoría de casos la frecuencia o la dosis con la que consumen la misma. En otros casos menos frecuentes, se establecen comentarios más arbitrarios en el que se muestran sus sensaciones o información sin relevancia. Incluso en algunos casos este campo aparece vacío. Es por eso, que hemos decidido eliminar la columna, tanto para el conjunto test como train.

```{r}
datos_train = datos_train[-8] # Eliminar columna para el commentsReview en el train
datos_test = datos_test[-8] # Eliminar columna para el commentsReview en el test
```

<!-------------------------------------------------------------------------------------------->

### 2.2.2. Eliminar filas

Además de eliminar las columnas innecesarias, se han localizado tres filas que no aportan información a nuestro análisis. Asimismo, dichas filas perjudicaban la aplicación de técnicas.

- Se elimina la fila 387, porque no dispone de información alguna ni en _benefitsReview_ y _sideEffectsReview_. 
- Se elimina la fila 928, porque en la columna _condition_ dispone de un carácter raro. 
- Se elimina la fila 3105, porque no tienen información en _benefitsReview_ ("---").

```{r}
datos_train = datos_train[-c(387, 928, 3105),] # Eliminar filas en el train
datos_test = datos_test[-c(387, 928, 3105),] # Eliminar filas en el test
```

<!-------------------------------------------------------------------------------------------->

### 2.2.3. Eliminar elementos repetidos (medicamentos)

Como se puede ver a continuación, existen medicamentos repetidos. Sin embargo, no se ha contabilizado realizar una eliminación de dichos medicamentos a priori, debido a que le damos más importancia a las opiniones de los pacientes, con el fin de obtener la efectividad o efectos secundarios del medicamento.

```{r, include=FALSE}
# Obtenemos los nombres de los medicamentos
nombres_medicamentos <- data.frame(datos_test$urlDrugName)

# Nos creamos un dataset con medicamentos
datos_medicamentos <- aggregate(datos_test$urlDrugName, nombres_medicamentos, length)
colnames(datos_medicamentos)[2]<-"Repeticiones"

# Ordenamos los medicamentos por los que más se repiten
datos_medicamentos_new <- datos_medicamentos[order(datos_medicamentos$Repeticiones, 
                                                   decreasing = TRUE),]

# Luego indico que quiero un grupo por cada valor unico
nombres_medicamentos %>% group_by(datos_test$urlDrugName) %>% tally()  

# Muestro el medicamentos las veces que se repite
datos_test[datos_test$urlDrugName == "paxil",]
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{imagenes/medicamentos_duplicados.png}
    \caption{Medicamento "paxil" repetido 20 veces en el conjunto test}
    \label{medicamentos_repetidos}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.4. Cuantificación de variables

Para poder analizar y trabajar más fácilmente con la información de *sideEffects* y  *effectiveness*, se va a realizar una conversión de dichas columnas a forma cuantitativa, es decir, vamos asignar una etiqueta numérica a cada valor pertinente, tanto para para _train_ como _test_. 

A continuación, vamos a cuantificar la columna de *sideEffects*, para ello se añade una nueva columna a nuestro conjunto de datos denominada *sideEffectsNumber* que nos clasifica los posibles valores de la columna *sideEffects* en un rango numérico, comprendido entre 1 y 5. Dicha columna hace referencia a la clasificación de los efectos secundarios del medicamento según el paciente, en donde la etiqueta con valor 1 hará referencia a que no haya ningún efecto secundario y la etiqueta con valor 5 a que tiene efectos secundarios extremadamente graves:

- Extremely Severe Side Effects (efectos secundarios extremadamente graves) : 5
- Severe Side Effects (efectos secundarios graves): 4
- Moderate Side Effects (efectos secundarios moderados) : 3
- Mild Side Effects (efectos secundarios leves) : 2
- No Side Effects (sin efectos secundarios) : 1

```{r}
# Datos Train
datos_train$sideEffectsNumber[datos_train$sideEffects=="Extremely Severe Side Effects"]<-5
datos_train$sideEffectsNumber[datos_train$sideEffects=="Severe Side Effects"]<-4
datos_train$sideEffectsNumber[datos_train$sideEffects=="Moderate Side Effects"] <- 3
datos_train$sideEffectsNumber[datos_train$sideEffects=="Mild Side Effects"]<- 2
datos_train$sideEffectsNumber[datos_train$sideEffects=="No Side Effects"]<- 1

# Datos Test
datos_test$sideEffectsNumber[datos_test$sideEffects=="Extremely Severe Side Effects"]<-5
datos_test$sideEffectsNumber[datos_test$sideEffects=="Severe Side Effects"]<-4
datos_test$sideEffectsNumber[datos_test$sideEffects=="Moderate Side Effects"]<-3
datos_test$sideEffectsNumber[datos_test$sideEffects=="Mild Side Effects"]<-2
datos_test$sideEffectsNumber[datos_test$sideEffects=="No Side Effects"]<-1
```

Podemos comprobar que se ha creado la nueva columna *sideEffectsNumber*, y que se han añadido los cambios comentados anteriormente.

```{r}
head(datos_train$sideEffects, 5)
head(datos_train$sideEffectsNumber, 5) 
```

Volvemos a aplicar el mismo procedimiento para la columna de *effectiveness*, creándonos para ello una columna denominada *effectivenessNumber*. Dicha columna, hace referencia a la clasificación de la efectividad del medicamento según el paciente, en donde la etiqueta con valor 1 hace referencia a que el medicamente es ineficaz y la etiqueta con valor 5 a que el medicamente es altamente eficaz:

- Highly Effective (altamente efectivo): 5
- Considerably Effective (considerablemente efectivo) : 4
- Moderately Effective (moderadamente efectivo) : 3
- Marginally Effective (marginalmente efectivo) : 2
- Ineffective (ineficaz) : 1

```{r}
# Datos de entrenamiento
datos_train$effectivenessNumber[datos_train$effectiveness=="Highly Effective"]<-5
datos_train$effectivenessNumber[datos_train$effectiveness=="Considerably Effective"]<-4
datos_train$effectivenessNumber[datos_train$effectiveness=="Moderately Effective"]<-3
datos_train$effectivenessNumber[datos_train$effectiveness=="Marginally Effective"]<-2
datos_train$effectivenessNumber[datos_train$effectiveness=="Ineffective"]<- 1

# Datos de test
datos_test$effectivenessNumber[datos_test$effectiveness=="Highly Effective"]<-5
datos_test$effectivenessNumber[datos_test$effectiveness=="Considerably Effective"]<-4
datos_test$effectivenessNumber[datos_test$effectiveness=="Moderately Effective"]<-3
datos_test$effectivenessNumber[datos_test$effectiveness=="Marginally Effective"]<-2
datos_test$effectivenessNumber[datos_test$effectiveness=="Ineffective"]<-1
```

Comprobamos que se ha creado la nueva columna *effectivenessNumber*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$effectiveness, 5)
head(datos_train$effectivenessNumber, 5) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.5. Cálculo del rating ponderado

En este subapartado, se va a realizar una agregación de varias columnas, en donde queremos realizar una valoración general del medicamento. Para ello, se va a realizar una ponderación entre la columna que contiene los efectos secundarios y la efectividad del medicamento. Asimismo, se ha considerado a los efectos secundarios del medicamento con mayor importancia, es por eso que se le ha otorgado una ponderación del 70\% frente al 30\% de la efectividad del medicamento.

$$( sideEffects \cdot 0.7 ) + ( effectiveness \cdot 0.3 )$$

El motivo de esta ponderación es que se considera que es peor tener efectos secundarios severos en un medicamento, que ser efectivo. Dicha agregación se ha añadido a una nueva columna, denominada **weightedRating**, cuyo resultado contiene una valoración general del medicamento. En donde, dicha transformación, puede ser usada para realizar una compararación con las propias valoraciones de los usuarios.

```{r}
# Recorremos el dataframe para el conjunto train
for (i in 1:length(datos_train[[1]])) {
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_train$sideEffectsNumber[i]
  # Obtenemos el valor de efectiveness
  effectivenessRating <- datos_train$effectivenessNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, ya que 
  # sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para 
  # ello realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
  
  # Obtenemos el resultado ponderado en tipo float
  floatResult <- effectivenessRating * 0.7 + sideEffectRating * 0.3
  
  # Convertimos el resultado a valor entero.
  integerResult <- as.integer(floatResult)
  
  # Calculamos la parte decimal y redondeamos
  if(floatResult - integerResult < 0.5) result <- integerResult
  else result <- integerResult+1
  
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a 
  # escala (1-10)
  datos_train$weightedRating[i] <- result * 2
}
```

Comprobamos que se ha creado la nueva columna *weightedRating*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$weightedRating, 10) 
```

Ahora ralizamos el mismo proceimiento para el conjunto test, y comprobamos que se ha creado la nueva columna *weightedRating*, y que se han añadido los cambios comentados.

```{r, include=FALSE}
# Ponderaciones
sideEffectstWeight <- 0.7
effectivenessWeight <- 0.3

# Recorremos el dataframe para el conjunto test
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_test$sideEffectsNumber[i]
  # Obtenemos el valor de efectiveness
  effectivenessRating <- datos_test$effectivenessNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, 
  # ya que sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para ello 
  # realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
  # Obtenemos el resultado ponderado en tipo float
  floatResult <- effectivenessRating * effectivenessWeight + sideEffectRating * sideEffectstWeight
  
  # Convertimos el resultado a valor entero.
  integerResult <- as.integer(floatResult)
  
  # Calculamos la parte decimal y redondeamos
  if(floatResult - integerResult < 0.5)
    result <- integerResult
  else
    result <- integerResult+1
  
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a 
  # escala (1-10)
  datos_test$weightedRating[i] <- result * 2
}
```

```{r}
head(datos_test$weightedRating, 10) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.6. Convertir el rating a variable binaria

Para la realización de algunas técnicas que se explicarán a continuación, se necesita tener una etiqueta o variable binaria comprendida entre 0 y 1, es por eso que se ha optado por escoger la columna que contiene la puntuación del medicamento por parte del paciente, y establecerla entre 0 y 1. En donde el 0, tendrá los valores comprendidos entre 1 y 4 y será que el medicamento no es favorable; y en donde el 1, tendrá los valores comprendidos entre 5 y 10 y será que el medicamento es favorable. Dichos cambios, serán añadidos a una nueva columna llamada **ratingLabel**. Realizamos dicho cambio, tanto para test como train.

```{r}
# Recorremos el dataframe para el conjunto train
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de rating
  rating <- datos_train$rating[i]
 
  # Cuando los valores comprendidos entre 1 y 4 - no favorable - 0
  if (datos_train$rating[i] < 5) result <- 0
  # Cuando los valores comprendidos entre 5 y 10 - favorable - 1
  else if (datos_train$rating[i] >= 5) 
    result <- 1
  
  # Asignamos el resultado a la nueva variable
  datos_train$ratingLabel[i]  <- result
}
```

```{r, include=FALSE}
# Recorremos el dataframe para el conjunto test
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de rating
  rating <- datos_test$rating[i]
 
  # Cuando los valores comprendidos entre 1 y 4 - no favorable - 0
  if (datos_test$rating[i] < 5) result <- 0
  # Cuando los valores comprendidos entre 5 y 10 - favorable - 1
  else if (datos_test$rating[i] >= 5) result <- 1
  
  # Asignamos el resultado a la nueva variable
  datos_test$ratingLabel[i]  <- result
}
```

<!-------------------------------------------------------------------------------------------->

### 2.2.7. Cambiar el orden para la columna sideEffectsNumber

Al comparar las columna _sideEffectsNumber_ y _effectivenesNumber_, llegamos a la conclusión, de que ambas siguen órdenes distintos, es decir, el valor 5 en _sideEffectsNumber_ dice que el medicamento tiene efectos secundarios extremadamente graves, y el valor 5 en _effectivenesNumber_ dice que el medicamento es altamente efectivo. Por tanto, se ha considerado, que el valor correspondiente al 5, sea positivo y el valor correspondiente a 1 negativo. Para ello, se ha modificado el orden de la columna _sideEffectsNumber_, en donde, la nueva columna **sideEffectsInverse** tiene:

- Extremely Severe Side Effects (efectos secundarios extremadamente graves) : 1
- Severe Side Effects (efectos secundarios graves): 2
- Moderate Side Effects (efectos secundarios moderados) : 3
- Mild Side Effects (efectos secundarios leves) : 4
- No Side Effects (sin efectos secundarios) : 5

Realizamos dicha modificación, tanto para train como test.

```{r}
# Recorremos el dataframe para el conjunto train
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_train$sideEffectsNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Cambiamos el orden para el el valor de sideEffect
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
 
  # Añadimos el resultado obtenido
  datos_train$sideEffectsInverse[i] <- sideEffectRating
}
```

```{r, include=FALSE}
# Recorremos el dataframe para el conjunto test
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_test$sideEffectsNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Cambiamos el orden para el el valor de sideEffect
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
 
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a escala (1-10)
  datos_test$sideEffectsInverse[i] <- sideEffectRating
}
```

```{r}
head(datos_train$sideEffectsNumber, 10)
head(datos_train$sideEffectsInverse, 10)
```

<!-------------------------------------------------------------------------------------------->

### 2.2.8. Representación gráfica de los datos

Antes de comenzar con el análisis exploratorio, vamos realizar distintas gráfica de barras con el fin de comprender mejor los datos, antes del procesamiento. Primero realizaremos un gráfico de barras de las clasificaciones del medicamente por parte del paciente. 

En la figura \ref{grafica_rating}, se observa como más del 50% de los medicamentos obtienen una nota superior 6 por parte del paciente. Esto nos sugiere que el paciente, tiene una buena opinión sobre un alto porcentaje de los medicamentos, lo que puede dar lugar a opiniones más positivas. Por otro lado, vamos a mostrar gráficamente los efectos secundarios del medicamento según el paciente. En donde el 1 significa que el medicamento tiene pocos efectos secundarios y el 5 que tiene muchos efectos secundarios. Como se aprecia en la figura \ref{grafica_sideEffectsNumber}, un alto porcentaje de los medicamentos no tiene efectos secundarios, de acuerdo a las valoraciones de los pacientes.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(rating) %>%
    ggplot(aes(x = factor(rating), y = n, fill = factor(rating))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación del medicamento por parte del paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold"))
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.76\textwidth]{imagenes/grafica_rating.png}
    \caption{Clasificación del medicamento por parte del paciente}
    \label{grafica_rating}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.76\textwidth]{imagenes/grafica_sideEffectsNumber.png}
    \caption{Clasificación de los efectos secundarios del medicamento según el paciente}
    \label{grafica_sideEffectsNumber}
\end{figure}

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(sideEffectsNumber) %>%
    ggplot(aes(x = factor(sideEffectsNumber), y = n, fill = factor(sideEffectsNumber))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación de los efectos secundarios del medicamento según el paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold"))
```


Por último, vamos a visualizar gráficamente, la efectividad del medicamentoe según del paciente. En donde el 1 significa que el medicamento tiene poca efectividad y el 5 que tiene mucha efectividad. De acuerdo a la figura \ref{grafica_sideEffectsNumber} y sabiendo que los pacientes aseguran que los medicamentos tienen pocos efectos secundarios, no es de extrañar que también tengan una alta efectividad.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(effectivenessNumber) %>%
    ggplot(aes(x = factor(effectivenessNumber), y = n, fill = factor(effectivenessNumber))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación de la efectividad del medicamento según el paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold")) 
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.76\textwidth]{imagenes/grafica_effectivenessNumber.png}
    \caption{Clasificación de la efectividad del medicamento según el paciente}
    \label{grafica_sideEffectsNumber}
\end{figure}

Acabamos de comprobar, como las valoraciones de los medicamentos por parte de los pacientes son mayormente positivas. Por tanto, una vez comprendidos los datos y eliminadas las columnas anteriores y modificadas las necesarias, ya podemos continuar con el procesamiento de los datos. Para ello, lo primero tenemos que hacer es cargar la librería que procesa los datos de tipo texto en R, para la construcción y manipulación del corpus. La librería más conocida se llama \textbf{tm}, aunque también haremos uso del paquete \textbf{SnowballC} para realizar el _Stemming_. 

<!-------------------------------------------------------------------------------------------->

### 2.2.9. Creación del corpus

Para poder obtener la estructura con la que vamos a procesar nuestra información, debemos obtener un vector con documentos. En nuestro caso, cada uno de los documentos se corresponde con una opinión sobre un fármaco (*benefitsReview*) y los efectos que tiene (*sideEffectsReview*). Para ello, primero debemos de construir un vector con todas los opiniones del _dataframe_ y convertir cada elemento del vector al formato de documento. Podemos usar la función _VectorSource_ para hacer esta conversión. Se deberán realizar todas las modificaciones tanto para el conjunto train como test. 

```{r}
# Datos train

# Nos quedamos con la única columna del dataset que nos interesa. 
# Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, 
# por lo que usamos as.vector para hacer la conversión
benefits_train_review_data = as.vector(datos_train$benefitsReview)
effects_train_review_data = as.vector(datos_train$sideEffectsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus 
# que lo vamos a utilizar
benefits_train_corpus = (VectorSource(benefits_train_review_data))
effects_train_corpus = (VectorSource(effects_train_review_data))

# Creamos el propio corpus
benefits_train_corpus <- Corpus(benefits_train_corpus)
effects_train_corpus <- Corpus(effects_train_corpus)
``` 

```{r}
# Datos test

# Nos quedamos con la única columna del dataset que nos interesa. 
# Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, 
# por lo que usamos as.vector para hacer la conversión
benefits_test_review_data = as.vector(datos_test$benefitsReview)
effects_test_review_data = as.vector(datos_test$sideEffectsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus 
# que lo vamos a utilizar
benefits_test_corpus = (VectorSource(benefits_test_review_data))
effects_test_corpus = (VectorSource(effects_test_review_data))

# Creamos el propio corpus
benefits_test_corpus <- Corpus(benefits_test_corpus)
effects_test_corpus <- Corpus(effects_test_corpus)
``` 

Podemos ver que funciona accediendo a uno cualquiera, de la forma `inspect(benefits_train_corpus[4])`:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_train_corpus1.png}
    \caption{Contenido para benefits\_train\_corpus I}
    \label{benefits1}
\end{figure}

O de la forma `benefits_train_corpus[[4]]$content`:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_train_corpus2.png}
    \caption{Contenido para benefits\_train\_corpus II}
    \label{benefits2}
\end{figure}

Y si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación.

```{r, include=FALSE}
# Si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación
inspect(benefits_train_corpus[4])

benefits_train_corpus[[4]]$content
```

```{r, include=FALSE}
# Si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación
inspect(effects_train_corpus[7])
effects_train_corpus[[7]]$content
```

<!-------------------------------------------------------------------------------------------->

### 2.2.10. Correlación

Una forma de medir la distancia es calcular la correlación entre un término y todos los demás de la matriz. Como en este caso, estamos usando variables textuales, no se aconseja hacer la correlación como tal. Debido a que la correlación indica la fuerza y la dirección de una relación lineal y proporcionalidad entre dos variables estadísticas, ya que está pensada para variables cuantitativas. Por otro lado, si que disponemos de variables categóricas, pero también se ha despreciado hacer la correlación entre ellas, debido a que no podemos prescindir de las etiquetas, ni agrupar distintos medicamentos en uno solo.

Además, la correlación está relacionada con el análisis de componentes principales (PCA), el cual, es una técnica utilizada para describir un conjunto de datos en términos de nuevas variables no correlacionadas. Por lo que se ha despreciado, de primeras realizar tal método.

<!-------------------------------------------------------------------------------------------->

### 2.2.11. Representación gráfica de las frecuencias del Corpus

Una vez creado el corpus y antes de aplicar las técnicas de preprocesamiento, vamos a visualizar las frecuencias para las dos columnas (*benefitsReview* y *sideEffectsReview*) de textos a las que vamos aplicar el preprocesamiento. Para ello, debemos calcular la matriz de términos y obtener los términos con mayor frecuencia.

Como se puede apreciar en la gráfica \ref{benefits3}, los términos que más se repiten son _the_ y _and_, además de otras preposiciones y conjunciones. Si se observa, las palabras que aparecen en la gráfica, no nos aportan información alguna, es por eso que vamos hacer una transformación a los términos, como la eliminación de los _stopwords_.

A continuación, mostramos los términos para la columna *sideEffects*, realizando el mismo procedimiento que antes. Y como se puede ver en la gráfica \ref{benefits4}, obtenemos la misma conclusión que antes. En donde, tenemos palabras que no nos aportan nada de información: _very_, _the_, _that_, _and_...

```{r, echo=FALSE, include=FALSE}
# Frecuencias para benefits en train
# https://rstudio-pubs-static.s3.amazonaws.com/40817_63c8586e26ea49d0a06bcba4e794e43d.html

# Cargamos la librería

# Calculamos la matriz de términos
dtm <- DocumentTermMatrix(benefits_train_corpus)

# Calculamos la frecuencia
freq <- sort(colSums(as.matrix(dtm)), decreasing=FALSE)
wf <- data.frame(word=names(freq), freq=freq)

# Dibujamos el histograma
subset(wf, freq>350)    %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat="identity", fill="darkred", colour="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  ggtitle("Frecuencias para benefits en train sin preprocesamiento") 

```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.67\textwidth]{imagenes/frecuencias_benefits.png}
    \caption{Frecuencia de términos para la columna benefitsReview}
    \label{benefits3}
\end{figure}

```{r, echo=FALSE, include=FALSE}
# Frecuencias para sideEffects en train
# https://rstudio-pubs-static.s3.amazonaws.com/40817_63c8586e26ea49d0a06bcba4e794e43d.html

# Calculamos la matriz de términos
dtm <- DocumentTermMatrix(effects_train_corpus)

# Calculamos la frecuencia
freq <- sort(colSums(as.matrix(dtm)), decreasing=FALSE)
wf <- data.frame(word=names(freq), freq=freq)

# Dibujamos el histograma
subset(wf, freq>350)    %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat="identity", fill="darkred", colour="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  ggtitle("Frecuencias para sideEffects en train sin preprocesamiento") 
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.67\textwidth]{imagenes/frecuencias_sideEffects.png}
    \caption{Frecuencia de términos para la columna sideEffectsReview}
    \label{benefits4}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.12. Eliminar signos de puntuación

Como hemos podido ver en el documento que se ha mostrado por pantalla, en él se aprecia el uso de signos de puntuación y exclamación. En un principio, no tiene sentido en \textit{Data Mining} contemplar los signos de puntuación, ya que no nos van a aportar información. Por ello, los quitamos, como se puede ver a continuación. Con `tm_map(corpus, removePunctuation)`, se eliminan los símbolos: ! " $ % & ' () * + , - . / : ; < = > ? @ [ \ ] ^ _ ' { | } ~, tanto para train como test.

```{r, warning=FALSE}
# Una vez que tenemos el corpus creado, continuamos con el procesamiento para datos train
benefits_train_corpus <- tm_map(benefits_train_corpus,
                                content_transformer(removePunctuation))
effects_train_corpus <- tm_map(effects_train_corpus, 
                               content_transformer(removePunctuation))

# Una vez que tenemos el corpus creado, continuamos con el procesamiento para datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, 
                               content_transformer(removePunctuation))
effects_test_corpus <- tm_map(effects_test_corpus, 
                              content_transformer(removePunctuation))
```

Si volvemos a mostrar la opinión número cuatro, vemos como todos los signos han desaparecido. De hecho, podemos inspeccionar el corpus, y se ve como todos los signos de puntuación, exclamación y derivados ya no están.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_signos_puntuacion.png}
    \caption{Contenido de benefits sin signos de puntuación}
    \label{benefits2}
\end{figure}

```{r, include=FALSE}
inspect(benefits_train_corpus[4])
```

Ocurre lo mismo con el comentario de efectos número siete.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_signos_puntuacion.png}
    \caption{Contenido de effects sin signos de puntuación}
    \label{benefits2}
\end{figure}

```{r, include=FALSE}
inspect(effects_train_corpus[7])
```

<!-------------------------------------------------------------------------------------------->

### 2.2.13. Conversión de las mayúsculas en minúsculas

Para poder hacer uso de los términos por igual, debemos convertir las mayúsculas en minúsculas. Ya que normalmente se convierte en minúsculas todas las letras para que los comienzos de oración no sean tratados de manera diferente por los algoritmos, tanto para train como test.

```{r, warning=FALSE}
# Datos train
benefits_train_corpus <- tm_map(benefits_train_corpus, content_transformer(tolower))
effects_train_corpus <- tm_map(effects_train_corpus, content_transformer(tolower))

# Datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, content_transformer(tolower))
effects_test_corpus <- tm_map(effects_test_corpus, content_transformer(tolower))
```

Si volvemos a mostrar las opiniones, vemos como todas las mayúsuculas han desaparecido. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_mayusculas.png}
    \caption{Contenido de benefits sin mayúsculas}
    \label{benefits2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_mayusculas.png}
    \caption{Contenido de effects sin mayúsculas}
    \label{benefits2}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.14. Eliminación de Stopwords

En cualquier idioma, hay palabras que son tan comunes o muy utilizadas que no aportan información relevante, a dichas palabras se las conoce como _stopwords_ o palabras _stop_. Por ejemplo, en español, las palabras "la", "a", "en", "de" son ejemplos de _stopwords_. Este tipo de palabras debemos de suprimirlas de nuestro corpus. Como, en nuestro caso, el contenido del corpus está en inglés, debemos especificar el idioma correcto para que nos elimine del corpus las palabras adecuadas en dicho idioma, tanto en train como en corpus.

```{r, warning=FALSE}
# Datos train
benefits_train_corpus <- tm_map(benefits_train_corpus, content_transformer(removeWords), 
                                stopwords("english"))
effects_train_corpus <- tm_map(effects_train_corpus, content_transformer(removeWords), 
                               stopwords("english"))

# Datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, content_transformer(removeWords), 
                               stopwords("english"))
effects_test_corpus <- tm_map(effects_test_corpus, content_transformer(removeWords), 
                              stopwords("english"))
```

Si volvemos a mostrar las opiniones, vemos como por ejemplo las palabras como _the_ o _and_, han desaparecido de nuestro corpus.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_stopwords.png}
    \caption{Contenido de benefits sin stopwords}
    \label{benefits2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_stopwords.png}
    \caption{Contenido de effects sin stopwords}
    \label{benefits2}
\end{figure}

Ahora ya hemos eliminado las _stopwords_ de forma correcta, y pasamos a realizar la agrupación de sinónimos.

<!-------------------------------------------------------------------------------------------->

### 2.2.15. Agrupación de sinónimos

Con el fin de disminuir la dimensión del espacio a trabajar, se pueden identificar palabras distintas con el mismo significado y reemplazarlas por una sola palabra. Para ello se toman los sinónimos de dicha palabra. Dentro de las librerías que podemos usar para agrupar sinónimos, destacamos dos: `wordnet` y `rword2vec`. Sin embargo, por su sencillez se va hacer uso de `rword2vec`. Previamente, se obtendrán que palabras son las que mayor frecuencia presentan en nuestro texto, tanto para *benefitsReview* como *sideEffectsReview* del conjunto train y test. Y visualizamos los 4 primeros términos gráficamente para cada columna y conjunto train y test:

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Obtenemos su matriz de términos
matrix_train_benefits_corpus <- TermDocumentMatrix(benefits_train_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_train_benefits_corpus <- as.matrix(matrix_train_benefits_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_train_benefits_corpus <- rowSums(matrix_train_benefits_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_benefits_train_corpus <- sort(matrix_train_benefits_corpus, decreasing = TRUE)
terms_frecuency_benefits_train_corpus <- terms_frecuency_benefits_train_corpus[1:length(benefits_train_corpus)]
# terms_frecuency_benefits_train_corpus
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Obtenemos su matriz de términos
matrix_test_benefits_corpus <- TermDocumentMatrix(benefits_test_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_test_benefits_corpus <- as.matrix(matrix_test_benefits_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_test_benefits_corpus <- rowSums(matrix_test_benefits_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_benefits_test_corpus <- sort(matrix_test_benefits_corpus, decreasing = TRUE)
terms_frecuency_benefits_test_corpus <- terms_frecuency_benefits_test_corpus[1:length(benefits_test_corpus)]
# terms_frecuency_benefits_test_corpus
```

```{r, include=FALSE}
# Columna sideEffectsReview del conjunto train

# Obtenemos su matriz de términos
matrix_train_effects_corpus <- TermDocumentMatrix(effects_train_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_train_effects_corpus <- as.matrix(matrix_train_effects_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_train_effects_corpus <- rowSums(matrix_train_effects_corpus)
# Ordenamos de mayor a menor los términos y nos quedamos con lso 100 primeros
terms_frecuency_effects_train_corpus <- sort(matrix_train_effects_corpus, decreasing = TRUE)
terms_frecuency_effects_train_corpus <- terms_frecuency_effects_train_corpus[1:length(effects_train_corpus)]
# terms_frecuency_effects_train_corpus
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Obtenemos su matriz de términos
matrix_test_effects_corpus <- TermDocumentMatrix(effects_test_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_test_effects_corpus <- as.matrix(matrix_test_effects_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_test_effects_corpus <- rowSums(matrix_test_effects_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_effects_test_corpus <- sort(matrix_test_effects_corpus, decreasing = TRUE)
terms_frecuency_effects_test_corpus <- terms_frecuency_effects_test_corpus[1:length(effects_test_corpus)]
# terms_frecuency_effects_test_corpus
```

```{r, echo=FALSE}
par(mfrow=c(2,2))

graph_terms_frecuency_benefits_train_corpus <- as.matrix(terms_frecuency_benefits_train_corpus)
barplot(graph_terms_frecuency_benefits_train_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("Benefits para train", font = 2))

graph_terms_frecuency_benefits_test_corpus <- as.matrix(terms_frecuency_benefits_test_corpus)
barplot(graph_terms_frecuency_benefits_test_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("Benefits para test", font = 2))

graph_terms_frecuency_effects_train_corpus <- as.matrix(terms_frecuency_effects_train_corpus)
barplot(graph_terms_frecuency_effects_train_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("SideEffects para train", font = 2))

graph_terms_frecuency_effects_test_corpus <- as.matrix(terms_frecuency_effects_test_corpus)
barplot(graph_terms_frecuency_effects_test_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("SideEffects paratest", font = 2))
```

Una vez que tenemos los términos con mayor frecuencia en nuestras columnas (*benefitsReview* y *sideEffectsReview*) y su frecuencia asociada, pasamos a matriz dichos datos, con el fin de obtener solo las palabras y descartar su frecuencia.

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_benefits_train_corpus <- as.matrix(terms_frecuency_benefits_train_corpus)
# terms_frecuency_benefits_train_corpus

# Me quedo solo con los términos
terms_benefits_train_corpus <- rownames(terms_frecuency_benefits_train_corpus)
# terms_benefits_train_corpus
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_benefits_test_corpus <- as.matrix(terms_frecuency_benefits_test_corpus)
# terms_frecuency_benefits_test_corpus

# Me quedo solo con los términos
terms_benefits_test_corpus <- rownames(terms_frecuency_benefits_test_corpus)
# terms_benefits_test_corpus
```

```{r, include=FALSE}
# Columna sideEffectsReview del conjunto train

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_effects_train_corpus <- as.matrix(terms_frecuency_effects_train_corpus)
# terms_frecuency_effects_train_corpus

# Me quedo solo con los términos
terms_effects_train_corpus <- rownames(terms_frecuency_effects_train_corpus)
# terms_effects_train_corpus
```

```{r, include=FALSE}
# Columna sideEffectsReview del conjunto test

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_effects_test_corpus <- as.matrix(terms_frecuency_effects_test_corpus)
# terms_frecuency_effects_test_corpus

# Me quedo solo con los términos
terms_effects_test_corpus <- rownames(terms_frecuency_effects_test_corpus)
# terms_effects_test_corpus
```

Como ya sabemos las palabras a usar, es decir, los términos que más se repite, procedemos a la agrupación por sinónimos. En donde, mediante la función *distance(...)* de la libería *rword2vec*, obtendremos todas palabras más similares de nuestro conjunto, en nuestro caso nos vamos a quedar con las 2 primeras, tanto para *benefitsTrainReview* como *sideEffectsReview* del conjunto train y test. A continuación, se muestran los pasos seguidos.

1. Escribir un fichero los datos asociados a dicha columna.
2. Entrenat los datos del fichero, con el fin de obtener los vectores de palabras que nos darán los palabras más similares.
3. Obtener para cada término del documento, la distancia con los térmios del ficheros, quedándonos con las de mayor frecuencia.
4. Guardar en un fichero dichas distancias.

```{r, include=FALSE}
# http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/
# https://github.com/mukul13/rword2vec
# http://www.rpubs.com/mukul13/rword2vec
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Escribo en un fichero la columna "benefitsReview"
# write.table(datos_train$benefitsReview, "benefitsTrainReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_benefits_train = word2vec(train_file = "benefitsTrainReview.txt", output_file = "benefitsTrainReview.bin", binary=1)

#dist_terms_benefits_train_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_benefits_train_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_benefits_train_corpus[i] = distance(file_name = "benefitsTrainReview.bin", 
#                                                 search_word = terms_benefits_train_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_benefits_train_corpus, 'datos/ficheros-sinonimos/benefits/dist_terms_benefits_train_corpus.RData')
dist_terms_benefits_train_corpus_new <- list.load('datos/ficheros-sinonimos/benefits/dist_terms_benefits_train_corpus.RData')
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Escribo en un fichero la columna "benefitsReview"
# write.table(datos_test$benefitsReview, "benefitsTestReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_benefits_test = word2vec(train_file = "benefitsTestReview.txt", output_file = "benefitsTestReview.bin", binary=1)

#dist_terms_benefits_test_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_benefits_test_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_benefits_test_corpus[i] = distance(file_name = "benefitsTestReview.bin", 
#                                                 search_word = terms_benefits_test_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_benefits_test_corpus, 'datos/ficheros-sinonimos/benefits/dist_terms_benefits_test_corpus.RData')
dist_terms_benefits_test_corpus_new <- list.load('datos/ficheros-sinonimos/benefits/dist_terms_benefits_test_corpus.RData')
```

```{r, include=FALSE}
# Columna sideEffects del conjunto train

# Escribo en un fichero la columna "sideEffectsReview"
# write.table(datos_train$sideEffectsReview, "effectsTrainReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_effects_train = word2vec(train_file = "effectsTrainReview.txt", output_file = "effectsTrainReview.bin", binary=1)

#dist_terms_effects_train_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_effects_train_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_effects_train_corpus[i] = distance(file_name = "effectsTrainReview.bin", 
#                                                 search_word = terms_effects_train_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_effects_train_corpus, 'datos/ficheros-sinonimos/effects/dist_terms_effects_train_corpus.RData')
dist_terms_effects_train_corpus_new <- list.load('datos/ficheros-sinonimos/effects/dist_terms_effects_train_corpus.RData')
```

```{r, include=FALSE}
# Columna sideEffects del conjunto test

# Escribo en un fichero la columna "sideEffectsReview"
# write.table(datos_test$sideEffectsReview, "effectsTestReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_effects_test = word2vec(train_file = "effectsTestReview.txt", output_file = "effectsTestReview.bin", binary=1)

#dist_terms_effects_test_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_effects_test_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_effects_test_corpus[i] = distance(file_name = "effectsTestReview.bin", 
#                                                 search_word = terms_effects_test_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_effects_test_corpus, 'datos/ficheros-sinonimos/effects/dist_terms_effects_test_corpus.RData')
dist_terms_effects_test_corpus_new <- list.load('datos/ficheros-sinonimos/effects/dist_terms_effects_test_corpus.RData')
```

Una vez, que tenemos todas las palabras con los 2 términos más similares, procedemos a sustituir todos esos términos por el término general. Veamos un ejemplo sencillo, en donde las palabras "medicine" o "medication", van a ser sustituidas por "drug".

```{r}
# Obtenemos el tercer término -> "drug"
terms_benefits_train_corpus[3]

# Vamos a sustituir "pain" por sus dos palabras más similares
dist_terms_benefits_train_corpus_new[[3]]
```

Se debe tener en cuenta, que los términos más similares han sido creados solo para nuestros documentos. Por último, ya solo nos queda hacer el reemplazamiento, para ello se usará la función *gsub(...)* sobre el corpus (*benefits_corpus* y *sideEffectsReview*). Para sustituir las palabras en el texto, se ha hecho uso de la función `gsub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE, fixed = FALSE, useBytes = FALSE)`. A continuación, se describe el proceso seguido:

1. Iteramos sobre los términos del documento
2. Iteramos sobre las palabras más frecuentes de cada término
3. Realizamos el reemplazamiento de las palabras más similares por los términos generales, previa conversión a minúsculas.
4. Guardamos los resultados en ficheros.

```{r, warning=FALSE, include=FALSE}
# Para la columna benefitsReview del conjunto train

#dist_terms_benefits_train_corpus_new <- list.remove(dist_terms_benefits_train_corpus_new, c(446, 506))
#dist_terms_benefits_train_corpus_new <- list.remove(dist_terms_benefits_train_corpus_new, c(447, 508, 651, 678, 686, 815, 982, 996))
# dist_terms_benefits_train_corpus <- list.remove(dist_terms_benefits_train_corpus, c(1049, 1077, 1103, 1123, 1186, 1229, 1562, 1617,1659))

#View(dist_terms_benefits_train_corpus)

#for (i in 1:640) # iteramos sobre los terminos, hasta el 1797, porque si vemos el fichero, ya no hay más palabras
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    benefits_train_corpus_new <- tm_map(benefits_train_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_benefits_train_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_benefits_train_corpus[i]))

# guardar "benefits_train_corpus_new"
#saveRDS(benefits_train_corpus_new, file = "datos/ficheros-sinonimos/benefits/benefits_train_corpus_new.rds")
benefits_train_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/benefits/benefits_train_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(benefits_train_corpus$content, "datos/ficheros-sinonimos/benefits/benefitsTrainSinSinonimos.txt")
write.table(benefits_train_corpus_new_load$content, "datos/ficheros-sinonimos/benefits/benefitsTrainConSinonimos.txt")
```

```{r, warning=FALSE, include=FALSE}
# Para la columna benefitsReview del conjunto test

# dist_terms_benefits_test_corpus_new <- list.remove(dist_terms_benefits_test_corpus_new, c(171, 470))

#for (i in 1:450) # iteramos sobre los terminos 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    benefits_test_corpus_new <- tm_map(benefits_test_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_benefits_test_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_benefits_test_corpus[i]))

# guardar "benefits_train_corpus_new"
#saveRDS(benefits_test_corpus_new, file = "datos/ficheros-sinonimos/benefits/benefits_test_corpus_new.rds")
benefits_test_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/benefits/benefits_test_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(benefits_test_corpus$content, "datos/ficheros-sinonimos/benefits/benefitsTestSinSinonimos.txt")
write.table(benefits_test_corpus_new_load$content, "datos/ficheros-sinonimos/benefits/benefitsTestConSinonimos.txt")
```

```{r, warning=FALSE, include=FALSE}
# Para la columna sideEffectsReview del conjunto train

#dist_terms_effects_train_corpus_new <- list.remove(dist_terms_effects_train_corpus_new, c(318, 504, 654, 706, 734, 991))

#for (i in 1:710) # iteramos sobre los terminos, hasta el 1539, porque si vemos el fichero, ya no hay más palabras 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    effects_train_corpus_new <- tm_map(effects_train_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_effects_train_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_effects_train_corpus[i]))

# guardar "effects_train_corpus_new"
# saveRDS(effects_train_corpus_new, file = "effects_train_corpus_new.rds")
effects_train_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/effects/effects_train_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(effects_train_corpus$content, "datos/ficheros-sinonimos/effects/effectsTrainSinSinonimos.txt")
write.table(effects_train_corpus_new_load$content, "datos/ficheros-sinonimos/effects/effectsTrainConSinonimos.txt")
```


```{r, warning=FALSE, include=FALSE}
# Para la columna sideEffectsReview del conjunto test


#for (i in 1:450) # iteramos sobre los terminos 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    effects_test_corpus_new <- tm_map(effects_test_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_effects_test_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_effects_test_corpus[i]))

# guardar "effects_train_corpus_new"
#saveRDS(effects_test_corpus_new, file = "datos/ficheros-sinonimos/effects/effects_test_corpus_new.rds")
effects_test_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/effects/effects_test_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(effects_test_corpus$content, "datos/ficheros-sinonimos/effects/effectsTestSinSinonimos.txt")
write.table(effects_test_corpus_new_load$content, "datos/ficheros-sinonimos/effects/effectsTestConSinonimos.txt")
```

<!-------------------------------------------------------------------------------------------->

### 2.2.16. TF-IDF

Para estudiar la importancia de los términos de un documento en particular, en lugar de utilizar la frecuencia de cada uno de los términos directamente, se pueden utilizar diferentes ponderaciones denominadas TF-IDF (_Term Frequency-Inverse Document Frecuency_). Estas ponderaciones se calculan como el producto de dos medidas, la frecuencia de aparición del término ($tf$) y la frecuencia inversa del documento ($idf$). La fórmula matemática para esta métrica es la siguiente:

$$ tfidf(t, d, D) = tf(t, d) × idf(t, D)$$

donde $t$ es el término, $d$ denota cada documento, $D$ el espacio total de documentos y $tfidf$ es el peso asignado a ese término en el documento correspondiente.

La combinación de los valores de $tf$ e $idf$ da una métrica que permite saber cómo de únicas son las palabras de un documento. La ponderación asigna un alto peso a un término si se produce con frecuencia en ese documento, pero rara vez en la colección completa. Sin embargo, si el término ocurre pocas veces en el documento, o aparece prácticamente en todos ellos, disminuye el peso asignado por la ponderación $tfidf$.

El peso aumenta proporcionalmente al número de veces que una palabra aparece en el documento, pero es compensada por la frecuencia de la palabra en la colección de documentos, lo que permite filtrar las palabras más comunes. Para ello, necesitamos que convertir nuestro corpus a un _dataframe_, en donde cada columna será una palabra del comentario y cada fila un comentario.

```{r, include=FALSE, echo}
# Convertimos las columnas de review a una tabla en el que cada columna será una palabra del comentario y cada fila pertenece a un comentario
dataframe_benefits_train<-data.frame(text=unlist(sapply(benefits_train_corpus_new_load, `[`)), stringsAsFactors=F)
dataframe_effects_train<-data.frame(text=unlist(sapply(effects_train_corpus_new_load, `[`)), stringsAsFactors=F)

dataframe_benefits_test<-data.frame(text=unlist(sapply(benefits_test_corpus_new_load, `[`)), stringsAsFactors=F)
dataframe_effects_test<-data.frame(text=unlist(sapply(effects_test_corpus_new_load, `[`)), stringsAsFactors=F)

# Crea un vector vacío
vector_benefits_train<- c()
vector_effects_train <- c()

vector_benefits_test<- c()
vector_effects_test <- c()

# Convertimos el dataframe a vector en train
for (i in 1:length(dataframe_benefits_train[[1]])){ 
  vector_benefits_train[i] <- dataframe_benefits_train[[1]][i]
  vector_effects_train[i] <- dataframe_effects_train[[1]][i]
}

# Convertimos el dataframe a vector en test
for (i in 1:length(dataframe_benefits_test[[1]])){ 
  vector_benefits_test[i] <- dataframe_benefits_test[[1]][i]
  vector_effects_test[i] <- dataframe_effects_test[[1]][i]
}  
```

**Frecuencia del término**

La primera parte de la fórmula $tf(t, d)$ es simplemente calcular el número de veces que aparece cada palabra en cada documento:

1. Creamos el corpus utilizando el vector de string que hemos creado previamente.
2. Generamos la matriz de términos
3. Convertimos a matriz.

```{r, include=FALSE}
# Creamos el corpus utilizando el vector de string que hemos creado previamente
doc_corpus_benefits_train <-Corpus( VectorSource(vector_benefits_train) )
doc_corpus_effects_train <-Corpus( VectorSource(vector_effects_train) )

doc_corpus_benefits_test <-Corpus( VectorSource(vector_benefits_test) )
doc_corpus_effects_test <-Corpus( VectorSource(vector_effects_test) )

# Generamos la matriz de términos
tdm_benefits_train <- TermDocumentMatrix(doc_corpus_benefits_train)
tdm_effects_train <- TermDocumentMatrix(doc_corpus_effects_train)

tdm_benefits_test <- TermDocumentMatrix(doc_corpus_benefits_test)
tdm_effects_test <- TermDocumentMatrix(doc_corpus_benefits_test)


( tf_benefits_train <- as.matrix(tdm_benefits_train) )
( tf_effects_train <- as.matrix(tdm_effects_train) )

( tf_benefits_test <- as.matrix(tdm_benefits_test) )
( tf_effects_test <- as.matrix(tdm_effects_test) )
```

**Frecuencia inversa del documento**

Durante el cálculo de la frecuencia del término se considera que todos los términos tienen igual importancia, no obstante, se conocen casos en los que ciertos términos pueden aparecer muchas veces pero tienen poca importancia. Esta segunda parte de la fórmula completa el análisis de evaluación de los términos y actúa como corrector de $tf$. Usando la matriz de frecuencia de términos, el peso $idf$ se puede calcular de la siguiente forma:

```{r}
# Calculamos los pesos asociados a cada término en train
terms_benefits_train <- ( idf_benefits_train <- log( ncol(tf_benefits_train) 
                                                     / ( 1+rowSums(tf_benefits_train != 0))))
terms_effects_train <- ( idf_effects_train <- log( ncol(tf_effects_train) 
                                                   / ( 1+rowSums(tf_effects_train != 0))))

# Calculamos los pesos asociados a cada término en test
terms_benefits_test <- ( idf_benefits_test <- log( ncol(tf_benefits_test) 
                                                   / ( 1+rowSums(tf_benefits_test != 0))))
terms_effects_test <- ( idf_effects_test <- log( ncol(tf_effects_test) 
                                                 / ( 1+rowSums(tf_effects_test != 0))))

# Muestra los pesos asociados a cada término (los 5 primeros)
terms_benefits_train[1:5] 
```

Ahora que tenemos nuestra matriz con el término frecuencia y el peso idf, estamos listos para calcular el peso total de $tf-idf$. Para hacer esta multiplicación de matrices, también tendremos que transformar el vector $idf$ en una matriz diagonal. Ambos cálculos se muestran a continuación.

1. Creamos la matriz diagonal: `( idf_benefits_train <- diag(idf_benefits_train) )`
2. Hacemos la operación para calcular $tf_idf$ como el producto de $td \cdot idf$: `tf_idf_benefits_train<- crossprod(tf_benefits_train, idf_benefits_train)`
3. Guardamos los datos en ficheros, con el fin de reducir el tiempo de procesamiento.

```{r, include=FALSE}
# Creamos la matriz diagonal
( idf_benefits_train <- diag(idf_benefits_train) )
( idf_effects_train  <- diag(idf_effects_train) )

( idf_benefits_test <- diag(idf_benefits_test) )
( idf_effects_test  <- diag(idf_effects_test) )


# Hacemos la operación para calcular tf_idf como el producto de td * idf
#tf_idf_benefits_train<- crossprod(tf_benefits_train, idf_benefits_train)
#----
# guardamos los datos

#write.csv(tf_idf_benefits_train, file = "datos/ficheros-TFIDF/benefits/tf_idf-benefits-train.csv")
tf_idf_benefits_train_new <- read.csv(file="datos/ficheros-TFIDF/benefits/tf_idf-benefits-train.csv", header=TRUE, sep=",")
#----

#tf_idf_effects_train<- crossprod(tf_effects_train, idf_effects_train)
#----
# guardamos los datos
#write.csv(tf_idf_effects_train, file = "datos/ficheros-TFIDF/effects/tf_idf-effects-train.csv")
tf_idf_effects_train_new <- read.csv(file="datos/ficheros-TFIDF/effects/tf_idf-effects-train.csv", header=TRUE, sep=",")
#----

#tf_idf_benefits_test<- crossprod(tf_benefits_test, idf_benefits_test)
#----
# guardamos los datos
#write.csv(tf_idf_benefits_test, file = "datos/ficheros-TFIDF/benefits/tf_idf-benefits-test.csv")
tf_idf_benefits_test_new <- read.csv(file="datos/ficheros-TFIDF/benefits/tf_idf-benefits-test.csv", header=TRUE, sep=",")
#----

#tf_idf_effects_test<- crossprod(tf_effects_test, idf_effects_test)
#----
# guardamos los datos
#write.csv(tf_idf_effects_test, file = "datos/ficheros-TFIDF/effects/tf_idf-effects-test.csv")
tf_idf_effects_test_new <- read.csv(file="datos/ficheros-TFIDF/effects/tf_idf-effects-test.csv", header=TRUE, sep=",")
#----

# Sustituye referencias por términos (columnas de tf_idf son igual a las filas de tf)
colnames(tf_idf_benefits_train_new) <- rownames(tf_benefits_train)
colnames(tf_idf_effects_train_new) <- rownames(tf_effects_train)

colnames(tf_idf_benefits_test_new) <- rownames(tf_benefits_test)
colnames(tf_idf_effects_test_new) <- rownames(tf_effects_test)
```

Hay que recordar que en la sección $tf$ (frecuencia del término), estamos representando cada término como el número de veces que aparecieron en el documento. El principal problema para esta representación es que creará un sesgo hacia documentos largos, ya que un término dado tiene más posibilidades de aparecer en documentos más largos, lo que los hace parecer más importantes de lo que realmente son. Por lo tanto, el enfoque para resolver este problema es la buena normalización:

$$ t\_benefits\_train = \frac{tf\_idf\_benefits\_train\_new}{\sqrt(rowSums( tf\_idf\_benefits\_train\_new^2 ) )}$$

```{r, include=FALSE}
# Normalización
t_benefits_train <- tf_idf_benefits_train_new / sqrt( rowSums( tf_idf_benefits_train_new^2 ) )
t_effects_train <- tf_idf_effects_train_new / sqrt( rowSums( tf_idf_effects_train_new^2 ) )

t_benefits_test <- tf_idf_benefits_test_new / sqrt( rowSums( tf_idf_benefits_test_new^2 ) )
t_effects_test <- tf_idf_effects_test_new / sqrt( rowSums( tf_idf_effects_test_new^2 ) )


# Creamos un vector vacío
v_benefits_train <- c()
v_effects_train <- c()

v_benefits_test <- c()
v_effects_test <- c()

# Realiza la suma de todos los pesos de los términos y los almacena en un vector
for (i in 1:length(dataframe_benefits_train[[1]])){
  v_benefits_train[i] <- sum(t_benefits_train[,i])
  v_effects_train[i] <- sum(t_effects_train[,i])
}

for (i in 1:length(dataframe_benefits_test[[1]])){
  v_benefits_test[i] <- sum(t_benefits_test[,i])
  v_effects_test[i] <- sum(t_effects_test[,i])
}


# Convertimos a matriz
terms1_benefits_train <- as.matrix(terms_benefits_train)
terms1_effects_train <- as.matrix(terms_effects_train)

terms1_benefits_test <- as.matrix(terms_benefits_test)
terms1_effects_test <- as.matrix(terms_effects_test)


# Me quedo solo con los términos
terms1_benefits_train <- rownames(terms1_benefits_train)
terms1_effects_train <- rownames(terms1_effects_train)

terms1_benefits_test <- rownames(terms1_benefits_test)
terms1_effects_test <- rownames(terms1_effects_test)


# Me quedo solo con los términos
terms1_5_benefits_train <- terms1_benefits_train[1:length(dataframe_benefits_train[[1]])]
terms1_5_effects_train <- terms1_effects_train[1:length(dataframe_effects_train[[1]])]

terms1_5_benefits_test <- terms1_benefits_test[1:length(dataframe_benefits_test[[1]])]
terms1_5_effects_test <- terms1_effects_test[1:length(dataframe_effects_test[[1]])]


# Unimos la tabla de términos y valores en x
x_benefits_train <- cbind(terms1_5_benefits_train,v_benefits_train)
x_effects_train <- cbind(terms1_5_effects_train,v_effects_train)

x_benefits_test <- cbind(terms1_5_benefits_test,v_benefits_test)
x_effects_test <- cbind(terms1_5_effects_test,v_effects_test)


# Convertimos dicha tabla a dataframe
x1_benefits_train <- as.data.frame(x_benefits_train)
x1_effects_train <- as.data.frame(x_effects_train)

x1_benefits_test <- as.data.frame(x_benefits_test)
x1_effects_test <- as.data.frame(x_effects_test)


# Guardamos en z los valores de x1 ordenados
z_benefits_train <- x1_benefits_train[order(v_benefits_train, decreasing = TRUE),]
z_effects_train <- x1_effects_train[order(v_effects_train, decreasing = TRUE),]

z_benefits_test <- x1_benefits_test[order(v_benefits_test, decreasing = TRUE),]
z_effects_test <- x1_effects_test[order(v_effects_test, decreasing = TRUE),]


# Ordenamos los datos, respetando el orden de los niveles de los factores. Referencia :https://rstudio-pubs-static.s3.amazonaws.com/7433_4537ea5073dc4162950abb715f513469.html
z_benefits_train$terms1_5_new_benefits_train <- factor(z_benefits_train$terms1_5_benefits_train, levels = (z_benefits_train$terms1_5_benefits_train[order(z_benefits_train$v_benefits_train, decreasing = TRUE)]))

# Nos quedamos con los primeros 20 valores
z_benefits_train$terms1_5_new_benefits_train[1:20]
```

```{r}
# Graficamos los resultados para benefits train
ggplot() + 
 geom_bar(data=z_benefits_train[1:10,],aes(x=z_benefits_train$terms1_5_new_benefits_train[1:10],
                                           y=z_benefits_train$v_benefits_train[1:10]), stat='identity', 
          position='dodge')
```

```{r, warning=FALSE, include=FALSE}
# INTENTAR ARREGLAR
# wordlcoud ver como arreglar
# SIGUE SIN SALIR

z_benefits_train$v2 <- as.numeric(z_benefits_train$v_benefits_train)

wordcloud(
 words = z_benefits_train$terms1_5_benefits_train,
 freq = z_benefits_train$v2,
 max.words = 20,
 random.order = F,
 colorPalette="Dark2"
 )
```

<!-------------------------------------------------------------------------------------------->

### 2.2.17. Stemming

El siguiente paso consiste en reducir el número de palabras totales con las que estamos trabajando. En este caso, se trata de reducir aquellas que no nos aportan nada relevante a lo que ya tenemos. En la columna con la que estamos trabajando en este dataframe, se repite una gran cantidad de veces la palabra "benefit", al igual que "benefits". 

Sin embargo, realizar el análisis de nuestros datos con ambas palabras no tiene gran relevancia, ya que una no aporta nada respecto a la otra. Este es un ejemplo del tipo de casos que se nos dan en nuestro dataset. Igual ocurre con "reduce" y "reduced", por ejemplo. Este tipo de situaciones son las que intentamos corregir con este paso. Vamos a ver un ejemplo de este suceso, que se da por ejemplo en los siguientes valores del corpus (y en muchos más). 

```{r}
inspect(benefits_train_corpus_new_load[183])
inspect(benefits_train_corpus_new_load[213])
```

A continuación, aplicamos el proceso de stemming mediante la siguiente orden:

```{r, warning=FALSE}
benefits_train_corpus_new_load <- tm_map(benefits_train_corpus_new_load, stemDocument)
effects_train_corpus_new_load <- tm_map(effects_train_corpus_new_load, stemDocument)

benefits_test_corpus_new_load <- tm_map(benefits_test_corpus_new_load, stemDocument)
effects_test_corpus_new_load <- tm_map(effects_test_corpus_new_load, stemDocument)
```

Si ahora volvemos a mostrar el contenido de dichas opiniones, podemos ver que el stemming se ha hecho efectivo: donde ponía \textit{benefits}, ahora pone \textit{benefit}, como se puede comprobar si volvemos a mostrar dichos elementos del corpus. De hecho, si nos fijamos, no solo esta palabra ha resultado modificada, sino que se han resumido muchas más palabras en comparación a como teníamos los documentos en el momento previo a la aplicación del método \textit{Stem}. Desde este momento, ya tenemos nuestro conjunto reducido a nivel de concepto.

```{r}
inspect(benefits_train_corpus_new_load[183])
inspect(benefits_train_corpus_new_load[213])
```

<!-------------------------------------------------------------------------------------------->

### 2.2.18. Valores perdidos

Tras el proceso de limpieza anterior en un volumen tan grande de datos cabe esperar que algún documento estuviera formado por tan solo palabras vacías, enlaces o combinaciones de estos, es por ello, que por medio de filtrado básico de R se obtienen aquellos que no contienen ninguna palabra y se elimina del conjunto del dataset para evitar problemas en los procesos posteriores.

```{r}
# https://github.com/joseangeldiazg/twitter-text-mining/blob/master/ner.R
# Localizamos posibles valores perdidos que se hayan generado tras el proceso de limpieza
which(benefits_train_corpus_new_load$content=="")
which(effects_train_corpus_new_load$content==" ")
which(benefits_test_corpus_new_load$content=="  ")
which(effects_test_corpus_new_load$content=="   ")

# Vemos que no hay muchos vacios 
benefits_train_corpus_new_load<-benefits_train_corpus_new_load[which(benefits_train_corpus_new_load$content!="")]
effects_train_corpus_new_load<-effects_train_corpus_new_load[which(effects_train_corpus_new_load$content!=" ")]
benefits_test_corpus_new_load<-benefits_test_corpus_new_load[which(benefits_test_corpus_new_load$content!="  ")]
effects_test_corpus_new_load<-effects_test_corpus_new_load[which(effects_test_corpus_new_load$content!="   ")]
```

<!-------------------------------------------------------------------------------------------->

### 2.2.19. Borrar espacios en blanco innecesarios

Hasta el momento hemos hecho distintos cambios en el texto de nuestro dataset. No solo hemos modificado algunas palabras, sino que también hemos borrado otras muchas. Por ello, es adecuado asegurarnos de que no hay más espacios en blanco que los que separan las palabras del texto. Para asegurarnos de ello, podemos ejecutar la siguiente orden, que se encarga de suprimir los espacios en blanco sobrantes.

```{r, warning=FALSE}
benefits_train_corpus_new_load <- tm_map(benefits_train_corpus_new_load, stripWhitespace) 
effects_train_corpus_new_load <- tm_map(effects_train_corpus_new_load, stripWhitespace) 

benefits_test_corpus_new_load <- tm_map(benefits_test_corpus_new_load, stripWhitespace) 
effects_test_corpus_new_load <- tm_map(effects_test_corpus_new_load, stripWhitespace) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.20. Sparsity

También puede resultar muy útil eliminar los términos que aparecen en muy pocos documentos antes de proceder a la clasificación. El motivo principal es la factibilidad computacional, ya que este proceso reduce drásticamente el tamaño de la matriz sin perder información significativa. Además puede eliminar errores en los datos, como podrían ser palabras mal escritas. Para suprimir estos términos, denominados escasos, se utiliza el comando `removeSparseTerms()`.

$$ df(t) > N · (1 != sparse)$$
siendo $df$ la frecuencia de documentos del término $t$ y $N$ el número de vectores. El parámetro sparse toma valores entre 0 y 1. En este caso, el umbral de escasez es 0.999, se toman los términos que aparecen en más del 1\% de documentos.

```{r}
dtm <- DocumentTermMatrix(benefits_train_corpus_new_load)
inspect(dtm)
dtm <- removeSparseTerms(dtm, sparse=0.999)
inspect(dtm)
```

Se observa como de x términos pasamos a x términos, ni un 5\% del total, por tanto se ha considerado despreciar aplicar esta técnica.  Por tanto, ya tenemos nuestros datos listos.

<!-------------------------------------------------------------------------------------------->

### 2.2.21. Matriz de documentos de los términos

Ahora vamos a mapear nuestro corpus creando una matriz de términos, donde las filas corresponden a los documentos y las columnas a los términos. Para ello usaremos la función TermDocumentMatrix:

```{r}
matrix_corpus <- TermDocumentMatrix(benefits_train_corpus_new_load)
```

Podemos observar que tenemos 5838 términos, esto quiere decir que tenemos 5838 palabras diferentes en nuestro Corpus. Obtengamos la *frecuencia de las palabras*:

```{r}
class(matrix_corpus)
```

Como podemos ver, actualmente aún no tenemos nuestros datos en la matriz que buscamos, sino en un vector, por tanto:

```{r}
matrix_corpus <- as.matrix(matrix_corpus)
class(matrix_corpus)
dim(matrix_corpus) 
```

Con este método, hemos obtenido la ocurrencia de las palabras que tenemos en nuestro dataset para cada uno de los documentos/comentarios. Esta matriz tiene 5838 columnas, que representa la totalidad de palabras diferentes que hay en los comentarios de la columna \textit{benefitsReview}, y 3107 filas, donde cada una representa un comentario. Por tanto, en la fila iésima la matriz, tendremos la ocurrencia de las palabras en \textit{benefitsReview} que existen en el comentario \textit{i}.

```{r}
# Sumamos las filas
suma_matrix_corpus <- rowSums(matrix_corpus)
head(suma_matrix_corpus,5)

# Ordenanamos de mayor a menor y muestra los 10 primeros
ordena_mayor_matrix_corpus <- sort(suma_matrix_corpus, decreasing = TRUE)
head(ordena_mayor_matrix_corpus,10)
copia_ordena_mayor = ordena_mayor_matrix_corpus # Para graficos (evitando data.frame)

# Ordenanamos de menor a mayor y muestra los 10 primeros
ordena_menor_matrix_corpus <- sort(suma_matrix_corpus, decreasing = FALSE)
head(ordena_menor_matrix_corpus,10)
```

```{r}
# Transformamos a objeto data.frame, con dos columnas (palabra, frec), para posteriormente graficarlo.
ordena_mayor_matrix_corpus <- data.frame(palabra = names(ordena_mayor_matrix_corpus), frec = ordena_mayor_matrix_corpus)
```

Mostramos las más frecuentes:

```{r}
ordena_mayor_matrix_corpus[1:20,]
```

Y obtenemos la *gráfica*:

```{r}
copia_ordena_mayor <- as.matrix(copia_ordena_mayor)
barplot(copia_ordena_mayor[1:10,],  xlab="Palabras", ylab="Número de frecuencia",
        col = c("lightblue", "mistyrose", "lightcyan",
                "lavender", "cornsilk"))
title(main = list("Las diez palabras más frecuentes después del preprocesamiento", font = 4))
```

### 2.2.22. Nube de palabras

Por último, vamos a visualizar la nube de palabras para benefits preprocesado, tanto al principio del procesamiento como al final.


```{r, include=FALSE, eval=FALSE}
library(tidyverse)
library(readr)
library(RColorBrewer)
library(tidytext)
library(wordcloud)
library(tm)

data_benefits <- read.csv(file="datos/datos_train_preprocesado.csv")
View(data_benefits)
data_benefits$items <- as.character(data_benefits$benefits_preprocesado) # ordena_mayor_matrix_corpus

# Función para crear el wordcloud 
cloud_negative_positive <- function(data){
#   
  drugstext <- unnest_tokens(data, word, items)
# 
  binarytextscore <- get_sentiments(lexicon = "bing")
#     
  drugscloudbinary <- drugstext %>%
    inner_join(binarytextscore, by = "word") %>%
     count(word, sentiment) %>%
     mutate(color = ifelse(sentiment == "positive", "darkgreen", "red"))
 
   drugscloudbinary
}
#

res <- cloud_negative_positive(data_benefits)
wordcloud(res$word, res$n, random.order = FALSE, colors = res$color, ordered.colors = TRUE)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/wordcloud1.png}
    \caption{Contenido de benefits sin stopwords}
    \label{benefits2}
\end{figure}



```{r, warning=FALSE, include=FALSE, eval=FALSE}
# sin preprocesar los datos

library(tidyverse)
library(readr)
library(RColorBrewer)
library(tidytext)
library(wordcloud)
library(tm)

datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",quote = "\"", header=TRUE)
#benefits_corpus = Corpus(VectorSource(datos_train$benefitsReview))
#benefits_corpus <- tm_map(benefits_corpus, content_transformer(tolower))
#benefits_corpus <- tm_map(benefits_corpus, content_transformer(removePunctuation))
#benefits_corpus <- tm_map(benefits_corpus, content_transformer(removeWords), stopwords("english"))
#benefits_corpus <- tm_map(benefits_corpus, stripWhitespace)
datos_train$items <- as.character(datos_train$benefitsReview)

drugstext <- unnest_tokens(datos_train, word, items)
binarytextscore <- get_sentiments(lexicon = "bing")
    
drugscloudbinary <- drugstext %>%
    inner_join(binarytextscore, by = "word") %>%
    count(word, sentiment) %>%
    mutate(color = ifelse(sentiment == "positive", "darkgreen", "red"))
wordcloud(drugscloudbinary$word, drugscloudbinary$n, random.order = FALSE, colors = drugscloudbinary$color, ordered.colors = TRUE)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/wordcloud2.png}
    \caption{Contenido de benefits sin stopwords}
    \label{benefits2}
\end{figure}

<!-------------------------------------------------------------------------------------------->

## 2.2.23. Convertir a dataframe nuestras modificaciones

Por último, con el fin de mejorar los tiempos computacionales y poder hacer uso todos los integrantes del grupo de las columnas preprocesadas, se ha optado por añadir dichos cambios en el dataset y guardarlos en un fichero.

```{r, include=FALSE}
benefits_train_dataframe <- data.frame(text=unlist(sapply(benefits_train_corpus_new_load, `[`)), stringsAsFactors=F)
effects_train_dataframe <- data.frame(text=unlist(sapply(effects_train_corpus_new_load, `[`)), stringsAsFactors=F)

benefits_test_dataframe <- data.frame(text=unlist(sapply(benefits_test_corpus_new_load, `[`)), stringsAsFactors=F)
effects_test_dataframe <- data.frame(text=unlist(sapply(effects_test_corpus_new_load, `[`)), stringsAsFactors=F)

# Añadimos las dos filas train al conjunto
library(data.table)
datos_train_preprocesado = data.frame(datos_train, benefits_train_dataframe)
setnames(datos_train_preprocesado, "text", "benefits_preprocesado")
datos_train_preprocesado = data.frame(datos_train_preprocesado, effects_train_dataframe)
setnames(datos_train_preprocesado, "text", "effects_preprocesado")

# Añadimos las dos filas train al conjunto
library(data.table)
datos_test_preprocesado = data.frame(datos_test, benefits_test_dataframe)
setnames(datos_test_preprocesado, "text", "benefits_preprocesado")
datos_test_preprocesado = data.frame(datos_test_preprocesado, effects_test_dataframe)
setnames(datos_test_preprocesado, "text", "effects_preprocesado")

# Guardamos en ficheros
library(data.table)
write.csv(datos_train_preprocesado, file = "datos/datos_train_preprocesado.csv", row.names = FALSE) # guarda un archivo csv
#View(datos_train_preprocesado)



write.csv(datos_test_preprocesado, file = "datos/datos_test_preprocesado.csv", row.names = FALSE) # guarda un archivo csv
#View(datos_test_preprocesado)
```


**_Nota: Cuando se necesite en las sucesivas técnicas, se realizarán las transformaciones necesarias de acuerdo a cada técnica en cuestión._**

<!----->


# Lectura de datos

```{r}
# Cargamos los tados
datos_train <- read.table("datos/datos_train_preprocesado.csv", sep=",", comment.char="",quote = "\"", header=TRUE)

datos_test <- read.table("datos/datos_test_preprocesado.csv", sep=",", comment.char="",quote = "\"", header=TRUE)
# Establecemos la semilla
```


# Análisis exploratorio de los datos

El análisis exploratorio de datos o (EDA) engloba un conjunto de técnicas para poder comprender de manera rápida la naturaleza de una colección de datos o dataset.

Se basa principalmente en dos criterios: las **estadísticas de resumen**  y la **visualización de datos**.

En primer lugar, vamos a realizar un resumen de nuestros datos utilizando la función `summary`. Dicha función nos mostrará información relevante para cada una de las columnas del datataset, mostrando información general como valores mínimos, máximos, media, mediana..

El resultado que obtenemos al evaluar nuestro dataset es el siguiente:

```{r}

summary(datos_train)

```

A continuación se va a realizar un análisis de la información más relevante no textual, como el valor de **rating** de los usuarios, la **efectividad** y los **efectos secundarios** de dicho medicamento y por último, la **valoración ponderada del rating** teniendo en cuenta la proporción entre efectividad y efectos secundarios del medicamento.


## Valoraciones de los medicamentos por parte de los usuarios.

En primer lugar vamos a analizar si el *rating* aportado por los usuarios sobre los medicamentos son buenos o no.

Empezamos obteniendo las frecuencias y porcentaje total de las valoraciones aportadas por los usuarios. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}

# Obtener frecuencias del rating
table(datos_train$rating)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de cada puntuación respecto del total.
table(datos_train$rating)/numDocuments

```

Como podemos observar, hay una mayoría de valoraciones positivas respecto a las negativas. De hecho el mayor porcentaje (casi el 24%) tienen la máxima valoración.

Podemos comprobar ésto mediante el uso de la moda.

```{r}

# Función para calcular la moda. Se le pasa como parámetro un atributo
calcularModa<-function(var){
  frec.var<-table(var)
  valor<-which(frec.var==max(frec.var))  # Elementos con el valor m
  names(valor)
}

# Obtenemos la moda para el rating
calcularModa(datos_train$rating)
```


Como resumen en general del rating, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable.

La media es la siguiente:

```{r}
# Media
mean(datos_train$rating)

```

La mediana es la siguiente:


```{r}
# Mediana
median(datos_train$rating)

```

El valor obtenido es medio obtenido es 7 y la mediana es 8. Podemos concluir con dicha información, que en general las valoraciones sobre los medicamentos son bastante positivas, situándose el 50% de dichas valoraciones en el valor 8.

A continuación, se va a visualizar dicha información gráficamente:


```{r}

# Histograma de la valoración dada por los usuarios sobre los medicamentos

ratingExploration <- datos_train$rating

hist(ratingExploration,
     main="Rating de los medicamentos",
     xlab="Rating",
     ylab="Frecuencia",
     border="goldenrod3",
     xlim=c(0,10),
     ylim=c(0,800),
     col= "cornsilk",
     breaks=10,
     
     
    )

```



```{r}

# Diagrama de densidad de la valoración dada por los usuarios sobre los medicamentos

plot(density(ratingExploration), 
     main="Densidad del rating",
     xlim=c(0,10),
     )

```

```{r}

# Diagrama de sectores de las valoraciones dadas por los usuarios
pie(table(datos_train$rating))

```


```{r}

# Diagrama de cajas sobre las valoraciones dadas por los usuarios
boxplot(datos_train$rating,main="Rating", col= "cornsilk" )

```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$rating)

```

Como se puede observar, la desviación típica nos da un valor de 2.93. Esto quiere decir que los valores no están concentrados en un único valor, sino que la mayoría se sitúan en el un intervalo con distancia 3 despecto de la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 5 y 10.

Esto también nos da como **conclusión** que en general las **opiniones** sobre los medicamentos **son buenas**, puesto que la mayor cantidad se sitúan en el intervalo [5.10].

## Efectividad del medicamento


En esta sección, se va a analizar si se consideran que los medicamentos son efectivos o no. Para ello se va a analizar el atributo **effectivenessNumber** (que mide la efectividad del medicamento, siendo 1 menos efectivo y 5 más afectivo) 

Empezamos obteniendo las frecuencias y porcentaje total de las anotaciones de efectividad. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}

# Obtener frecuencias del efectivenessNumber
table(datos_train$effectivenessNumber)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de cada valor de efectividad respecto del total.
table(datos_train$effectivenessNumber)/numDocuments

```


Como podemos observar, la mayoría de los medicamentos se consideran que son efectivos. De hecho, la mayoría de los medicamentos se consideran altamente efectivos (con un 42%)

Podemos comprobar ésto mediante el uso de la moda.

```{r}

# Obtenemos la moda para el efectivenessNumber
calcularModa(datos_train$effectivenessNumber)

```


Como resumen en general de la efectividad, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable.

La media es la siguiente:

```{r}
# Media
mean(datos_train$effectivenessNumber)

```

La mediana es la siguiente:


```{r}
# Mediana
median(datos_train$effectivenessNumber)

```

El valor medio obtenido es 3.93 sobre 5 y la mediana es 4. Podemos concluir con dicha información, que en general los medicamentos son bastantes efectivos, situándose el 50% de dichas mediciones sobre el valor 4.

A continuación, se va a visualizar dicha información gráficamente:

```{r}

# Histograma sobre la efectividad de los medicamentos

efecctivenessNumberExploration <- datos_train$effectivenessNumber

hist(efecctivenessNumberExploration,
     main="Efectividad de los medicamentos",
     xlab="Nivel de efectividad",
     ylab="Frecuencia",
     border="green",
     xlim=c(1,5),
     col= "darkseagreen1",
     breaks=5,
     prob=TRUE
    )

```


```{r}

# Diagrama de densidad de la efectividad de los medicamentos

plot(density(datos_train$effectivenessNumber), 
     main="Densidad de la tasa de efectividad",
     xlim=c(0,5),
     )

```

```{r}

# Diagrama de sectores de la efectividad de los medicamentos
pie(table(datos_train$effectivenessNumber))

```


```{r}

# Diagrama de cajas sobre la efectividad de los medicamentos
boxplot(datos_train$effectivenessNumber,main="Tasa de efectividad", col= "darkseagreen1" )

```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$effectivenessNumber)

```

Como se puede observar, la desviación típica nos da un valor de 1.23. Esto quiere decir que la mayor parte de los valores se sitúan en un intervalo con una distancia de uno de la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 3 y 5.

Esto también nos da como **conclusión** que en general los medicamentos tienen una tasa bastante **buena de efectividad** puesto que su tasa se sitúa entre [3.5].


## Efectos secundarios del medicamento


En esta sección, se va a analizar si se consideran que los medicamentos tienen efectos secundarios o no. Para ello se va a analizar el atributo **sideEffectsNumber** (que mide la tasa de efectos secundarios del medicamento, siendo 1 el mínimo de efectos secundarios y 5 el máximo de efectos secundarios) 

Empezamos obteniendo las frecuencias y porcentaje total de las anotaciones de efectos secundarios. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}

# Obtener frecuencias del sideEffectsNumber
table(datos_train$sideEffectsNumber)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de tasa de efectos secundarios respecto del total.
table(datos_train$sideEffectsNumber)/numDocuments

```


Como podemos observar, la mayoría de los medicamentos se consideran que no tienen efectos secundarios severos. De hecho, la mayoría de los medicamentos se sitúan entre sin efectos secundarios (29%) o que tienen efectos secundarios leves (32%).

Podemos comprobar ésto mediante el uso de la moda.

```{r}

# Obtenemos la moda para el sideEffectsNumber
calcularModa(datos_train$sideEffectsNumber)

```


Como resumen en general de sobre la tasa de efectos secundarios, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable.

La media es la siguiente:

```{r}
# Media
mean(datos_train$sideEffectsNumber)

```

La mediana es la siguiente:


```{r}
# Mediana
median(datos_train$sideEffectsNumber)

```

El valor medio obtenido es 2.30 sobre 5 y la mediana es 2. Podemos concluir con dicha información, que en general los medicamentos no tienen efectos secundarios o que dichos efectos son leves.

A continuación, se va a visualizar dicha información gráficamente:

```{r}

# Histograma de la tasa de efectos secundarios

sideEffectsNumberExploration <- datos_train$sideEffectsNumber

hist(sideEffectsNumberExploration,
     main="Efectos secundarios de los medicamentos",
     xlab="Nivel de efectos secundarios",
     ylab="Frecuencia",
     border="white",
     xlim=c(1,5),
     col= "firebrick2",
     breaks=5,
     prob=TRUE
    )

```


```{r}

# Diagrama de densidad sobre la tasa de efectos secundarios

plot(density(datos_train$sideEffectsNumber), 
     main="Densidad de la tasa de efectos secundarios",
     xlim=c(0,5),
     )

```

```{r}
# Diagrama de sectores de los efectos secundarios de los medicamentos
pie(table(datos_train$sideEffectsNumber))

```


```{r}

# Diagrama de cajas de los efectos secundarios de los medicamentos
boxplot(datos_train$effectivenessNumber,main="Tasa de efectos secundarios", col= "firebrick2" )

```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$sideEffectsNumber)

```

Como se puede observar, la desviación típica nos da un valor de 1.17. Esto quiere decir que la mayor parte de los valores se sitúan en un intervalo con una distancia de uno de la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 1 y 2.

Esto también nos da como **conclusión** que en general los medicamentos **no tienen efectos secundarios o son muy leves**.



## Valoración ponderada sobre el medicamento


En esta sección, se va a analizar si se consideran que los medicamentos son buenos o no teniendo en cuenta la relación entre los beneficios que aporta (efectividad) y las inconvenientes que tiene (efectos secundarios). Para ello se va a analizar el atributo **weightedRating** (que mide dicha relación teniendo en cuenta una tasa de efectividad del 30% y una tasa de efectos secundarios del 70%), y siendo 1 peor valorado y 10 mejor valorado.

Empezamos obteniendo las frecuencias y porcentaje total de las anotaciones sobre la puntuación ponderada. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}

# Obtener frecuencias del weightedRating
table(datos_train$weightedRating)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de puntuación ponderada respecto del total.
table(datos_train$weightedRating)/numDocuments

```


Como podemos observar, la mayoría de los medicamentos se consideran que son generalmente beneficiosos. De hecho, la mayoría de los medicamentos se sitúan con una valoración de 8 sobre 10 teniendo en cuenta la relación beneficio/perjuicio.

Podemos comprobar ésto mediante el uso de la moda.

```{r}

# Obtenemos la moda para el weightedRating
calcularModa(datos_train$weightedRating)

```


Como resumen en general de sobre la tasa de efectos secundarios, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable.

La media es la siguiente:

```{r}
# Media
mean(datos_train$weightedRating)

```

La mediana es la siguiente:


```{r}
# Mediana
median(datos_train$weightedRating)

```

El valor medio obtenido es 7.52 sobre 10 y la mediana es 2. Podemos concluir con dicha información que la puntuación general sobre los medicamentos es de **notable**.

A continuación, se va a visualizar dicha información gráficamente:

```{r}

# Histograma de valoración ponderada

weightedRatingExploration <- datos_train$weightedRating

hist(weightedRatingExploration ,
     main="Valoración ponderada de los medicamentos",
     xlab="Rating ponderado",
     ylab="Frecuencia",
     border="blue",
     xlim=c(0,10),
     col= "dodgerblue1",
     breaks=5
     
    )

```



```{r}

# Diagrama de densidad sobre la valoración ponderada

plot(density(datos_train$weightedRating), 
     main="Densidad de valoración ponderada",
     xlim=c(0,10),
     )

```

```{r}
# Diagrama de sectores sobre la valoración ponderada
pie(table(datos_train$weightedRating))

```


```{r}

# Diagrama de cajas sobre la valoración ponderada
boxplot(datos_train$weightedRating,main="Valoración ponderada", col= "dodgerblue1" )

```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$weightedRating)

```

Como se puede observar, la desviación típica nos da un valor de 2.07. Esto quiere decir que la mayor parte de los valores se sitúan en un intervalo con una distancia de dos de la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 6 y 10.

Esto también nos da como **conclusión** que en general los medicamentos **son convenientes tomarlos**.



## Correlación sobre las variables

En esta sección se va a comprobar la correlación que existe entre las variables que miden la efectividad(effectivenessNumber), los efectos secundarios(sideEffectsNumber), la valoración aportada por los usuarios(rating) y la valoración ponderada que se ha realizado sobre el medicamento(weightedRating).

Empezamos calculando la correlación entre la variable que mide la efectividad y los efectos secundarios.

```{r}

# Correlación lineal entre efectivenessNumber y sideEffectsNumber
cor(datos_train[,c(8,9)])
```

Podemos observar que cuantos más efectos secundarios tiene, menor es la efectividad del medicamento. Esto puede estar influido por las valoraciones subjetivas del usuario, ya que si ha tenido una mala experiencia (debido a los efectos secundarios) por la ingesta del medicamento, no va a hacer énfasis en los beneficios del medicamento, sino que hará un mayor énfasis en los aspectos negativos. 


A continuación vamos a calcular la correlación entre la efectividad y la valoración ponderada del medicamento.

```{r}

# Correlación lineal entre efectivenessNumber y weightedRating
cor(datos_train[,9:10])

```

Como se puede observar, cuando el medicamento es más efectivo, la valoración ponderada del medicamento acumenta (como es obvio), y si ahora calculamos la valoración ponderada del medicamento teniendo en cuenta los efectos secundarios

```{r}

# Correlación lineal entre sideEffectsNumber y weightedRating
cor(datos_train[,c(8,10)])

```

Observamos como si el medicamento tiene una mayor tasa de efectos secundarios, la valoración ponderada disminuye considerablemente (obvio porque el 70% de la valoración ponderada tiene en cuenta los efectos secundarios del medicamento).

Ahora vamos a comprobar la relación que existe entre la valoración dada por el usuario y los efectos secundarios.


```{r}

# Correlación lineal entre rating y sideEffectsNumber
cor(datos_train[,c(2,8)])

```

Podemos comprobar como si el medicamento tiene una mayor tasa de efectos secundarios, la valoración dada por el usuario disminuye

```{r}

# Correlación lineal entre rating y effectivenessNumber
cor(datos_train[,c(2,9)])

```

Y si la efectividad del medicamento es alta, la valoración del usuario se incrementa.

Como observación general, se puede destacar que **la valoración del usuario está condicionada más por la efectividad del medicamento** (relación 1/0.74) que por los efectos secundarios (relación 1/-0.68).

Por último, vamos a observar en el siguiente gráfico como se relacionan las variables entre sí en función se sus valores.

```{r}

# Gráfico de coordenadas paralelas
library(MASS)
parcoord(datos_train[,c(8,9,2,10)], col=datos_train$rating,var.label=T)
```

Por ejemplo, podemos destacar como si el número de efectos secundarios es 1 (no tiene efectos secundarios) y la efectividad del medicamento es 5 (muy efectivo), entonces la valoración del usuario será 10 y la valoración ponderada será también 10.



<!------->


```{r, include=FALSE}
# Lectura de los datos train preprocesados
datos_train_preprocesados <- read.csv(file="datos/datos_train_preprocesado.csv")

# Lectura de los datos test preprocesados
datos_test_preprocesados <- read.csv(file="datos/datos_test_preprocesado.csv")
```

# 5. Regresión

En este apartado se va hacer uso de la técnica de **regresión**, con el objetivo de describir dependencias significativas entre las variables incluidas en la base de datos. La regresión es un modelo de predicción de variables continuas, en donde las variables independientes tambien son continuas o al menos numéricas. Dicho proceso viene caracterizado por aprender una función que aplica un conjunto de atributos $X_1..X_n$ en otro atributo $Y$. En nuestro caso, vamos a hacer uso de las columnas:

- **ratingLabel**: etiqueta de 0 ó 1, que contempla la opinión del paciente sobre el medicamento si es favorable (1) o no es favorable (0).
- **effectivenessNumber**: clasificación de la efectividad del medicamento según el paciente (5 posibles valores), en donde el 1 significa que es ineficaz y el 5 que es altamente eficaz.
- **sideEffectsInverse**: clasificación de los efectos secundarios del medicamento según el paciente (5 posibles valores), en donde el 1 significa que teine efectos secundarios extremadamente graves y el 5 que es sin efectos secundarios.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{imagenes/regresion/1.png}
    \caption{Visualización de las columnas a las que aplica regresión}
    \label{1}
\end{figure}

Como se observa en la gráfica \ref{1}, se va hacer uso de variables discretas. El objetivo de aplicar regresión, es obtener la curva ROC, la matriz de confusión y el error en el conjunto test, para obtener así la precisión de nuestro modelo y saber según el paciente qué medicamentos favorables o no, tienen efectos secundarios o son efectivos. 

Como se ha comentado, se va hacer uso de la matriz de confusión, la cual es una herramienta que permite la visualización del desempeño de un algoritmo, en donde cada columna de la matriz representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real. Una de sus ventajas es que permite ver si la predicción falla o no. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{imagenes/regresion/2.png}
    \caption{Matriz de confusión para clasificador binario.}
    \label{2}
\end{figure}

De esta forma, se observa como en la figura \ref{2}, la diagonal principal contiene la suma de todas las predicciones correctas (el modelo dice “S” y acierta, tiene efectos secundarios, o dice “N” y acierta también, no tiene efectos secundarios). La otra diagonal refleja los errores del clasificador: los falsos positivos o “true positives” (dice que es tiene efectos secundarios “S”, pero en realidad no tiene “n”), o los falsos negativos o “false negatives” (dice que es no tiene efectos secundarios “N”, pero en realidad los tiene “p”). Además, otra de las medidas a usar, será la curva ROC, para caracterizar el comportamiento de la predicción.

Pero previo a la realización de las técnicas, se ha optado por eliminar los fármacos repetidos, para así obtener una predicción más acertada. Para dicha eliminación, se han cogido todos los medicamentos duplicados y eliminados los necesarios. Así que si tenemos 5 filas de un mismo medicamentos, se eliminan las 4 consecutivas al primero.

```{r, include=FALSE}
# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r

# Cogemos las columnas que queremos del train
datos_train2 <- datos_train_preprocesados[c(11,9,12)]

# Cogemos los farmacos
nombres_farmacos <- unique(datos_train_preprocesados[,1])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. 
# En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" 
# y "effectivenessNumber".
datos_procesados_train <- matrix(ncol=3, nrow=length(nombres_farmacos))

# Recorremos la lista de fármacos
for(i in 1:length(nombres_farmacos)) {
  
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_train2[which(datos_train_preprocesados$urlDrugName == nombres_farmacos[i]),]
  datos_farmaco = filas_farmaco[1,]
  datos_procesados_train[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_train_procesado <- data.frame(datos_procesados_train)
rownames(data_train_procesado) <- nombres_farmacos
colnames(data_train_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")
# A partir de ahora "data_train_procesado"
```

```{r, include=FALSE}
# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r

# Cogemos las columnas que queremos del test
datos_test2 <- datos_test_preprocesados[c(11,9,12)]

# Cogemos los farmacos
nombres_farmacos <- unique(datos_test_preprocesados[,1])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. 
# En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" 
# y "effectivenessNumber".
datos_procesados_test <- matrix(ncol=3, nrow=length(nombres_farmacos))

# Recorremos la lista de fármacos
for(i in 1:length(nombres_farmacos)){
  
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_test2[which(datos_test_preprocesados$urlDrugName == nombres_farmacos[i]),]
  datos_farmaco = filas_farmaco[1,]
  datos_procesados_test[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_test_procesado <- data.frame(datos_procesados_test)
rownames(data_test_procesado) <- nombres_farmacos
colnames(data_test_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")
# A partir de ahora "data_test_procesado"
```

## 5.1. Regresión Lineal

La regresión lineal simple consiste en generar un modelo de regresión (ecuación de una recta) que permita explicar la relación lineal que existe entre dos variables. A la variable dependiente o respuesta se le identifica como $Y$ y a la variable predictora o independiente como $X$. Con el comando `lm()` podemos ajustar el modelo. Algunos parámetros importantes de esta función son:
 
`lm(formula, data, subset, weights)`

- _formula_: definimos el modelo como: $Y \sim X$.
    - Regresion Múltiple: $y \sim X_1+X_2+...X_n$.
    - Regresión Polinómica: $y \sim poly(x = X, degree = k)$
    - Interacción de variables: $y \sim X_1 \cdot X_2$. Si sólo queremos el término de interacción: $X1:X2$
- _data_ : especificamos el dataset a utilizar
- _subset_ : si dividimos la muestra en training y testing, podemos indicar el subconjunto de entrenamiento con un vector que indique sus números de fila.


### 5.1.1. Regresión Lineal Simple

Se pretende predecir el valor del rating (etiqueta 0-1) en función de la puntuación de los medicamentos y, por otro lado para los efectos secundarios del mismo. Para ello se va a emplear la función `lm()`, la cual genera un modelo de regresión lineal por mínimos cuadrados en el que la variable respuesta es ratingLabel y el predictor sideEffectsInverse, y por otro lado, la variable respuesta será ratingLabel y el predictor effectivenessNumber. 

El modelo de regresión lineal simple se describe de acuerdo a la siguiente ecuación:

$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$$

Siendo $\beta_0$ la ordenada en el origen, $\beta_1$ la pendiente y $\epsilon$ el error aleatorio. Este último representa la diferencia entre el valor ajustado por la recta y el valor real y recoge el efecto de todas aquellas variables que influyen en $Y$ pero que no se incluyen en el modelo como predictores. Al error aleatorio también se le conoce como residuo.

A continuación, se realiza una función con la cual obtener los errores dentro y fuera de la muestra, y la matriz de confusión. 

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_lineal <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  # Calculamos Etest y mostramos la matriz de confusión
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) 
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  # Devolvemos el eror para el conjunto train y test
  list(Etrain=Etrain*100, Etest=Etest*100)
}
```

Primero vamos a obtener un modelo en donde la variable respuesta es ratingLabel y el predictor sideEffectsInverse. Con el fin de obtener, que medicamentos favorables tienen efectos secundarios. Por lo que tendremos que hacer caso a la otra dioganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
lm_effects = lm(data = data_train_procesado, formula = ratingLabel ~ sideEffectsInverse)
summary(lm_effects)
# Evaluamos el modelo
errorres_regresion_lineal(lm_effects)
```

Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05). El valor de R^2 indica que el modelo calculado explica el 26.91% de la variabilidad presente en la variable respuesta (ratingLabel) mediante la variable independiente (sideEffectsInverse). Como se observa se obtiene que hay 11 falsos positivos, es decir, medicamentos que se dicen que tienen efectos secundarios pero no los tienen. Y existen 27 falsos negativos, es decir, medicamentos que se dicen que no tienen efectos secundarios pero que los tienen. Dichos resultados son los obtenidos según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

A continuación, vamos a crear el modelo para la variable respuesta ratingLabel y el predictor effectivenessNumber. Con el fin de obtener, que medicamentos favorables son efectivos. Por lo que tendremos que hacer caso a la otra dioganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
lm_effectiveness = lm(data = data_train_procesado, formula = ratingLabel ~ effectivenessNumber)
summary(lm_effectiveness)
# Evaluamos el modelo
errorres_regresion_lineal(lm_effectiveness)
```

Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05). El valor de R^2 indica que el modelo calculado explica el 36.98% de la variabilidad presente en la variable respuesta (ratingLabel) mediante la variable independiente (effectivenessNumber). Como se observa se obtiene que hay 3 falsos positivos, es decir, medicamentos que se dicen que son efectivos pero que no lo son. Y existen 35 falsos negativos, es decir, medicamentos que se dicen que no son efectivos pero los son Dichos resultados, según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

Una vez que hemos obtenidos las prediciones para nuestro modelo, vamos a obtener las probabilidades para el mismo con el fin de obtener la curva ROC.

```{r}
# Función que dibuja una curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  
  # Realizamos la predicción con la función de RORCR
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, 
       main="Curva ROC - Regresión Lineal - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}
```

```{r, echo=FALSE}
# Obtenemos las probabilidades para effects
prob_LM_effects = predict(lm_effects, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_LM_effects, data_test_procesado$ratingLabel)

# Obtenemos las probabilidades para effectiveness
prob_LM_effectiveness = predict(lm_effectiveness, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_LM_effectiveness, data_test_procesado$ratingLabel)
```


#### 5.1.1.1. Casos atípicos

A continuación para el modelo lineal simple, vamos a obtener los casos atípicos, una forma rápida de identificarlos es usando la función `influencePlot()` del paquete `car`. Esta función produce un gráfico que señala a los casos atípicos influyentes. 

Una de las fuentes de violaciones de los supuestos en el modelado lineal es la presencia de casos atípicos. Un caso atípico es aquel que, dados ciertos valores de $x \sim 1$, $x \sim 2$, $x \sim n$ tiene valores de $y$ muy diferentes a los demás y por lo tanto producen un residuo muy alto. Estos casos atípicos pueden tener gran influencia sobre el modelo, ya que el criterio de mínimos cuadrados buscará minimizar el error y cambiará la pendiente para dar cuenta de estos casos.

Primero vamos a obtener los casos atípicos para el modelo de los efectos secundarios del medicamento.

```{r}
# Detección y visualización de observaciones influyentes para effects
influencePlot(lm_effects, xlab="Hat-Values", ylab="Studentized Residuals")
```

Para dicho modelo, los medicamentos _claritin_, _lipitor_, _ultram-er_, _metronidazole_, _toradol_ y _bactroban_ aparecen como casos atípicos. A continuación, vamos a obtener los casos atípicos para el modelo de la efectividad del medicamento.

```{r}
# Detección y visualización de observaciones influyentes para effectivenessNumber
influencePlot(lm_effectiveness, xlab="Hat-Values", ylab="Studentized Residuals")
```

Para dicho modelo, los medicamentos _propecia_, _claritin_, _depakote_, _anafranil_ y _fluvoxamine_ aparecen como casos atípicos.

#### 5.1.1.2. Regresión Robusta

Una alternativa para controlar los casos atípicos es ajustar un modelo lineal robusto. El modelo lineal robusto utiliza criterios diferentes al de los mínimos cuadrados y pondera la influencia de los casos atípicos, por lo que producen coeficientes y sobre todo errores estándar más confiables. El paquete `MASS` incluye la función `rlm()`, de sintaxis similar a `lm()` que implementa el método para el ajuste de los coeficientes y cálculo de los errores estándar.

Primero, calcularemos el modelo en donde la variable respuesta es ratingLabel y el predictor sideEffectsInverse. Con el fin de obtener, que medicamentos favorables tienen efectos secundarios. Por lo que tendremos que hacer caso a la otra dioganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
rlm_effects = MASS::rlm(ratingLabel ~ sideEffectsInverse, data = data_train_procesado)
stargazer(lm_effects, rlm_effects, type = "text", model.numbers = FALSE, title="Comparación de modelo OLS y Robusto")
```

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
rlm_effectiveness = MASS::rlm(ratingLabel ~ effectivenessNumber, data = data_train_procesado)
stargazer(lm_effectiveness, rlm_effectiveness, type = "text", model.numbers = FALSE, title="Comparación de modelo OLS y Robusto")
```

El modelo robusto aumenta los coeficientes y reduce los errores estándar, aunque no en gran cuantía. En este caso interpretamos que los casos atípicos no son un problema grave.

### 5.1.2. Regresión Lineal Múltiple

Una vez que hemos la regresión lineal simple, vamos a intentar predecir el valor del ratingLabel en función de la puntuación de los medicamentos y de los efectos secundarios del mismo. Para ello se va a emplear la misma (`lm()`), la cual genera un modelo de regresión lineal por mínimos cuadrados en el que la variable respuesta es ratingLabel y los predictores son sideEffectsInverse y effectivenessNumber. Previamenete a la realización del modelo, vamos a comprobar que que las variables a usar pueden ser aplicadas juntas con la función `step()`, para así determinar la calidad del modelo.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber + sideEffectsInverse 
lm_multiple <- lm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)

# https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple
# Nos dice si existe alguna variable que estamos usando que no nos hace falta
step(lm_multiple, direction = "both", trace = 1)

# Obtenemos el error d
errorres_regresion_lineal(lm_multiple)
```

Como se aprecia en salida de la función `step(lm_multiple, direction = "both", trace = 1)`, las dos variables deben ser incluidas en el proceso de selección. 

Por tanto, se observa se obtiene que hay 5 falsos positivos, es decir, medicamentos que se dicen que son favorables pero que no lo son. Y existen 24 falsos negativos, es decir, medicamentos que se dicen que no favorables pero los son. Se debe tener en cuenta que dichos resultados obtenidos han sido según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 9.265176, un buen error si tenemos en cuenta, los obtenidos con la regresión simple.


## 5.2. Regresión Logística

A continuación, vamos a ajustar un modelo con Regresión Logística binario sin regularización. De este modo vamos a comprobar, si se puede intentar encontrar un buen modelo lineal para nuestro problema. Además, discutiremos las necesidades de regularización, para ver si de esta forma conseguimos mejorarlo en cuanto a resultados. 

Para la obtención de la regresión, vamos hacer uso del comando `glm()`.

### 5.2.1. Regresión Logística Simple

La regresión logística simple, es un método de regresión que permite estimar la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. Una de las principales aplicaciones de la regresión logística es la de clasificación binaria, en el que las observaciones se clasifican en un grupo u otro dependiendo del valor que tome la variable empleada como predictor. Es decir para predecir la probabilidad de pertenencia o no a una determinada clase (efectividad - no efectividad).

Para ello, vamos a utilizar la función `glm(..)` que en base al conjunto de muestras de entrenamiento suministrado, es capaz de calcular una probabilidad para cada dato. Si esta probabilidad sobrepasa el valor 0.5, entonces consideramos que dicha muestra pertence a la clase 1, sin embargo, si su probabilidad es menor que 0.5, entonces consideramos que se encuentra en la clase con etiqueta 0. Una vez tengamos las etiquetas predichas a partir de las probabilidades que calcula el modelo, vamos a calcular el error dentro de la muestra y el error fuera de la muestra. Para ello, vamos a especificar como primer argumento, la variable respuesta denominada ratingLabel y a continuación, la variable en la que nos vamos a fijar para ajustar el modelo. 

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_logistica <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) # Calculamos Etest
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  list(Etrain=Etrain*100, Etest=Etest*100)
}
```

Primero vamos a obtener el modelo, que predice la variable sideEffectsInverse a partir del ratingLabel.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
gml_effects = glm(ratingLabel ~ sideEffectsInverse, family = binomial(logit), data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(gml_effects)
```

Como se observa se obtiene que hay 11 falsos positivos, es decir, medicamentos que se dicen que tienen efectos secundarios pero no los tienen. Y existen 27 falsos negativos, es decir, medicamentos que se dicen que no tienen efectos secundarios pero que los tienen. Dichos resultados son los obtenidos según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero se ha comprobado, que se obtiene un mejor error con la regresión lineal múltiple.

A continuación, vamos a crear el modelo para la variable respuesta ratingLabel y el predictor effectivenessNumber. Con el fin de obtener, que medicamentos favorables son efectivos. Por lo que tendremos que hacer caso a la otra diagonal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
gml_effectiveness = glm(ratingLabel ~ effectivenessNumber, family = binomial(logit), data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(gml_effectiveness)
```

Como se observa se obtiene que hay 3 falsos positivos, es decir, medicamentos que se dicen que son efectivos pero que no lo son. Y existen 35 falsos negativos, es decir, medicamentos que se dicen que no son efectivos pero los son Dichos resultados, según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

Una vez que hemos obtenidos las prediciones para nuestro modelo, vamos a obtener las probabilidades para el mismo con el fin de obtener la curva ROC.
```{r, echo=FALSE}
# Obtenemos las probabilidades para effects
prob_GLM_effects = predict(gml_effects, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo logística
plotROC(prob_GLM_effects, data_test_procesado$ratingLabel)
```

```{r, echo=FALSE}
# Obtenemos las probabilidades para effectiveness
prob_GLM_effectiveness = predict(gml_effectiveness, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effectiveness, data_test_procesado$ratingLabel)
```

### 5.2.2. Regresión Logística Multiple

Una vez que hemos la regresión logística simple, vamos a intentar predecir el valor del ratingLabel en función de la puntuación de los medicamentos y de los efectos secundarios del mismo. Para ello se va a emplear la misma (`glm()`).

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse + effectivenessNumber
modelo_glm_multiple <- glm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(modelo_glm_multiple)
```


### 5.2.3. Regularización en Regresión Logística

En este apartado vamos a ajustar un modelo a través de la regresión logística con regularización meidante la técnica Lasso Regression.

#### 5.2.3.1. Rigde Regression

Esta ténica, en esencia, es la regresión lineal con Weight Decay que utilizamos en la Práctica 2, y cuya fórmula es: $(XTX + lambdaI)-1 *XˆT$. Es el parámetro lambda, el que en función de su valor, marca el equilibrio entre los componentes de sesgo y varianza. Cuanto mayor sea su valor, mayor sesgo pero menor varianza. Es decir, cuanto mayor valor tenga lambda, mayor penalización y mayor reducción se les aplica a los valores de los coeficientes.


#### 5.2.3.2. Lasso Regression

Esta técnica, además de realizar la misma tarea que la anterior, pero con una fórmula distinta para aplicar la penalización. Aún así, también utiliza el parámetro lambda para concretar el equilibrio entre sesgo y varianza. Además, también es capaz de realizar una selección de variables, anulando algunos coeficientes. Por lo que además de la reducción de los valores de estos coeficientes también reduce el número de estos necesarios para ajustar el modelo.

Por tanto, para aplicar la regularización, primero debemos averiguar el valor de alpha, que representa la técnica a utilizar. Si alpha=0 entonces la regularización se aplica con la técnica Ridge Regression. Si por el contrario alpha=1, entonces la técnica a utilizar será Lasso Regression. Una vez sabemos qué técnica aplicar a través del valor de alpha, tendremos que concretar el valor de lambda, para
que dicha técnica pueda ajustar el modelo con su respectiva penalización.

Para ello, vamos a usar la función `train(..)` que es capaz de probar distintos valores para alpha y lambda a través del ajuste de varios modelos, de modo que devuelve el mejor valor de lambda y el mejor valor de alpha. Para ello, como primer argumento debemos indicarle los valores de las etiquetas, que se corresponden con los valores de la variable explicativa. A continuación, vamos a darle la oportunidad de explorar con las columnas sideEffectsInverse + effectivenessNumber. Como segundo argumento le proporcionamos el conjunto de entrenamiento. El tercer argumento especifica el tipo de técnica a utilizar para explorar todos los modelos posibles. Con `glmnet`(), le concretamos que
queremos que ajuste dichos modelos a través de la Lasso Regression y de Ridge Regression. Y por último, como cuarto argumento le especificamos la clase de funciones que debe utilizar para ajustar un modelo a través de regresión logística.

```{r}
library(glmnet)
# Ajustamos un modelo a través de Regresión Logística multiclase
modelbest = train(form=as.factor(ratingLabel) ~ sideEffectsInverse + effectivenessNumber, 
                  data=data_train_procesado, method="glmnet", family="binomial")

modelbest$bestTune$alpha
modelbest$bestTune$lambda
```

Como se puede observar, la función nos dice que el mejor modelo que podemos ajustar para nuestro conjunto de entrenamiento, es el que tiene el valor de alpha 0.1. Con este valor tan cercano a 0 podemos intuir que la técnica que va a emplear es Ridge Regression, ya que esta se representa a través de alpha = 0.

En cuanto al valor de lambda, podemos comprobar que es bastante próximo a 0, y que por tanto, la penalización que va a aplicar Ridge Regression no es demasiado agresiva. Por lo que podemos intuir que el modelo ajustado tendrá un cierto grado de flexibilidad en referencia a las muestras mal clasificadas. También indica, que el modelo que va a ajustar, por el valor pequeño de lambda, se puede caracterizar por un
bajo sesgo pero una alta varianza. Lo que puede desembocar en un modelo sobreajustado a los datos de entrenamiento, con una capacidad de generalización bastante escasa.

Para ajustar este modelo hemos utilizado la función `glmnet(..)`. Como primer argumento especificamos una matriz con las muestras de entrenamiento pero sin sus etiquetas, las cuales se le proporcionan a la función en el segundo argumento. Como tercer argumento le volvemos a indicar la familia de funciones que debe utilizar para que sea un modelo ajustado a partir de regresión logística. Los dos siguientes parámetros se corresponden con el mejor alpha y el mejor lambda que hemos obtenido en el proceso anterior.

```{r}
# Conjunto Train

# Primero generamos una matriz con el conjunto de train separando las etiquetas de los datos
x = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, data_train_procesado)[,-ncol(data_train_procesado)]
y = data_train_procesado$ratingLabel

# Conjunto Test
x.test = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, data_test_procesado)[,-ncol(data_test_procesado)]
y.test = data_test_procesado$ratingLabel

# Reproducimos el modelo ajustado con el mejor lambda y el mejor alpha
ridge.mod = glmnet(x=x, y=y, family="binomial", alpha=modelbest$bestTune$alpha,lambda=modelbest$bestTune$lambda,thresh=1e-12)

# Calculamos la predicción
predicciones.ridge = predict(ridge.mod, s=ridge.mod$lambda, newx=x.test, type="response")

# Error de regresión con penalización Ridge
error.ridge = mean (( predicciones.ridge - y.test)^2)
cat("Error con la técnica Ridge Regression: ",error.ridge*100,"%\n")
```

Como se observa, se obtiene un error similar a los anteriores.

## 5.3. Regresión Polinomial

En algunos casos, la verdadera relación entre la variable respuesta y los predictores puede no ser lineal, por lo que podemos aplicar por ejemplo una regresión polinomial. Una forma simple de incorporar asociaciones no lineales en un modelo lineal es incluir versiones transformadas de los predictores, elevándolos a distintas potencias, evitando un exceso de grados para evitar el sobreajuste o overfitting.

La forma más sencilla de incorporar flexibilidad a un modelo lineal es introduciendo nuevos predictores obtenidos al elevar a distintas potencias el predictor original.

Partiendo del modelo lineal: $Y_i = \beta_0 + \beta_1 X_i + \epsilon$

Se obtiene un modelo polinómico de grado d a partir de la ecuación:

$$Y_i = \beta_0 + \beta_1 x_i + \beta_2 x^2_i + \beta_3 x^3_i + ... + \beta_d x^d_i + \epsilon_i$$

```{r}
# Hacemos uso del poly para 2
lm_poly = lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2) + effectivenessNumber)
summary(lm_poly)
errorres_regresion_lineal(lm_poly)
```

Los p-values individuales de sideEffectsInverse, apuntan a que un polinomio de grado 2 es suficiente para modelar el ratingLabel en función de sideEffectsInverse.

```{r}
# Calculo del polinomio de grado 2
modelo_poli2 <- lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2))
summary(modelo_poli2)

# Interpolacion de puntos dentro del rango predictos
limites <- range(data_train_procesado$sideEffectsInverse)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos <- data.frame(sideEffectsInverse = nuevos_puntos)

# Predicción de la variable respuesta y del error estándar
predicciones <- predict(modelo_poli2, newdata = nuevos_puntos, se.fit = TRUE,
                        level = 0.95)

# Cálculo del intervalo de confianza superior e inferior 95%
intervalo_conf <- data.frame(inferior = predicciones$fit -
                                        1.96*predicciones$se.fit,
                             superior = predicciones$fit +
                                        1.96*predicciones$se.fit)

attach(data_train_procesado)
plot(x = sideEffectsInverse, y = ratingLabel, pch = 20, col = "darkgrey")
title("Polinomio de grado 2: ratingLabel ~ sideEffectsInverse")
lines(x = nuevos_puntos$sideEffectsInverse, predicciones$fit, col = "red", pch = 20)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$inferior, col = "blue", pch = 4)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$superior, col = "blue", pch = 4)
```

## 5.4. Conclusiones