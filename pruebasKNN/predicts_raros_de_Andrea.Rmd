---
title: "K_means_v2"
output: html_document
---

```{r}
library(tm)
library(factoextra)
library(proxy)
library(ggpubr)

# Cargamos los tados
datos_train <- read.table("datos_train_preprocesado.csv", sep=",", comment.char="",quote = "\"", header=TRUE)

datos_test <- read.table("datos_test_preprocesado.csv", sep=",", comment.char="",quote = "\"", header=TRUE)
# Establecemos la semilla
set.seed(3)

# Nos quedamos con las columnas que nos interesan 
datos_train2 = datos_train[c(2,8,9)]
datos_test2 = datos_test[c(2,8,9)]
head(datos_train2)
```

Los resultados que se obtienen son muy impredecibles. Vamos a obtener los fármacos representados por una única vez. 
```{r}
km.res <- kmeans(datos_train2, 4)



fviz_cluster(object = km.res, data = datos_train2, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")



```


```{r}

# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r
nombres_farmacos <- unique(datos_train[,1])

print(nombres_farmacos[1:10])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" y "effectivenessNumber".
datos_procesados <- matrix(ncol=3, nrow=length(nombres_farmacos))

for(i in 0:length(nombres_farmacos)){
  #https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_train2[which(datos_train$urlDrugName == nombres_farmacos[i]),]

  mean_rating <- mean(filas_farmaco$rating)
  mean_side_effect <- mean(filas_farmaco$sideEffectsNumber)
  mean_effectiveness <- mean(filas_farmaco$effectivenessNumber)

  #print(mean_rating)
  datos_procesados[i,] <- c(mean_rating, round(mean_side_effect)*(-1), round(mean_effectiveness))
  
}


data_train_procesado <- data.frame(datos_procesados)
rownames(data_train_procesado) <- nombres_farmacos
colnames(data_train_procesado) <- c("rating", "sideEffectNumber", "effectivenessNumber")
```

```{r}
res_clustering <- kmeans(data_train_procesado, 5)

# https://rpubs.com/Joaquin_AR/310338 PASOS SEGUIDOS  

fviz_cluster(object = res_clustering, data = data_train_procesado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")
```
Voy a repetir el mismo cálculo, pero en este caso solamente mostrando fármacos "famosos" o significativos, ya que salen muchos fármacos y no se entiende nada, y de esta forma quizá conseguimos quedarnos con los más importantes y entender algo del gráfico resultante.

Así que he copiado la misma función de arriba, pero le he añadido un nuevo parámetro a la función, que representa a partir de cuántas repeticiones de un fármaco consideramos que este es relevante para ponerlo en el clustering. 
```{r}


# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r
nombres_farmacos <- unique(datos_train[,1])

print(nombres_farmacos[1:10])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" y "effectivenessNumber".
datos_procesados <- matrix(ncol=3, nrow=length(nombres_farmacos))

for(i in 0:length(nombres_farmacos)){
  #https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_train2[which(datos_train$urlDrugName == nombres_farmacos[i]),]
  if (nrow(filas_farmaco)>20 ){
  mean_rating <- mean(filas_farmaco$rating)
  mean_side_effect <- mean(filas_farmaco$sideEffectsNumber)
  mean_effectiveness <- mean(filas_farmaco$effectivenessNumber)}

  #print(mean_rating)
  datos_procesados[i,] <- c(mean_rating, round(mean_side_effect)*(-1), round(mean_effectiveness))
  
}




data_train_procesado <- data.frame(datos_procesados)
rownames(data_train_procesado) <- nombres_farmacos
colnames(data_train_procesado) <- c("rating", "sideEffectNumber", "effectivenessNumber")

datos_luis = data_train_procesado

res_clustering <- kmeans(data_train_procesado, 5)





```

```{r}
fviz_cluster(object = res_clustering, data = data_train_procesado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")
```


Vamos a intentar hacer predict...... lloran2
```{r}

nombres_farmacos <- unique(datos_test[,1])

print(nombres_farmacos[1:10])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" y "effectivenessNumber".
datos_procesados <- matrix(ncol=3, nrow=length(nombres_farmacos))

for(i in 0:length(nombres_farmacos)){
  #https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_test2[which(datos_test$urlDrugName == nombres_farmacos[i]),]
  
  mean_rating <- mean(filas_farmaco$rating)
  mean_side_effect <- mean(filas_farmaco$sideEffectsNumber)
  mean_effectiveness <- mean(filas_farmaco$effectivenessNumber)

  #print(mean_rating)
  datos_procesados[i,] <- c(mean_rating, round(mean_side_effect)*(-1), round(mean_effectiveness))
  
}


data_test_procesado <- data.frame(datos_procesados)
rownames(data_test_procesado) <- nombres_farmacos
colnames(data_test_procesado) <- c("rating", "sideEffectNumber", "effectivenessNumber")


test_clustering = kmeans(data_test_procesado,centers=res_clustering$centers)
fviz_cluster(object = test_clustering, data = data_test_procesado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")



```

```{r}


predict.kmeans <- function(object, newdata){
    centers <- object$centers
    n_centers <- nrow(centers)
    dist_mat <- as.matrix(dist(rbind(centers, newdata)))
    dist_mat <- dist_mat[-seq(n_centers), seq(n_centers)]
    max.col(-dist_mat)
}

set.seed(47)



library('clue')
mod_kmeans <-  kmeans(data_train_procesado, 5)
test_preds <- cl_predict(mod_kmeans, data_test_procesado)


table(test_preds)

head(test_preds)

```




https://stats.stackexchange.com/questions/144616/comparing-k-means-results-to-original-data-how-to-interpret-the-resulting-plots quiza sirve para pintar graficos de estos de cajas chulis


```{r}

```

ahora voy a buscar un farmaco que exista en los dos conjuntos

```{r}
# Primero buscamos los fármacos que estén en tanto en train como en test, pq son con los que podemos ver si funciona o no el clustering. Vamos a ver si coinciden. 
x = intersect(datos_test$urlDrugName, datos_train$urlDrugName)
head(x)

# df[match(item,df$cname),]
indice_train = match('sarafem',datos_train$urlDrugName)
indice_test = match('sarafem',datos_test$urlDrugName)

# imprimimos cluster que tiene en train 
res_clustering$cluster[indice_train]

# imprimimos cluster que tiene en test
test_clustering$cluster[indice_test]

count = 0
count_na = 0
for(farmaco in x){
  indice_train = match(farmaco,datos_train$urlDrugName)
  indice_test = match(farmaco,datos_test$urlDrugName)
  
  # imprimimos cluster que tiene en train 
  c_train = res_clustering$cluster[indice_train]

  # imprimimos cluster que tiene en test
  c_test = test_clustering$cluster[indice_test]
  
  if ( !is.na(c_train) && !is.na(c_test) && c_train == c_test){
    count = count +1
  }
  
  if (is.na(c_train) || is.na(c_test))
    count_na = count_na +1
}

print(count)

```


## Clustering Difuso

INTENTO FUZZY CLUSTERING
```{r}
#install.packages("ppclust")
library(ppclust)
library(cluster)
library(fclust)

 head(data_train_procesado)
datos <- scale(data_train_procesado)
 fuzzy_cluster <- fanny(x = datos, k = 3, metric = "euclidean", stand = FALSE)
head(fuzzy_cluster$membership)
# fuzzy_cluster$coeff
# head(fuzzy_cluster$clustering)
fviz_cluster(object = fuzzy_cluster, repel = TRUE, ellipse.type = "norm", pallete = "jco") + theme_bw() + labs(title = "Fuzzy Cluster plot")

```

## K - MEDIOIDES CLUSTERING

Nuevo método en el que agrupamos las observaciones en K clusters, siendo este valor K preestablecido. En este caso, cada cluster está representado por una observación presente en el cluster. Mediante este método hacemos uso de medoids, consiguiendo que sea menos afectado por ruido.

Para su resolución usaremos el alogitmo PAM (Partitioning Around Medoids). Este minimiza la suma de las diferencias de cada observación respecto a su medoid.

```{r}

# Escalamos antes de aplicar el clustering
datos <- scale(datos_luis)

# Identificamos el número optimo de clusters
fviz_nbclust(x = datos, FUNcluster = pam, method = "wss", k.max = 15, diss = dist(datos, method = "manhattan"))

# Vemos que a partir de 6 clusters parece estabilizarse, por tanto, k=6
set.seed(123)
pam_clusters <- pam(x = datos, k = 6, metric = "manhattan")
#pam_clusters
# Observaciones que finalmente se han seleccionado
#pam_clusters$medoids
# Cluster al que se ha asignado cada observación
#pam_clusters$clustering

fviz_cluster(object = pam_clusters, data = datos, ellipse.type = "t", repel = TRUE) +
  theme_bw() +
  labs(title = "Resultados clustering PAM") +
  theme(legend.position = "none")

```

Como podemos observar, no hay centroides. Ahora vamos a resaltar las observaciones que actúan como medoids.

```{r}

# Calculamos el PCA y extraemos las proyecciones almacenadas en el elemento x.
medoids <- prcomp(datos)$x

# Se seleccionan únicamente las proyecciones de las observaciones que son medoids
medoids <- medoids[rownames(pam_clusters$medoids), c("PC1", "PC2")]
medoids <- as.data.frame(medoids)

# Se emplean los mismos nombres que en el objeto ggplot
colnames(medoids) <- c("x", "y")

# Creación del gráfico
fviz_cluster(object = pam_clusters, data = datos, ellipse.type = "t",
             repel = TRUE) +
  theme_bw() +
  # Se resaltan las observaciones que actúan como medoids
  geom_point(data = medoids, color = "firebrick", size = 2) +
  labs(title = "Resultados clustering PAM") +
  theme(legend.position = "none")
```

## Hierarchical clustering

Hierarchical clustering es una alternativa a los métodos de partitioning clustering que no requiere que se pre-especifique el número de clusters. Se pueden seguir dos estrategias, aglomerativa o divisiva, en este caso vamos a usar la primera.

En el método aglomerativo el agrupamiento se inicia en el base del árbol, siendo cada observación un cluster individual. Entonces los cluster se van conbinando conforma le estructura crece hasta unirse en única rama central.

```{r}
# Verificar el árbol

datos <- scale(datos_luis)

# Matriz de distancias euclídeas
mat_dist <- dist(x = datos, method = "euclidean")
# Dendrogramas con linkage complete y average
hc_euclidea_complete <- hclust(d = mat_dist, method = "complete")
hc_euclidea_average  <- hclust(d = mat_dist, method = "average")

cor(x = mat_dist, cophenetic(hc_euclidea_complete))
cor(x = mat_dist, cophenetic(hc_euclidea_average))

```



```{r}
# Cortar el árbol para generar los clusters

library(factoextra)
datos <- scale(datos_luis)
set.seed(101)

hc_euclidea_completo <- hclust(d = dist(x = datos, method = "euclidean"),
                               method = "complete")

fviz_dend(x = hc_euclidea_completo, k = 2, cex = 0.6) +
  geom_hline(yintercept = 5.5, linetype = "dashed") +
  labs(title = "Herarchical clustering",
       subtitle = "Distancia euclídea, Lincage complete, K=2")
```

```{r}
fviz_cluster(object = list(data=datos, cluster=cutree(hc_euclidea_completo, k=4)),
             ellipse.type = "convex", repel = TRUE, show.clust.cent = FALSE,
             labelsize = 8)  +
  labs(title = "Hierarchical clustering + Proyección PCA",
       subtitle = "Distancia euclídea, Lincage complete, K=4") +
  theme_bw() +
  theme(legend.position = "bottom")
```


```{r}
set.seed(101)
# Se simulan datos aleatorios con dos dimensiones
datos <- matrix(rnorm(n = 100*2), nrow = 100, ncol = 2, dimnames = list(NULL,c("x", "y")))
datos <- as.data.frame(datos)

# Se determina la media que va a tener cada grupo en cada una de las dos
# dimensiones. En total 2*4 medias. Este valor se utiliza para separar
# cada grupo de los demás.
media_grupos <- matrix(rnorm(n = 8, mean = 0, sd = 4), nrow = 4, ncol = 2,
                       dimnames = list(NULL, c("media_x", "media_y")))
media_grupos <- as.data.frame(media_grupos)
media_grupos <- media_grupos %>% mutate(grupo = c("a","b","c","d"))

# Se genera un vector que asigne aleatoriamente cada observación a uno de
# los 4 grupos
datos <- datos %>% mutate(grupo = sample(x = c("a","b","c","d"), size = 100, replace = TRUE))

# Se incrementa el valor de cada observación con la media correspondiente al
# grupo asignado.
library(dplyr)
datos <- left_join(datos, media_grupos, by = "grupo")
datos <- datos %>% mutate(x = x + media_x,
                          y = y + media_y)
datos <- datos %>% select(grupo, x, y)
ggplot(data = datos, aes(x = x, y = y, color = grupo)) +
  geom_point(size = 2.5) +
  theme_bw()
```



```{r}
# Se calculan las distancias
matriz_distancias <- dist(x = datos[, c("x", "y")], method = "euclidean")
set.seed(567)
hc_euclidea_completo <- hclust(d = matriz_distancias, method = "complete")
hc_euclidea_single   <- hclust(d = matriz_distancias, method = "single")
hc_euclidea_average  <- hclust(d = matriz_distancias, method = "average")
```


```{r}
par(mfrow = c(3,1))
plot(x = hc_euclidea_completo, cex = 0.6, xlab = "", ylab = "", sub = "",
     main = "Distancia euclídea, Linkage complete")
plot(x = hc_euclidea_single, cex = 0.6, xlab = "", ylab = "", sub = "",
     main = "Distancia euclídea, Linkage single")
plot(x = hc_euclidea_average, cex = 0.6, xlab = "", ylab = "", sub = "",
     main = "Distancia euclídea, Linkage average")
```
```{r}
plot(x = hc_euclidea_completo, cex = 0.6, sub = "",
     main = "Distancia euclídea, Linkage complete, k=4",
     xlab = "", ylab = "", labels = datos[, "grupo"])
abline(h = 6, lty = 2)

table(cutree(hc_euclidea_completo, h = 6), datos[, "grupo"])
```















