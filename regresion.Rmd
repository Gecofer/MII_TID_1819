---
title: "regresion"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Lectura de datos

```{r}
datos_train <- read.csv(file="datos/datos_train_preprocesado.csv")
View(datos_train)

datos_test <- read.csv(file="datos/datos_test_preprocesado.csv")
View(datos_test)
```

Nuestro modelo de regresión, solo tiene variables discretass, por lo que sería de clasificación, ver eso en el tema 5.


# Regresión Multiclase

Hay que tener cuidado con la regresión, porque esta, muy relacionada con la correlación, debemos tener claro que lo nuestro son variables categoricas.



## Regresión Lineal

Regresión lineal con variables categóricas

https://rpubs.com/Diego_Koz/326716

Regresión lineal
con el comando lm() podemos ajustar el modelo. Algunos parametros importantes de esta función son:

formula: definimos el modelo como _ Y ~ X _.
regresion multiple: y ~ X1+X2+...Xn.
regresión polinómica: y ~ poly(x = X, degree = k)
interacción de variables: y ~ X1∗X2. Si sólo queremos el término de interacción: X1:X2
data : especificamos el dataset a utilizar
subset : si dividimos la muestra en training y testing, podemos indicar el subconjunto de entrenamiento con un vector que indique sus números de fila



Calcular el coeficiente de correlacióon simple usado para medir la relación lineal entre dos variables (ver lo del coeficiente de correlacion lineal, calcular la R al cuadradro)

https://rpubs.com/Joaquin_AR/254575

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_lineal <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(datos_test), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=datos_test$ratingLabel)) # Calculamos Etest
  
  Etest = mean(predTst != datos_test$ratingLabel) 
  
  list(Etest=Etest)
}

# Creamos el modelo
# la etiqueta tiene que estar entre 0 y 1
lm_effects = lm(data = datos_train, formula = ratingLabel ~ sideEffectsInverse)
summary(lm_effects)
errorres_regresion_lineal(lm_effects)

lm_effectiveness = lm(data = datos_train, formula = ratingLabel ~ effectivenessNumber)
errorres_regresion_lineal(lm_effectiveness)

# # Detección y visualización de observaciones influyentes
require(car)
influencePlot(lm_effectiveness)
```

```{r}
# para effects

# Obtenemos las probabilidades
prob_LM_effects = predict(lm_effects, data.frame(datos_test), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Lineal - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_LM_effects, datos_test$ratingLabel)

```

```{r}
# para effects

# Obtenemos las probabilidades
prob_LM_effectiveness = predict(lm_effectiveness, data.frame(datos_test), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Lineal - Efectividad", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_LM_effectiveness, datos_test$ratingLabel)

```


## Regresión Lineal Múltiple

https://rpubs.com/Joaquin_AR/226291

No porque no se puede hacer correlación

Pero no sé de que serviría juntar estas.

```{r}
modelo <- lm(ratingLabel ~ poly(sideEffectsInverse,3) + effectivenessNumber, data = datos_train)
summary(modelo)

# https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple
step(modelo, direction = "both", trace = 1)

errorres_regresion_lineal(modelo)
# no se ha sido excluido en el proceso de selección a ninguna variable.
```

```{r}
# Matriz de correlación entre predictores.
library(corrplot)
corrplot(cor(dplyr::select(datos_train, ratingLabel, sideEffectsInverse,effectivenessNumber)),
         method = "number", tl.col = "black")
```


## Regresión Multivariante 

Creo que esta regresión es la regresión lineal Múltiple


## Regresión Logística 

La regresión logística se usa para predecir la probabilidad de ocurrencia de una variable binaria. Es decir para predecir la probabilidad de pertenencia o no a una determinada clase (fallo no-fallo, pago impago etc.) es muy usada en control de calidad y en análisis de riesgo.

https://stackoverrun.com/es/q/3252973

```{r}

# cuantos medicamentos dicen que son efectivos pero no lo son

# Función que calcula los errores y E_test para regresión logística
errorres_regresion_logistica <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(datos_test), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=datos_test$ratingLabel)) # Calculamos Etest
  
  Etest = mean(predTst != datos_test$ratingLabel) 
  
  list(Etest=Etest)
}

# Creamos el modelo
# la etiqueta tiene que estar entre 0 y 1
gml_effects = glm(ratingLabel ~ sideEffectsNumber, family = binomial(logit), data = datos_train)

errorres_regresion_logistica(gml_effects)

gml_effectiveness = glm(ratingLabel ~ effectivenessNumber, family = binomial(logit), data = datos_train)
errorres_regresion_logistica(gml_effectiveness)

## guardar en una variable 

```

```{r}
# para effects

# Ponderaciones



# Obtenemos las probabilidades
prob_GLM_effects = predict(gml_effects, data.frame(datos_test), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Logística - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effects, datos_test$ratingLabel)

```

```{r}
# para effects

# Obtenemos las probabilidades
prob_GLM_effectiveness = predict(gml_effectiveness, data.frame(datos_test), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Logística - Efectividad", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effectiveness, datos_test$ratingLabel)

```

```{r}

```



## Regresión Polinomial - Simple

 En algunos casos, la verdadera relación entre la variable respuesta y los predictores puede no ser lineal, por lo que podemos aplicar por ejemplo una regresión polinomial (existen métodos más complejos). Una forma simple de incorporar asociaciones no lineales en un modelo lineal es incluir versiones transformadas de los predictores, elevándolos a distintas potencias, evitando un exceso de grados para evitar el sobreajuste o overfitting.

https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple


https://rpubs.com/Joaquin_AR/250069

```{r}
# CÁLCULO DEL MODELO POLINÓMICO DE GRADO 4
# ----------------------------------------
modelo_poli4 <- lm(ratingLabel ~ poly(sideEffectsInverse, 4), data = datos_train)
summary(modelo_poli4)

# INTERPOLACIÓN DE PUNTOS DENTRO DEL RANGO DEL PREDICTOR
# -----------------------------------------------------------------------------
limites <- range(datos_train$sideEffectsInverse)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos <- data.frame(sideEffectsInverse = nuevos_puntos)

# PREDICCIÓN DE LA VARIABLE RESPUESTA Y DEL ERROR ESTÁNDAR
# -----------------------------------------------------------------------------
predicciones <- predict(modelo_poli4, newdata = nuevos_puntos, se.fit = TRUE,
                        level = 0.95)

# CÁLCULO DEL INTERVALO DE CONFIANZA SUPERIOR E INFERIOR 95%
# -----------------------------------------------------------------------------
intervalo_conf <- data.frame(inferior = predicciones$fit -
                                        1.96*predicciones$se.fit,
                             superior = predicciones$fit +
                                        1.96*predicciones$se.fit)

attach(datos_train)
plot(x = sideEffectsInverse, y = ratingLabel, pch = 20, col = "darkgrey")
title("Polinomio de grado 4: ratingLabel ~ sideEffectsInverse")
lines(x = nuevos_puntos$sideEffectsInverse, predicciones$fit, col = "red", pch = 20)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$inferior, col = "blue", pch = 4)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$superior, col = "blue", pch = 4)
```




## Regularicion

Rigde regression
Lasso regresion

https://www.r-bloggers.com/ridge-regression-and-the-lasso/

```{r}
install.packages("glmnet")
library(glmnet)

swisslm <- lm(ratingLabel ~ sideEffectsInverse+effectivenessNumber, data = datos_train)
coef(swisslm)

ridge.mod <- glmnet(x, y, alpha = 0, lambda = lambda)
predict(ridge.mod, s = 0, exact = T, type = 'coefficients')[1:6,]

```

# Conclusiones