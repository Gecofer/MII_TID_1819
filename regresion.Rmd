---
title: "regresion"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Lectura de datos

```{r}
datos_train_preprocesados <- read.csv(file="datos/datos_train_preprocesado.csv")
View(datos_train_preprocesados)

datos_test_preprocesados <- read.csv(file="datos/datos_test_preprocesado.csv")
View(datos_test_preprocesados)
```

Nuestro modelo de regresión, solo tiene variables discretass, por lo que sería de clasificación, ver eso en el tema 5.


# Regresión 

La regresión es un modelo de predicción de variables continuas, habitualmente las variables independientes tambien son continuas o al menos numéricas. Hay que tener cuidado con la regresión, porque esta, muy relacionada con la correlación, debemos tener claro que lo nuestro son variables categóricas..., es discreta, booleana, nominal etc.

Calcular el coeficiente de correlacióon simple usado para medir la relación lineal entre dos variables (ver lo del coeficiente de correlacion lineal, calcular la R al cuadradro)

https://rpubs.com/Diego_Koz/326716
https://rpubs.com/Joaquin_AR/254575

Antes de nada, vamos a quitar los fármacos que se repiten, para así predecir los fármacos:

```{r}
datos_train2 <- datos_train_preprocesados[c(11,9,12)]

# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r
nombres_farmacos <- unique(datos_train_preprocesados[,1])

length(nombres_farmacos)

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" y "effectivenessNumber".

datos_procesados_train <- matrix(ncol=3, nrow=length(nombres_farmacos))

for(i in 1:length(nombres_farmacos)){
  #print("iiteracion nueva")
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_train2[which(datos_train_preprocesados$urlDrugName == nombres_farmacos[i]),]

  datos_farmaco = filas_farmaco[1,]
  
  # datos_procesados[i,] <- c(rating, side_effect, effectiveness)
  #print(dim(datos_farmaco))
  
  #print(dim(datos_procesados[1,] ))
  datos_procesados_train[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
  }

data_train_procesado <- data.frame(datos_procesados_train)
rownames(data_train_procesado) <- nombres_farmacos
colnames(data_train_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")

View(data_train_procesado)

# Nos quedamos con los data_train_procesado
```


```{r}
datos_test2 <- datos_test_preprocesados[c(11,9,12)]

# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r
nombres_farmacos <- unique(datos_test_preprocesados[,1])

length(nombres_farmacos)

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" y "effectivenessNumber".

datos_procesados_test <- matrix(ncol=3, nrow=length(nombres_farmacos))

for(i in 1:length(nombres_farmacos)){
  #print("iiteracion nueva")
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_test2[which(datos_test_preprocesados$urlDrugName == nombres_farmacos[i]),]

  datos_farmaco = filas_farmaco[1,]
  
  # datos_procesados[i,] <- c(rating, side_effect, effectiveness)
  #print(dim(datos_farmaco))
  
  #print(dim(datos_procesados[1,] ))
  datos_procesados_test[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_test_procesado <- data.frame(datos_procesados_test)
rownames(data_test_procesado) <- nombres_farmacos
colnames(data_test_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")

View(data_test_procesado)

# Nos quedamos con los data_test_procesado
```

## Regresión Lineal Simple

Regresión lineal con variables categóricas

Con el comando lm() podemos ajustar el modelo. Algunos parametros importantes de esta función son:

- formula: definimos el modelo como: $Y ~ X$.
  - regresion multiple: $y ~ X1+X2+...Xn$.
  - regresión polinómica: $y ~ poly(x = X, degree = k)$
  - interacción de variables: $y ~ X1∗X2$. Si sólo queremos el término de interacción: X1:X2
- data : especificamos el dataset a utilizar
- subset : si dividimos la muestra en training y testing, podemos indicar el subconjunto de entrenamiento con un vector que indique sus números de fila

```{r}
predictionData <- list("sunny sunny sunny rainy rainy", "rainy sunny rainy rainy", "hello", "", "this is another rainy world") 
predictionData
```


```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_lineal <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) # Calculamos Etest
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  list(Etrain=Etrain, Etest=Etest)
}

# Creamos el modelo
# la etiqueta tiene que estar entre 0 y 1
lm_effects = lm(data = data_train_procesado, formula = ratingLabel ~ sideEffectsInverse)
# summary(lm_effects)
errorres_regresion_lineal(lm_effects)

lm_effectiveness = lm(data = data_train_procesado, formula = ratingLabel ~ effectivenessNumber)
errorres_regresion_lineal(lm_effectiveness)
```

```{r}
# para effects
# Obtenemos las probabilidades
prob_LM_effects = predict(lm_effects, data.frame(data_test_procesado), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Lineal - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_LM_effects, data_test_procesado$ratingLabel)
```

```{r}
# para effects

# Obtenemos las probabilidades
prob_LM_effectiveness = predict(lm_effectiveness, data.frame(data_test_procesado), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Lineal - Efectividad", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_LM_effectiveness, data_test_procesado$ratingLabel)

```

### Casos atípicos

La visualización gráfica de las influencias se obtiene del siguiente modo:

https://www.rdocumentation.org/packages/car/versions/3.0-2/topics/influencePlot
https://www.institutomora.edu.mx/testU/SitePages/martinpaladino/modelos_lineales_con_R.html

```{r}
# Detección y visualización de observaciones influyentes
# Para sideEffectsInverse

require(car)
influencePlot(lm_effects, xlab="Hat-Values", ylab="Studentized Residuals")
```

```{r}
# Detección y visualización de observaciones influyentes
# Para effectivenessNumber
require(car)
influencePlot(lm_effectiveness, xlab="Hat-Values", ylab="Studentized Residuals")
```


## Regresión Robusta

Una alternativa para controlar casos atípicos es ajustar una modelo lineal robusto. Los modelos lineales robustos utilizan criterios diferentes al de los mínimos cuadrados y ponderan la influencia de los casos atípicos, por lo que producen coeficientes y -sobre todo- errores estandar más confiables. El paquete MASS:: incluye la función rlm(), de sintaxis similar a lm() que implementa el método M para el ajuste de los coeficientes y cálculo de los errores estándar.

https://www.institutomora.edu.mx/testU/SitePages/martinpaladino/modelos_lineales_con_R.html

```{r}
# Para sideEffectsInverse
library(rlm)
rlm_effects = MASS::rlm(ratingLabel ~ sideEffectsInverse, data = data_train_procesado)
# summary(lm_effects)
library(stargazer)
stargazer(lm_effects, rlm_effects, type = "text", model.numbers = FALSE, title="Comparación de modelo OLS y Robusto")
```

```{r}
# Para effectivenessNumber
library(rlm)
rlm_effectiveness = MASS::rlm(ratingLabel ~ effectivenessNumber, data = data_train_procesado)
# summary(lm_effects)
library(stargazer)
stargazer(lm_effectiveness, rlm_effectiveness, type = "text", model.numbers = FALSE, title="Comparación de modelo OLS y Robusto")
```


## Regresión Lineal Múltiple

https://rpubs.com/Joaquin_AR/226291

No porque no se puede hacer correlación

Pero no sé de que serviría juntar estas.

```{r}
lm_multiple <- lm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)
summary(lm_multiple)

# https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple
# nos dice si existe alguna variable que estamos usando que no nos hace falta
step(modelo, direction = "both", trace = 1)

errorres_regresion_lineal(lm_multiple)
# no se ha sido excluido en el proceso de selección a ninguna variable.
```

```{r}
# Matriz de correlación entre predictores.
library(corrplot)
corrplot(cor(dplyr::select(data_train_procesado, ratingLabel, sideEffectsInverse,effectivenessNumber)),
         method = "number", tl.col = "black")
```


## Regresión Logística Simple

La regresión logística se usa para predecir la probabilidad de ocurrencia de una variable binaria. Es decir para predecir la probabilidad de pertenencia o no a una determinada clase (fallo no-fallo, pago impago etc.) es muy usada en control de calidad y en análisis de riesgo.

https://stackoverrun.com/es/q/3252973

```{r}
# cuantos medicamentos dicen que son efectivos pero no lo son

# Función que calcula los errores y E_test para regresión logística
errorres_regresion_logistica <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) # Calculamos Etest
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  list(Etrain=Etrain, Etest=Etest)
}

# Creamos el modelo
# la etiqueta tiene que estar entre 0 y 1
gml_effects = glm(ratingLabel ~ sideEffectsInverse, family = binomial(logit), data = data_train_procesado)
errorres_regresion_logistica(gml_effects)

gml_effectiveness = glm(ratingLabel ~ effectivenessNumber, family = binomial(logit), data = data_train_procesado)
errorres_regresion_logistica(gml_effectiveness)

## guardar en una variable 
```

```{r}
# para gml_effects

# Ponderaciones
# Obtenemos las probabilidades
prob_GLM_effects = predict(gml_effects, data.frame(data_test_procesado), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Logística - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effects, data_test_procesado$ratingLabel)

```

```{r}
# para gml_effectiveness

# Obtenemos las probabilidades
prob_GLM_effectiveness = predict(gml_effectiveness, data.frame(data_test_procesado), type=c("response"))

# Función que dibuja uan curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC - Regresión Logística - Efectividad", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effectiveness, data_test_procesado$ratingLabel)

```


## Regresión Logística Multiple

```{r}
modelo <- glm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)
summary(modelo)

# https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple
step(modelo, direction = "both", trace = 1)

errorres_regresion_logistica(modelo)
# no se ha sido excluido en el proceso de selección a ninguna variable.
```


## Regresión Polinomial

```{r}
# Hacemos uso del poly para 2, en donde no usamos otra grado, porque no se obtiene mejora
lm = lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2) + effectivenessNumber)
errorres_regresion_lineal(lm)
```

En algunos casos, la verdadera relación entre la variable respuesta y los predictores puede no ser lineal, por lo que podemos aplicar por ejemplo una regresión polinomial (existen métodos más complejos). Una forma simple de incorporar asociaciones no lineales en un modelo lineal es incluir versiones transformadas de los predictores, elevándolos a distintas potencias, evitando un exceso de grados para evitar el sobreajuste o overfitting.

https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple

https://rpubs.com/Joaquin_AR/250069

```{r}
# CÁLCULO DEL MODELO POLINÓMICO DE GRADO 4
# ----------------------------------------
modelo_poli2 <- lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2))
summary(modelo_poli2)

# INTERPOLACIÓN DE PUNTOS DENTRO DEL RANGO DEL PREDICTOR
# -----------------------------------------------------------------------------
limites <- range(data_train_procesado$sideEffectsInverse)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos <- data.frame(sideEffectsInverse = nuevos_puntos)

# PREDICCIÓN DE LA VARIABLE RESPUESTA Y DEL ERROR ESTÁNDAR
# -----------------------------------------------------------------------------
predicciones <- predict(modelo_poli2, newdata = nuevos_puntos, se.fit = TRUE,
                        level = 0.95)

# CÁLCULO DEL INTERVALO DE CONFIANZA SUPERIOR E INFERIOR 95%
# -----------------------------------------------------------------------------
intervalo_conf <- data.frame(inferior = predicciones$fit -
                                        1.96*predicciones$se.fit,
                             superior = predicciones$fit +
                                        1.96*predicciones$se.fit)

attach(datos_train)
plot(x = sideEffectsInverse, y = ratingLabel, pch = 20, col = "darkgrey")
title("Polinomio de grado 2: ratingLabel ~ sideEffectsInverse")
lines(x = nuevos_puntos$sideEffectsInverse, predicciones$fit, col = "red", pch = 20)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$inferior, col = "blue", pch = 4)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$superior, col = "blue", pch = 4)
```


### Regularización en Regresión Logística

En este apartado vamos a ajustar un modelo a través de la Regresión Logística con regularización meidante la técnica Lasso Regression o con Ridge Regression. Ambas se explican a continuación:


#### Ridge Regression

Esta ténica, en esencia, es la Regresión Lineal con Weight Decay que utilizamos en la Práctica 2, y cuya
fórmula es: (XTX + lambdaI)-1 *XˆT. Es el parámetro lambda, el que en función de su valor, marca el equilibrio
entre los componentes de sesgo y varianza. Cuanto mayor sea su valor, mayor sesgo pero menor varianza. Es
decir, cuanto mayor valor tenga lambda, mayor penalización y mayor reducción se les aplica a los valores de
los coeficientes.

#### Lasso Regression

```{r}
# Ajustamos un modelo a través de Regresión Logística multiclase
library(caret)
library(e1071)
modelbest = train(form=as.factor(ratingLabel) ~ sideEffectsInverse + effectivenessNumber, data=data_train_procesado, method="glmnet", family="binomial")

modelbest$bestTune$alpha
modelbest$bestTune$lambda
```

```{r}
##### CONJUNTO DE TRAIN ####
# Primero generamos una matriz con el conjunto de train separando las etiquetas de los datos
x = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, data_train_procesado)[,-ncol(data_train_procesado)]
y = data_train_procesado$ratingLabel
##### CONJUNTO DE TEST ####
x.test = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, data_test_procesado)[,-ncol(data_test_procesado)]
y.test = data_test_procesado$ratingLabel
# Reproducimos el modelo ajustado con el mejor lambda y el mejor alpha
ridge.mod = glmnet(x=x, y=y, family="binomial", alpha=modelbest$bestTune$alpha,lambda=modelbest$bestTune$lambda,thresh=1e-12)

# Calculamos la predicción
predicciones.ridge = predict(ridge.mod, s=ridge.mod$lambda, newx=x.test, type="response")
# Error de regresión con penalización Ridge
error.ridge = mean (( predicciones.ridge - y.test)^2)
cat("Eout con la técnica Ridge Regression: ",error.ridge*100,"%\n")
```


## Regularicion


```{r}
require(glmnet)
# Data = considering that we have a data frame named dataF, with its first column being the class
x <- as.matrix(data_train_procesado[,-1]) # Removes class
y <- as.double(as.matrix(data_train_procesado[, 1])) # Only class

# Fitting the model (Ridge: Alpha = 0)
set.seed(999)
cv.ridge <- cv.glmnet(x, y, family='binomial', alpha=0, parallel=TRUE, standardize=TRUE, type.measure='auc')

# Results
plot(cv.ridge)
cv.ridge$lambda.min
cv.ridge$lambda.1se
coef(cv.ridge, s=cv.ridge$lambda.min)
```


# Conclusiones