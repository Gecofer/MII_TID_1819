---
title:
author:
- "Alejandro Campoy Nieves"
- "Gema Correa Fern√°ndez"
- "Luis Gallego Quero"
- "Jonathan Mart√≠n Valera"
- "Andrea Morales Garz√≥n"
date: "14 de noviembre de 2018"
output:
  pdf_document:
    keep_tex: true
lang: es-ES
geometry: margin=1in
header-includes:
  - \usepackage{fancyhdr}
  - \fancyfoot[CO,CE]{My footer}
---

<!----------------------------------------------------------------Portada------------------------------------------------------------------>
####################
\thispagestyle{empty}

\begin{center} \huge \textbf{Tratamiento Inteligente de datos} \end{center}
\vspace{0.3cm}
\begin{center} \huge \textbf{(TID)} \end{center}
\vspace{1.7cm}
\begin{center} \Large \textbf{\textsc{Pr√°cticas de la asignatura}} \end{center}
\vspace{0.2cm}
\begin{center} \large \textbf{2018-2019} \end{center}

\vspace{2.5cm}

\textbf{\large En colaboraci√≥n con:}
\vspace{0.2cm}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{imagenes/logoUGR.jpg}
    \label{imagen2}
\end{figure}

\vspace{2.5cm}

\hspace{8.5cm}{\large \textbf{Participantes}}

\vspace{0.25cm}

\hspace{8.5cm}{Alejandro Campoy Nieves:  \href{mailto:alejandroac79@correo.ugr.es}{\textcolor{blue}{\underline{alejandroac79@correo.ugr.es}}}}

\vspace{0.15cm}

\hspace{8.5cm}{Gema Correa Fern√°ndez:  \href{mailto:gecorrea@correo.ugr.es}{\textcolor{blue}{\underline{gecorrea@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Luis Gallego Quero:  \href{mailto:lgaq94@correo.ugr.es}{\textcolor{blue}{\underline{lgaq94@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Jonathan Mart√≠n Valera:  \href{mailto:jmv742@correo.ugr.es}{\textcolor{blue}{\underline{jmv742@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Andrea Morales Garz√≥n:  \href{mailto:andreamgmg@correo.ugr.es}{\textcolor{blue}{\underline{andreamgmg@correo.ugr.es}}} }

\vspace{0.15cm}

\newpage

<!----------------------------------------------------------------Indices------------------------------------------------------------------>
####################
\thispagestyle{empty}
\tableofcontents
\newpage

\thispagestyle{empty}
\listoffigures
\newpage

\thispagestyle{empty}
\listoftables
\newpage

\pagestyle{fancy}
\fancyhf{}
\lhead{Proyecto: T√©cnicas aplicadas para an√°lisis inteligente de datos}
\rhead{\thepage}
\setcounter{page}{1}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(3) # semilla para obtenci√≥n de los mismos resultados
getwd()     # para saber el directorio de trabajo
```

<!-----------------------------------------1. Comprender el problema a resolver------------------------------------------------------>

<!--------------------------------------------1. Comprender el problema a resolver--------------------------------------------------------->
# 1. Comprender el problema a resolver

Para la realizaci√≥n y aplicaci√≥n de las t√©cnicas explicadas a lo largo del curso, hemos seleccionado un _dataset_ proporcionado por [*UCI Machine Learning Repository*](https://archive.ics.uci.edu/ml/index.php). En concreto, hemos escogido [**Drug Review Dataset**](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29), una exhaustiva base de datos de medicamentos organizada por relevancia para medicamentos espec√≠ficos. El conjunto de datos proporciona revisiones de pacientes sobre medicamentos espec√≠ficos junto con las condiciones relacionadas. Adem√°s, las revisiones se agrupan en informes sobre tres aspectos: beneficios, efectos secundarios y comentarios generales. De igual modo, las calificaciones est√°n disponibles con respecto a la satisfacci√≥n general, as√≠ como una calificaci√≥n de efectos secundarios y de eficacia de 5 pasos. Los datos se obtuvieron rastreando los sitios de revisi√≥n farmac√©utica en l√≠nea.

El objetivo principal del estudio es:

 - Realizar un an√°lisis de sentimientos en relaci√≥n con la experiencia en el uso de dichos medicamentos, como por ejemplo la efectividad, efectos secundarios...
 
 - Compatibilizar dicho modelo de datos con otros conjuntos de datos aportados en: [**Drugs.com**](https://www.drugs.com/)
 
En este proyecto nos centraremos en el **an√°lisis y experiencia de los usuarios** en el uso de los distintos medicamentos.

Las caracter√≠sticas de este conjunto de datos vienen descritas en la siguiente tabla:

<!--- Tabla --->

| DataSet Characteristics:   | Multivariate, Text                     | Number of Instances:  | 4143 | Area:               | N/A        |
|----------------------------|----------------------------------------|-----------------------|------|---------------------|------------|
| Attribute Characteristics: | Integer                                | Number of Attributes: | 8    | Date Donated        | 2018-10-02 |
|----------------------------|----------------------------------------|-----------------------|------|---------------------|------------|
| Associated Tasks:          | Classification, Regression, Clustering | Missing Values?       | N/A  | Number of Web Hits: | 7001       |

Los datos se dividen en un conjunto train (75%) y otro conjunto test (25%) y se almacenan en dos archivos.tsv (tab-separated-values), respectivamente. Los atributos que tenemos en este dataset son:

1. **urlDrugName** (categorical): nombre de la droga
2. **condition** (categorical): nombre de la condici√≥n
3. **benefitsReview** (text): paciente sobre beneficios
4. **sideEffectsReview** (text): paciente sobre los efectos secundarios
5. **commentsReview** (text): comentario general del paciente
6. **rating** (numerical): clasificaci√≥n de paciente de 10 estrellas
7. **sideEffects** (categorical): clasificaci√≥n de 5 pasos de efectos secundarios
8. **effectiveness** (categorical): clasificaci√≥n de efectividad de 5 pasos


<!--------------------------------------------2. Prepocesamiento de datos------------------------------------------------------------>

# 2. Prepocesamiento de datos

Para poder analizar el dataset y realizar el prepocesamiento al mismo, lo primero que se va hacer es leer tanto el conjunto de datos train como de test. Primero, leeremos los datos con los que se va a entrenar y luego los datos test.

## 2.1. Lectura de datos

A continuaci√≥n, leemos nuestro dataset train y test:

```{r lectura }
# Lectura de datos train
datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",
                          quote = "\"", header=TRUE)
head(datos_train, 5) # visualizar las 5 primeras filas
summary(datos_train) # informaci√≥n sobre los datos
View(datos_train)    # vista de la tabla

# Lectura de datos test
datos_test <- read.table("./datos/drugLibTest_raw.tsv", sep="\t", comment.char="",
                         quote = "\"", header=TRUE)
head(datos_test, 5) # visualizar las 5 primeras filas
summary(datos_test) # informaci√≥n sobre los datos
View(datos_test)    # vista de la tabla
```

## 2.2. Falta de datos, categorizaci√≥n, normalizaci√≥n, reducci√≥n de dimensionalidad.

<!--- Borrar si a√±g√∫n atributo no nos da informaci√≥n como un ID, hacer una transformaci√≥n con los atributos asim√©tricos, ya que son necesarios para la aplicaci√≥n de algunos m√©todos de aprendizaje sensibles a distancias. Se consideran asim√©tricos cuando el valor skewness se aleja de 0, podemos eliminar las variables con varianza 0 o muy pr√≥ximas. --->


```{r}
# Procesar datos

# 1. Eliminamos la columna del ID. Esa columna es la n˙mero 1, por tanto la quitamos directamente del data_frame
datos_test = datos_test[-1]


```


```{r}

# 2. Primero tenemos que usar la librerÌa que procese los datos de tipo texto en R. La m·s conocida se llama tm. Si no la tenemos instalada en R, tnemos que hacerlo previamente. Para eso hacemos:
# install.packages("tm")
library("tm")

# 3. Los datos que vamos a leer se cargan haciendo un vector de mensajitos. Para eso, nos creamos un vector de documentos a partir de un vector de string. Podemos usar la funciÛn VectorSource para hacer esta conversiÛn.

# Nos quedamos con la ˙nica columna del dataset que nos interesa. Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, por lo que usamos asvector para hacer la conversiÛn
beneficts_review_data = as.vector(datos_test$benefitsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus que lo vamos a utilizar.
corpus = (VectorSource(beneficts_review_data))

# Creamos el propio corpus
corpus <- Corpus(corpus)
#summary(corpus)


# Podemos ver que funciona accediendo a uno cualquiera. Si nos fijamos en el contenido, vemos que tiene signos de puntuaciÛn y exclamaciÛn.
inspect(corpus[4])
corpus[[4]]$content

# 4. Una vez que tenemos el corpus creado, continuamos con el procesamiento. En data mining no tiene sentido contemplar los signos de puntuaciÛn, por lo que los quitamos.
corpus <- tm_map(corpus, content_transformer(removePunctuation))

# Si volvemos a mostrar la opiniÛn cuarta, vemos como todos los signos han desaparecido. De hecho, podemos inspeccionar el corpus, y se ve como todos los signos de puntuaciÛn, exclamaciÛn y derivados ya no est·n.
inspect(corpus[4])

# 5. Stopwords. En cualquier idioma, hay palabras tan tan tan comunes que no nos aportan informaciÛn relevante. Por ejemplo, en espaÒol, las palabras "la", "a", "en", "de" son ejemplos de lo que se conoce como Stopwords. Este tipo de palabras, tenemos que suprimirlas de nuestro corpus. Como el contenido del corpus est· en inglÈs, debemos especificar el idioma para que nos elimine del corpus las palabras adecuadas. 
corpus <- tm_map(corpus, content_transformer(removeWords), 
          stopwords("english"))

```

