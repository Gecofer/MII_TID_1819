---
title:
author:
- "Alejandro Campoy Nieves"
- "Gema Correa Fernández"
- "Luis Gallego Quero"
- "Jonathan Martín Valera"
- "Andrea Morales Garzón"
date: "14 de noviembre de 2018"
output:
  pdf_document:
    keep_tex: true
lang: es-ES
geometry: margin=1in
header-includes:
  - \usepackage{fancyhdr}
  - \fancyfoot[CO,CE]{My footer}
  - \usepackage{color}
  - \usepackage{colortbl}
  - \usepackage{multicol}
  - \usepackage{multirow}
---

<!-------------------------------------------------------------Portada------------------------------------------------------------->

\thispagestyle{empty}

\begin{center} \huge \textbf{Tratamiento Inteligente de datos} \end{center}
\vspace{0.3cm}
\begin{center} \huge \textbf{(TID)} \end{center}
\vspace{1.7cm}
\begin{center} \Large \textbf{\textsc{Prácticas de la asignatura}} \end{center}
\vspace{0.2cm}
\begin{center} \large \textbf{2018-2019} \end{center}

\vspace{2.5cm}

\textbf{\large En colaboración con:}
\vspace{0.2cm}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{imagenes/logoUGR.jpg}
    \label{imagen2}
\end{figure}

\vspace{2.5cm}

\hspace{8.5cm}{\large \textbf{Participantes}}

\vspace{0.25cm}

\hspace{8.5cm}{Alejandro Campoy Nieves:  \href{mailto:alejandroac79@correo.ugr.es}{\textcolor{blue}{\underline{alejandroac79@correo.ugr.es}}}}

\vspace{0.15cm}

\hspace{8.5cm}{Gema Correa Fernández:  \href{mailto:gecorrea@correo.ugr.es}{\textcolor{blue}{\underline{gecorrea@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Luis Gallego Quero:  \href{mailto:lgaq94@correo.ugr.es}{\textcolor{blue}{\underline{lgaq94@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Jonathan Martín Valera:  \href{mailto:jmv742@correo.ugr.es}{\textcolor{blue}{\underline{jmv742@correo.ugr.es}}} }

\vspace{0.15cm}

\hspace{8.5cm}{Andrea Morales Garzón:  \href{mailto:andreamgmg@correo.ugr.es}{\textcolor{blue}{\underline{andreamgmg@correo.ugr.es}}} }

\vspace{0.15cm}

\newpage

<!------------------------------------------------------------Indices--------------------------------------------------------------->

\thispagestyle{empty}
\tableofcontents
\newpage

\thispagestyle{empty}
\listoffigures
\newpage

\thispagestyle{empty}
\listoftables
\newpage

\pagestyle{fancy}
\fancyhf{}
\lhead{Proyecto: Técnicas aplicadas para análisis inteligente de datos}
\rhead{\thepage}
\setcounter{page}{1}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(3) # semilla para obtención de los mismos resultados
getwd()     # para saber el directorio de trabajo
```

```{r, include=FALSE}
source("librerias.R")
```

<!-----------------------------------------0. Paquetes necesarios ------------------------------------------------------>

# Descripción de los paquetes necesarios

A continuación, se describen los paquetes necesarios para el desarollo del proyecto:

- [`arules`](https://cran.r-project.org/web/packages/arules/arules.pdf) : Paquete que proporciona la infraestructura para representar, manipular y analizar datos y patrones de transacción (conjuntos de elementos frecuentes y reglas de asociación). Se puede instalar usando : _install.packages("arules")_.

- [`arulesViz`](https://cran.r-project.org/web/packages/arulesViz/arulesViz.pdf) : Paquete que extiende el paquete 'arules' con varias técnicas de visualización para reglas de asociación y conjuntos de elementos. El paquete también incluye varias visualizaciones interactivas para la exploración de reglas. Se puede instalar usando : _install.packages("arulesViz")_.

- [`car`](https://cran.r-project.org/web/packages/car/car.pdf) : Paquete que nos propociona distintas funciones. : _install.packages("car")_.

- [`cluster`](https://cran.r-project.org/web/packages/cluster/cluster.pdf) : Paquete que nos proporciona métodos para el análisis de clusters.  : _install.packages("cluster")_.

- [`caret`](https://cran.r-project.org/web/packages/caret/caret.pdf) : Paquete para entrenamiento de clasificación y regresión. Se puede instalar usando : _install.packages("quanteda")_.

- [`dbscan`](https://cran.r-project.org/web/packages/dbscan/dbscan.pdf) : Paquete que proporciona implementaciones de varios algoritmos basados en densidad de la familia DBSCAN para datos espaciales. Se puede instalar usando : _install.packages("dbscan")_.

- [`devtools`](https://cran.r-project.org/web/packages/devtools/devtools.pdf) : Paquete que contiene una colección de herramientas de desarrollo de paquetes, usando conjuntamento con `rword2vec`, para obtener la agrupación de sinónimos. Se puede instalar usando : _install.packages("devtools")_.

- [`dplyr`](https://cran.r-project.org/web/packages/dplyr/dplyr.pdf) : Paquete que agiliza el trabajo con los datos. Se puede instalar usando : _install.packages("dplyr")_.

- [`e1071`](https://cran.r-project.org/web/packages/e1071/e1071.pdf) : Paquete para realizar _fuzzy clustering_, clasificador de _Naive Bayes_... Se puede instalar usando : _install.packages("e1071")_.

- [`fclust`](https://cran.r-project.org/web/packages/fclust/fclust.pdf) : Paquete que nos proporciona algoritmos para la agrupación difusa, índices de validez de clusters y gráficos para la validez de estos. Además de la visualización de los resultados de la agrupación difusa. : _install.packages("fclust")_.

- [`factoextra`](https://cran.r-project.org/web/packages/factoextra/factoextra.pdf) : Proporciona algunas funciones sencillas para extraer y visualizar la producción de análisis de datos multivariados. : _install.packages("factoextra")_.

- [`ggpubr`](https://cran.r-project.org/web/packages/ggpubr/ggpubr.pdf) : Paquete que proporciona algunas funciones de fácil manejo para crear y personalizar gráficos listos para ser usados en _ggplot2_. : _install.packages("ggpubr")_.

- [`ggplot2`](https://cran.r-project.org/web/packages/ggplot2/ggplot2.pdf) : Paquete para realizar gráficas. Se puede instalar usando : _install.packages("ggplot2")_.

- [`glmnet`](enlace) : Paquete que nos proporciona rocedimientos eficaces para la adaptación de la red para la regresión lineal, los modelos de regresión logística y multinomial, la regresión de Poisson y el modelo de Cox. : _install.packages("glmnet")_.

- [`igraph`](https://cran.r-project.org/web/packages/igraph/igraph.pdf) : Paquete que nos proporciona procesos para gráficos simples y análisis de redes. Puede manejar gráficos grandes muy bien, gráficos aleatorios y gráficos regulares, además de visualización de estos. : _install.packages("igraph")_.

- [`MASS`](https://cran.r-project.org/web/packages/MASS/MASS.pdf) : Paquete que nos propociona funciones y conjuntos de datos de soporte. : _install.packages("MASS")_.

- [`magrittr`](https://cran.r-project.org/web/packages/magrittr/magrittr.pdf) : Paquete que proporciona un mecanismo para encadenar comandos con \%>\%. Se puede instalar usando : _install.packages("magrittr")_.

- [`NLP`](https://cran.r-project.org/web/packages/NLP/NLP.pdf) : Paquete con clases básicas y métodos para el procesamiento del lenguaje natural. Se puede instalar usando : _install.packages("NLP")_.

- [`ppclust`](https://cran.r-project.org/web/packages/ppclust/ppclust.pdf) : Paquete que nos permite la agrupación de particiones de un conjunto de datos en subconjuntos o clusters no superpuestos mediante el uso de los algoritmos de agrupación probabilística basados en prototipos. : _install.packages("ppclust")_.

- [`plyr`](https://cran.r-project.org/web/packages/plyr/plyr.pdf) : Paquete que nos ofrece herramientas para dividir, aplicar y combinar datos. Se puede instalar usando : _install.packages("plyr")_.

- [`proxy`](https://cran.r-project.org/web/packages/proxy/proxy.pdf) : Paquete que proporciona un _framework_ para cálculo eficiente. Se puede instalar usando : _install.packages("proxy")_. 

- [`quanteda`](https://cran.r-project.org/web/packages/quanteda/quanteda.pdf) : Paquete para análisis cuantitativo de texto en R, usado para gestionar corpus, crear y manipular tokens y n-gramas, analizar palabras clave, etc, representando visualmente el texto y los análisis de texto. Se puede instalar usando : _install.packages("quanteda")_.

- [`rlm`](https://cran.r-project.org/web/packages/rlm/rlm.pdf) : Paquete que nos propociona una adaptación robusta de un modelo lineal que puede responder en forma de matriz. : _install.packages("rlm")_.

- [`rattle`](https://cran.r-project.org/web/packages/rattle/rattle.pdf) : Paquete que permite al usuario cargar rápidamente datos desde un archivo CSV, transformarlos y explorarlos, construir y evaluar modelos, y además, exportarlos. : _install.packages("rattle")_.

- [`randomForest`](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf) : Paquete que nos proporciona clasificación y regresión basada en árboles usando entradas aleatorias. : _install.packages("randomForest")_.

- [`RColorBrewer`](https://cran.r-project.org/web/packages/RColorBrewer/RColorBrewer.pdf) : Paquete que proporciona paletas de colores. Se puede instalar usando : _install.packages("wordcloud")_.

- [`rlist`](https://cran.r-project.org/web/packages/rlist/rlist.pdf) : Paquete que proporciona un conjunto de funciones para la manipulación de datos en forma de lista. Se puede instalar usando : _install.packages("rlist")_.

- [`ROCR`](https://cran.r-project.org/web/packages/ROCR/ROCR.pdf) : Paquete que nos permite hacer uso de gráficos ROC (curva ROC), entre otros. Se puede instalar usando : _install.packages("ROCR")_.

- [`RTextTools`](https://cran.r-project.org/web/packages/RTextTools/RTextTools.pdf) : Paquete para realizar clasificación automática de textos mediante aprendizaje supervisado. Se puede instalar usando : _install.packages("RTextTools")_.

- [`rword2vec`](https://github.com/mukul13/rword2vec) : Paquete que toma un corpus de texto como entrada y produce los vectores de palabra como salida, usado especialmente para obtener las distancias que existen entre un término y los términos semejantes en el texto de formación (aprende la representación vectorial de las palabras). Se puede instalar usando : _install\_github("mukul13/rword2vec")_. 

- [`stargazer`](https://cran.r-project.org/web/packages/stargazer/stargazer.pdf) : Paquete que produce código LaTeX, código HTML/CSS y texto ASCII para tablas bien formateadas que contienen resultados del análisis de regresión de varios modelos en paralelo, así como un resumen de estadísticas. : _install.packages("stargazer")_.

- [`SnowballC`](https://cran.r-project.org/web/packages/SnowballC/SnowballC.pdf) : Paquete adicional para minería de datos, implementa un algoritmo que permite reducir el número de términos con lo que trabajar, es decir, agrupa aquellos términos que contienen la misma raíz. El paquete soporta los siguientes idiomas: alemán, danés, español, finlandés, francés, húngaro, inglés, italiano, noruego, portugués, rumano, ruso, sueco y turco. Se puede instalar usando : _install.packages("SnowballC")_.

- [`tidytext`](https://cran.r-project.org/web/packages/tidytext/tidytext.pdf) : Paquete para minería de textos para procesamiento de textos y análisis de sentimientos usando `dplyr`, `ggplot2`, y otras herramientas ordenadas. Se puede instalar usando : _install.packages("tidytext")_.

- [`tm`](https://cran.r-project.org/web/packages/tm/tm.pdf) : Paquete específico para minería de datos, permite procesar datos de tipo texto. Se puede instalar usando : _install.packages("tm")_.

- [`tseries`](https://cran.r-project.org/web/packages/tseries/tseries.pdf) : Paquete para análisis de series temporales y computación financiera. Se puede instalar usando : _install.packages("tseries")_.

- [`wesanderson`](https://cran.r-project.org/web/packages/wesanderson/wesanderson.pdf) : Paquete que proporciona paletas de colores. Se puede instalar usando : _install.packages("wesanderson")_.

- [`wordcloud`](https://cran.r-project.org/web/packages/wordcloud/wordcloud.pdf) : Paquete para crear gráficas de nubes de palabras, permitiendo visualizar las diferencias y similitudes entre documentos. Se puede instalar usando : _install.packages("wordcloud")_.

\newpage

<!---------------------------- 1. Comprender el problema a resolver ---------------------------------->

# 1. Comprender el problema a resolver

El _dataset_ [**Drug Review Dataset**](https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29), proporcionado por [*UCI Machine Learning Repository*](https://archive.ics.uci.edu/ml/index.php), contiene una exhaustiva base de datos de medicamentos específicos, en la cual, el conjunto de datos muestra revisiones de pacientes sobre medicamentos específicos para unas condiciones particulares. Dichas revisiones se encuentran desglosadas en función del tema que se esté tratando: beneficios, efectos secundarios y comentarios generales. De igual modo, se dispone de una calificación de satisfacción general, es decir, de una calificación en base a los efectos secundarios del medicamento y de otra, en base a la efectividad del mismo.

En este proyecto nos centraremos en el **análisis y experiencia qué tienen los usuarios con ciertos tipos de medicamentos**, para la realización y aplicación de las técnicas explicadas a lo largo del curso. Para ello, se proponen los siguientes objetivos principales:

 - Realizar un análisis de sentimientos a partir de la experiencia de dichos usuarios en el uso de ciertos medicamentos, como por ejemplo ver la efectividad del medicamento cuánto está relacionado con los efectos secundarios o beneficios del mismo.
 
 - Comparar la efectividad o efectos secundarios del medicamento, de acuerdo a la puntuación del medicamento según el paciente.
 
 - Compatibilizar dicho modelo de datos con otros conjuntos de datos aportados en [**Drugs.com**](https://www.drugs.com/).

Las características de este conjunto de datos vienen descritas en la siguiente tabla \ref{tabla:preseleccion}:

<!--- Tabla --->

\begin{table}[h]
	\begin{center}
		\begin{tabular}{|>{\columncolor[rgb]{0.94,0.97,1.0}}l|c|}
			\hline 
			\textbf{Características del Data Set} & Multivariable, texto \\ \hline
			\textbf{Características de los atributos} & Entero \\ \hline
			\textbf{Tareas asociadas} & Clasificación, regresión, clustering \\ \hline
			\textbf{Número de instancias} & 4143 \\ \hline
			\textbf{Número de atributos} & 8 \\ \hline
			\textbf{Valores vacíos} & N/A \\ \hline
			\textbf{Área} & N/A \\ \hline
			\textbf{Fecha de donación} & 10/02/2018 \\ \hline
			\textbf{Veces visualizado} & 16759 \\ \hline
		\end{tabular}
		\caption{Información del conjunto de datos}
		\label{tabla:preseleccion}
	\end{center}
\end{table}

Los datos se dividen en un conjunto train (75%) y otro conjunto test (25%) y se almacenan en dos archivos _.tsv_ (tab-separated-values), respectivamente. Los atributos que tenemos en este dataset son:

1. **urlDrugName** (categorical): nombre del medicamento/fármaco.
2. **rating** (numerical): clasificación o puntuación del 1 a 10 del medicamento según el paciente.
3. **effectiveness** (categorical): clasificación de la efectividad del medicamento según el paciente (5 posibles valores).
4. **sideEffects** (categorical): clasificación de los efectos secundarios del medicamento según el paciente (5 posibles valores).
5. **condition** (categorical): nombre de la condición (diagnóstico).
6. **benefitsReview** (text): opinión del paciente sobre los beneficios.
7. **sideEffectsReview** (text): opinión del paciente sobre los efectos secundarios.
8. **commentsReview** (text): comentario general del paciente.

<!----------------------------2. Preprocesamiento de datos------------------------------------>

# 2. Preprocesamiento de datos

En este apartado, pondremos los datos a punto para la aplicación de diversas técnicas. Por tanto, para poder analizar dicho _dataset_ y realizar el preprocesamiento al mismo, lo primero que se va hacer es leer el conjunto de datos _train_ y _test_. Una vez leídos, se procederán a aplicar las siguientes técnicas con el fin de limpiar los datos:

1. *Lectura del dataset* a usar.
2. *Eliminar las columnas* que no aportan información relevante.
3. *Eliminar las filas* que contienen caracteres raros y perjudican al análisis.
4.  *Eliminar los medicamentos repetidos* en nuestro dataset.
5. *Cuantificación de variables* para la obtención de las columnas con etiquetas numéricas.
6. *Cálculo del rating ponderado* para la obtención de una valoración general del medicamento.
7. *Conversión de rating a variable binaria*, para ser usada como etiqueta.
8. *Cambiar el orden para la columna sideEffectsNumber*, con el fin de obtener el mismo orden en efectividad y efectos secundarios.
9. *Representación gráfica de los datos*.
10. *Creación del corpus* para las columnas benefitsReview y sideEffectsReview.
11. *Correlación* entre las variables del dataset.
12. *Representación gráfica de las frecuencias del Corpus*.
13. *Eliminar signos de puntuación*.
14. *Conversión de mayúsculas a minúsculas*.
15. *Eliminación de palabras no aportan información relevante (stopwords)*.
16. *Agrupación de sinónimos*.
17. Cálculo de la frecuencia de cada término con *TF-IDF*.
18. Reducción de palabras con *stemming*.
19. Obtención y eliminación de *valores perdidos*.
20. *Borrar espacios en blanco* innecesarios.
21. Eliminar los términos que aparecen en muy pocos documentos (*sparsity*).
22. Obtención de la *matriz de términos*.
23. Creación de la *nube de palabras* para las columnas sin y con preprocesamiento.

\newpage 

<!-------------------------------------------------------------------------------------------->

## 2.1. Lectura del dataset

A continuación, mediante la función `read.table(...)` procedemos a la lectura de los datos explicados previamente:

### 2.1.1. Lectura de datos train

Se va a proceder a la lectura del conjunto de datos de entrenamiento.

```{r, warning=FALSE}
# Lectura de datos train
datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",
                          quote = "\"", header=TRUE)
```

Disponemos de una matriz de 3107 filas x 9 columnas, asimismo vamos a ver un ejemplo de cómo está distribuida la información. Por ejemplo, para la tercera fila encontramos la siguiente información:

\begin{table}[h]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{X} & \textbf{urlDrugName} & \textbf{rating} & \textbf{effectiveness} 
      & \textbf{sideEffects} &\textbf{condition} \\ \hline
      1146 & ponstel & 10 & Highly Effective & No Side Effects & menstrual cramps  \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de entrenamiento I}
  \label{tabla:datos_trainI}
\end{table}

\begin{table}[h]
  \centering
    \begin{tabular}{|m{5cm}|m{3cm}|m{7cm}|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{benefitsReview} & \textbf{sideEffectsReview} & \textbf{commentsReview} \\ \hline
      I was used to having cramps so badly that they would leave me balled up in bed for at least 2 days. The Ponstel doesn't take the pain away completely, but takes the edge off so much that normal activities were possible. Definitely a miracle medication!! & Heavier bleeding and clotting than normal. & I took 2 pills at the onset of my menstrual cramps and then every 8-12 hours took 1 pill as needed for about 3-4 days until cramps were over. If cramps are bad, make sure to take every 8 hours on the dot because the medication stops working suddenly and unfortunately takes about an hour to an hour and a half to kick back in.. if cramps are only moderate, taking every 12 hours is okay. \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de entrenamiento II}
  \label{tabla:datos_trainII}
\end{table}

De los cuadros \ref{tabla:datos_trainI} y \ref{tabla:datos_trainII} podemos extraer que el medicamento \textbf{ponstel} con identificador \textbf{1146}, tiene la máxima puntuación por parte del paciente (\textbf{rating = 10}), el cual tiene un alto nivel de efectividad (\textbf{Highly Effective}) sin efectos secundarios (\textbf{No Side Effects}), usado para dolores menstruales (\textbf{menstrual cramps}), en donde el paciente dice que de estar tumbado en la cama con dolores ha pasado a poder realizar actividades cotidianas sin ningún impedimento. Además, asegura que tomar este medicamento le ha supuesto un sangrado más abundante y coagulación de lo normal. La dosis del medicamento oscila entre una píldora cada 8-12 horas durante 3-4 días.

```{r, warning=FALSE, include=FALSE}
# Visualizar las 5 primeras filas para los datos train
head(datos_train, 5) 
# Resumen sobre los datos train
summary(datos_train) 
```

### 2.1.2. Lectura de datos test

Se va a proceder a la lectura del conjunto de datos de prueba.

```{r, warning=FALSE}
# Lectura de datos test
datos_test <- read.table("./datos/drugLibTest_raw.tsv", sep="\t", comment.char="",
                         quote = "\"", header=TRUE)
```

Disponemos una matriz de 1036 filas x 9 columnas, asimismo vamos a ver un ejemplo de cómo está distribuida la información. Por ejemplo, para la primera fila encontramos la siguiente información:

```{r, warning=FALSE, include=FALSE}
# Visualizar las 5 primeras filas para los datos test
head(datos_test, 5) 
# información sobre los datos test
summary(datos_test) 
```

De las tablas \ref{tabla:datos_testI} y \ref{tabla:datos_testII} podemos extraer que el medicamento \textbf{biaxin} con identificador \textbf{1366}, tiene una puntuación de 9 por parte del paciente (\textbf{rating = 9}), el cual tiene un nivel considerable de efectividad (\textbf{Considerably Effective}) con efectos secundarios leves (\textbf{Mild Side Effects}), usado para la infección sinusal   (\textbf{sinus infection}), en donde el paciente dice que no está muy seguro de si el antibiótico ha destruido las bacterias que causan su infección sinusal. Además, asegura que tomar este medicamento le da algo de dolor de espalda y algunas náuseas. El paciente tomó los antibióticos durante 14 días y la infección sinusal desapareció al sexto día.

\begin{table}[h]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{X} & \textbf{urlDrugName} & \textbf{rating} & \textbf{effectiveness} 
      & \textbf{sideEffects} &\textbf{condition} \\ \hline
      1366 & biaxin & 9 & Considerably Effective & Mild Side Effects & sinus infection  \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de prueba I}
  \label{tabla:datos_testI}
\end{table}

\begin{table}[h]
  \centering
    \begin{tabular}{|m{7cm}|m{3cm}|m{5cm}|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{benefitsReview} & \textbf{sideEffectsReview} & \textbf{commentsReview} \\ \hline
      The antibiotic may have destroyed bacteria causing my sinus infection. But it may also have been caused by a virus, so its hard to say. & Some back pain, some nauseau. & Took the antibiotics for 14 days. Sinus infection was gone after the 6th day. \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de prueba II}
  \label{tabla:datos_testII}
\end{table}


```{r lectura, warning=FALSE, eval=FALSE, include=FALSE}
View(datos_train)    # vista de la tabla
View(datos_test)    # vista de la tabla
```

<!-------------------------------------------------------------------------------------------->

<!--- ## 2.2. Falta de datos, categorización, normalización, reducción de dimensionalidad. --->

<!--- Borrar si añgún atributo no nos da información como un ID, hacer una transformación con los atributos asimétricos, ya que son necesarios para la aplicación de algunos métodos de aprendizaje sensibles a distancias. Se consideran asimétricos cuando el valor skewness se aleja de 0, podemos eliminar las variables con varianza 0 o muy próximas. --->

Una vez leídos nuestros datos, procedemos a la transformación y preprocesamiento de los mismos. En donde la representación del documento se llevará a cabo utilizando palabras, después de un debido filtrado para minimizar la dimensión del espacio de trabajo.

## 2.2. Preprocesamiento de los datos

Dado que la representación total del documento puede tener una alta dimensión, se va a proceder a construir un corpus, necesario para la aplicación de métodos de limpieza y estructuración del texto de entrada e identificación de un subconjunto simplificado de las características del documento, con el fin de poder ser representado en un análisis posterior.

<!-------------------------------------------------------------------------------------------->

### 2.2.1. Eliminar columnas

El primer paso que vamos a realizar es la **eliminación de columnas**, las cuales contienen información irrelevante para nuestro análisis.

#### Eliminar columna ID

Al conjunto de datos utilizado se le ha añadido de forma automática una novena columna, que representa un ID para cada uno de los datos con los que estamos trabajando. Como este ID no nos aporta información alguna, hemos decidido quitarlo directamente del _dataframe_. Esta columna se corresponde con la primera columna, por lo cuál, debemos eliminar la columna que se corresponde con la posición 1. Los cambios que hacemos en el _dataset_ deben modificarse tanto en el conjunto de test como train para que los resultados sean consistentes.

```{r}
datos_train = datos_train[-1] # Eliminar columna para el ID en el train
datos_test = datos_test[-1] # Eliminar columna para el ID en el test
```

#### Eliminar columna de commentsReview

Consideramos que la información contenida en _commentsReview_ no es de nuestro interés. En este atributo se almacena texto, en el cual los consumidores de los medicamentos suelen poner en la mayoría de casos la frecuencia o la dosis con la que consumen la misma. En otros casos menos frecuentes, se establecen comentarios más arbitrarios en el que se muestran sus sensaciones o información sin relevancia. Incluso en algunos casos este campo aparece vacío. Es por eso, que hemos decidido eliminar la columna, tanto para el conjunto test como train.

```{r}
datos_train = datos_train[-8] # Eliminar columna para el commentsReview en el train
datos_test = datos_test[-8] # Eliminar columna para el commentsReview en el test
```

<!-------------------------------------------------------------------------------------------->

### 2.2.2. Eliminar filas

Además de eliminar las columnas innecesarias, se han localizado tres filas que no aportan información a nuestro análisis. Asimismo, dichas filas perjudicaban la aplicación de técnicas.

- Se elimina la fila 387, porque no dispone de información alguna ni en _benefitsReview_ y _sideEffectsReview_. 
- Se elimina la fila 928, porque en la columna _condition_ dispone de un carácter raro. 
- Se elimina la fila 3105, porque no tienen información en _benefitsReview_, tan solo había tres guiones.

```{r}
datos_train = datos_train[-c(387, 928, 3105),] # Eliminar filas en el train
datos_test = datos_test[-c(387, 928, 3105),] # Eliminar filas en el test
```

<!-------------------------------------------------------------------------------------------->

### 2.2.3. Eliminar elementos repetidos (medicamentos)

Como se puede ver a continuación, existen medicamentos repetidos. Sin embargo, no se ha realizado a priori, debido a que le damos más importancia a las opiniones de los pacientes, con el fin de obtener la efectividad o efectos secundarios del medicamento.

```{r, include=FALSE}
# Obtenemos los nombres de los medicamentos
nombres_medicamentos <- data.frame(datos_test$urlDrugName)

# Nos creamos un dataset con medicamentos
datos_medicamentos <- aggregate(datos_test$urlDrugName, nombres_medicamentos, length)
colnames(datos_medicamentos)[2]<-"Repeticiones"

# Ordenamos los medicamentos por los que más se repiten
datos_medicamentos_new <- datos_medicamentos[order(datos_medicamentos$Repeticiones, 
                                                   decreasing = TRUE),]

# Luego indico que quiero un grupo por cada valor unico
nombres_medicamentos %>% group_by(datos_test$urlDrugName) %>% tally()  

# Muestro el medicamentos las veces que se repite
datos_test[datos_test$urlDrugName == "paxil",]
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{imagenes/medicamentos_duplicados.png}
    \caption{Medicamento "paxil" repetido 20 veces en el conjunto test}
    \label{medicamentos_repetidos}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.4. Cuantificación de variables

Para poder analizar y trabajar más fácilmente con la información de *sideEffects* y  *effectiveness*, se va a realizar una conversión de dichas columnas a forma cuantitativa, es decir, vamos asignar una etiqueta numérica a cada valor pertinente, tanto para para _train_ como _test_. 

A continuación, vamos a cuantificar la columna de *sideEffects*, para ello se añade una nueva columna a nuestro conjunto de datos denominada *sideEffectsNumber* que nos clasifica los posibles valores de la columna *sideEffects* en un rango numérico, comprendido entre 1 y 5. Dicha columna hace referencia a la clasificación de los efectos secundarios del medicamento según el paciente, en donde la etiqueta con valor 1 hará referencia a que no haya ningún efecto secundario y la etiqueta con valor 5 a que tiene efectos secundarios extremadamente graves:

- Extremely Severe Side Effects (efectos secundarios extremadamente graves) : 5
- Severe Side Effects (efectos secundarios graves): 4
- Moderate Side Effects (efectos secundarios moderados) : 3
- Mild Side Effects (efectos secundarios leves) : 2
- No Side Effects (sin efectos secundarios) : 1

```{r}
# Datos Train
datos_train$sideEffectsNumber[datos_train$sideEffects=="Extremely Severe Side Effects"]<-5
datos_train$sideEffectsNumber[datos_train$sideEffects=="Severe Side Effects"]<-4
datos_train$sideEffectsNumber[datos_train$sideEffects=="Moderate Side Effects"] <- 3
datos_train$sideEffectsNumber[datos_train$sideEffects=="Mild Side Effects"]<- 2
datos_train$sideEffectsNumber[datos_train$sideEffects=="No Side Effects"]<- 1

# Datos Test
datos_test$sideEffectsNumber[datos_test$sideEffects=="Extremely Severe Side Effects"]<-5
datos_test$sideEffectsNumber[datos_test$sideEffects=="Severe Side Effects"]<-4
datos_test$sideEffectsNumber[datos_test$sideEffects=="Moderate Side Effects"]<-3
datos_test$sideEffectsNumber[datos_test$sideEffects=="Mild Side Effects"]<-2
datos_test$sideEffectsNumber[datos_test$sideEffects=="No Side Effects"]<-1
```

Podemos comprobar que se ha creado la nueva columna *sideEffectsNumber*, y que se han añadido los cambios comentados anteriormente.

```{r}
head(datos_train$sideEffects, 5)
head(datos_train$sideEffectsNumber, 5) 
```

Volvemos a aplicar el mismo procedimiento para la columna de *effectiveness*, creándonos para ello una columna denominada *effectivenessNumber*. Dicha columna, hace referencia a la clasificación de la efectividad del medicamento según el paciente, asignaremos la etiqueta con valor 1 para indicar que el medicamente es ineficaz, si este es altamente eficaz, le asignaremos la etiqueta con valor 5:

- Highly Effective (altamente efectivo): 5
- Considerably Effective (considerablemente efectivo) : 4
- Moderately Effective (moderadamente efectivo) : 3
- Marginally Effective (marginalmente efectivo) : 2
- Ineffective (ineficaz) : 1

```{r}
# Datos de entrenamiento
datos_train$effectivenessNumber[datos_train$effectiveness=="Highly Effective"]<-5
datos_train$effectivenessNumber[datos_train$effectiveness=="Considerably Effective"]<-4
datos_train$effectivenessNumber[datos_train$effectiveness=="Moderately Effective"]<-3
datos_train$effectivenessNumber[datos_train$effectiveness=="Marginally Effective"]<-2
datos_train$effectivenessNumber[datos_train$effectiveness=="Ineffective"]<- 1

# Datos de test
datos_test$effectivenessNumber[datos_test$effectiveness=="Highly Effective"]<-5
datos_test$effectivenessNumber[datos_test$effectiveness=="Considerably Effective"]<-4
datos_test$effectivenessNumber[datos_test$effectiveness=="Moderately Effective"]<-3
datos_test$effectivenessNumber[datos_test$effectiveness=="Marginally Effective"]<-2
datos_test$effectivenessNumber[datos_test$effectiveness=="Ineffective"]<-1
```

Comprobamos que se ha creado la nueva columna *effectivenessNumber*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$effectiveness, 5)
head(datos_train$effectivenessNumber, 5) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.5. Cálculo del rating ponderado

En este subapartado, se va a realizar una agregación de varias columnas, en donde queremos realizar una valoración general del medicamento. Para ello, se va a realizar una ponderación entre la columna que contiene los efectos secundarios y la efectividad del medicamento. Asimismo, se ha considerado los efectos secundarios del medicamento con mayor importancia, es por eso que se le ha otorgado una ponderación del 70\% frente al 30\% de la efectividad del medicamento.

$$( sideEffects \cdot 0.7 ) + ( effectiveness \cdot 0.3 )$$

El motivo de esta ponderación es que se considera que es peor tener efectos secundarios severos en un medicamento, que ser efectivo. Dicha agregación se ha añadido a una nueva columna, denominada **weightedRating**, cuyo resultado contiene una valoración general del medicamento. En donde, dicha transformación, puede ser usada para realizar una compararación con las propias valoraciones de los usuarios.

```{r}
# Recorremos el dataframe para el conjunto train
for (i in 1:length(datos_train[[1]])) {
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_train$sideEffectsNumber[i]
  # Obtenemos el valor de efectiveness
  effectivenessRating <- datos_train$effectivenessNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, ya que 
  # sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para 
  # ello realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
  
  # Obtenemos el resultado ponderado en tipo float
  floatResult <- effectivenessRating * 0.7 + sideEffectRating * 0.3
  
  # Convertimos el resultado a valor entero.
  integerResult <- as.integer(floatResult)
  
  # Calculamos la parte decimal y redondeamos
  if(floatResult - integerResult < 0.5) result <- integerResult
  else result <- integerResult+1
  
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a 
  # escala (1-10)
  datos_train$weightedRating[i] <- result * 2
}
```

Comprobamos que se ha creado la nueva columna *weightedRating*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$weightedRating, 10) 
```

Ahora realizamos el mismo procesamiento para el conjunto test, comprobamos que se ha creado la nueva columna *weightedRating*, y además que se han añadido los cambios comentados.

```{r, include=FALSE}
# Ponderaciones
sideEffectstWeight <- 0.7
effectivenessWeight <- 0.3

# Recorremos el dataframe para el conjunto test
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_test$sideEffectsNumber[i]
  # Obtenemos el valor de efectiveness
  effectivenessRating <- datos_test$effectivenessNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, 
  # ya que sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para ello 
  # realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
  # Obtenemos el resultado ponderado en tipo float
  floatResult <- effectivenessRating * effectivenessWeight + sideEffectRating * sideEffectstWeight
  
  # Convertimos el resultado a valor entero.
  integerResult <- as.integer(floatResult)
  
  # Calculamos la parte decimal y redondeamos
  if(floatResult - integerResult < 0.5)
    result <- integerResult
  else
    result <- integerResult+1
  
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a 
  # escala (1-10)
  datos_test$weightedRating[i] <- result * 2
}
```

```{r}
head(datos_test$weightedRating, 10) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.6. Convertir el rating a variable binaria

Para la realización de algunas técnicas que se explicarán más adelante, se necesita tener una etiqueta o variable binaria comprendida entre 0 y 1, es por eso que se ha optado por escoger la columna que contiene la puntuación del medicamento por parte del paciente, y establecerla entre 0 y 1. En donde el 0, tendrá los valores comprendidos entre 1 y 4 y nos indicará que el medicamento no es favorable; y en donde el 1, tendrá los valores comprendidos entre 5 y 10 indicándonos que el medicamento es favorable. Dichos cambios, serán añadidos a una nueva columna llamada **ratingLabel**. Realizamos dicho cambio, tanto para test como train.

```{r}
# Recorremos el dataframe para el conjunto train
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de rating
  rating <- datos_train$rating[i]
 
  # Valores comprendidos entre 1 y 4 - no favorable - 0
  if (datos_train$rating[i] < 5) result <- 0
  # Valores comprendidos entre 5 y 10 - favorable - 1
  else if (datos_train$rating[i] >= 5) 
    result <- 1
  
  # Asignamos el resultado a la nueva variable
  datos_train$ratingLabel[i] <- result
}
```

```{r, include=FALSE}
# Recorremos el dataframe para el conjunto test
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de rating
  rating <- datos_test$rating[i]
 
  # Cuando los valores comprendidos entre 1 y 4 - no favorable - 0
  if (datos_test$rating[i] < 5) result <- 0
  # Cuando los valores comprendidos entre 5 y 10 - favorable - 1
  else if (datos_test$rating[i] >= 5) result <- 1
  
  # Asignamos el resultado a la nueva variable
  datos_test$ratingLabel[i]  <- result
}
```

<!-------------------------------------------------------------------------------------------->

### 2.2.7. Cambiar el orden para la columna sideEffectsNumber

Al comparar las columna _sideEffectsNumber_ y _effectivenesNumber_, llegamos a la conclusión, de que ambas siguen órdenes distintos, es decir, el valor 5 en _sideEffectsNumber_ dice que el medicamento tiene efectos secundarios extremadamente graves, y el valor 5 en _effectivenesNumber_ dice que el medicamento es altamente efectivo. Por tanto, se ha considerado, que el valor correspondiente al 5, sea positivo y el valor correspondiente a 1 negativo. Para ello, se ha modificado el orden de la columna _sideEffectsNumber_, en donde, la nueva columna **sideEffectsInverse** tiene:

- Extremely Severe Side Effects (efectos secundarios extremadamente graves) : 1
- Severe Side Effects (efectos secundarios graves): 2
- Moderate Side Effects (efectos secundarios moderados) : 3
- Mild Side Effects (efectos secundarios leves) : 4
- No Side Effects (sin efectos secundarios) : 5

Realizamos dicha modificación, tanto para train como test.

```{r}
# Recorremos el dataframe para el conjunto train
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_train$sideEffectsNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Cambiamos el orden para el el valor de sideEffect
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
 
  # Añadimos el resultado obtenido
  datos_train$sideEffectsInverse[i] <- sideEffectRating
}
```

```{r, include=FALSE}
# Recorremos el dataframe para el conjunto test
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_test$sideEffectsNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  
  # Cambiamos el orden para el el valor de sideEffect
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
 
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a escala (1-10)
  datos_test$sideEffectsInverse[i] <- sideEffectRating
}
```

```{r}
head(datos_train$sideEffectsNumber, 10)
head(datos_train$sideEffectsInverse, 10)
```

<!-------------------------------------------------------------------------------------------->

### 2.2.8. Representación gráfica de los datos

Antes de comenzar con el análisis exploratorio, vamos realizar distintas gráficas de barras con el fin de comprender mejor los datos, antes del procesamiento. Primero realizaremos un gráfico de barras de las clasificaciones del medicamento por parte del paciente. 

En la figura \ref{grafica_rating}, se observa como más del 50% de los medicamentos obtienen una nota superior 6 por parte del paciente. Esto nos sugiere que el paciente, tiene una buena opinión sobre un alto porcentaje de los medicamentos, lo que puede dar lugar a opiniones más positivas. Por otro lado, vamos a mostrar gráficamente los efectos secundarios del medicamento según el paciente. En donde el 1 significa que el medicamento tiene pocos efectos secundarios y el 5 que tiene muchos efectos secundarios. Como se aprecia en la figura \ref{grafica_sideEffectsNumber}, un alto porcentaje de los medicamentos no tiene efectos secundarios, de acuerdo a las valoraciones de los pacientes.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(rating) %>%
    ggplot(aes(x = factor(rating), y = n, fill = factor(rating))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación del medicamento por parte del paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold", size=40))
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.76\textwidth]{imagenes/grafica_rating.png}
    \caption{Clasificación del medicamento por parte del paciente}
    \label{grafica_rating}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.76\textwidth]{imagenes/grafica_sideEffectsNumber.png}
    \caption{Clasificación de los efectos secundarios del medicamento según el paciente}
    \label{grafica_sideEffectsNumber}
\end{figure}

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(sideEffectsNumber) %>%
    ggplot(aes(x = factor(sideEffectsNumber), y = n, fill = factor(sideEffectsNumber))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación de los efectos secundarios del medicamento según el paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold"))
```


Por último, vamos a visualizar gráficamente, la efectividad del medicamentoe según el paciente. En donde el 1 significa que el medicamento tiene poca efectividad y el 5 que tiene mucha efectividad. De acuerdo a la figura \ref{grafica_sideEffectsNumber} y sabiendo que los pacientes aseguran que los medicamentos tienen pocos efectos secundarios, no es de extrañar que también tengan una alta efectividad.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(effectivenessNumber) %>%
    ggplot(aes(x = factor(effectivenessNumber), y = n, fill = factor(effectivenessNumber))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación de la efectividad del medicamento según el paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold")) 
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.76\textwidth]{imagenes/grafica_effectivenessNumber.png}
    \caption{Clasificación de la efectividad del medicamento según el paciente}
    \label{grafica_sideEffectsNumber}
\end{figure}

Acabamos de comprobar, como las valoraciones de los medicamentos por parte de los pacientes son mayormente positivas. Por tanto, una vez comprendidos los datos y eliminadas las columnas anteriores y modificadas las necesarias, ya podemos continuar con el procesamiento de los datos. Para ello, lo primero tenemos que hacer es cargar la librería que procesa los datos de tipo texto en R, para la construcción y manipulación del corpus. La librería más conocida se llama \textbf{tm}, aunque también haremos uso del paquete \textbf{SnowballC} para realizar el _Stemming_. 

<!-------------------------------------------------------------------------------------------->

### 2.2.9. Creación del corpus

Para poder obtener la estructura con la que vamos a procesar nuestra información, debemos obtener un vector con documentos. En nuestro caso, cada uno de los documentos se corresponde con una opinión sobre un fármaco (*benefitsReview*) y los efectos que tiene (*sideEffectsReview*). Para ello, primero debemos de construir un vector con todas los opiniones del _dataframe_ y convertir cada elemento del vector al formato de documento. Podemos usar la función _VectorSource_ para hacer esta conversión. Se deberán realizar todas las modificaciones tanto para el conjunto train como test. 

```{r}
# Datos train

# Nos quedamos con la única columna del dataset que nos interesa. 
# Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, 
# por lo que usamos as.vector para hacer la conversión
benefits_train_review_data = as.vector(datos_train$benefitsReview)
effects_train_review_data = as.vector(datos_train$sideEffectsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus 
# que lo vamos a utilizar
benefits_train_corpus = (VectorSource(benefits_train_review_data))
effects_train_corpus = (VectorSource(effects_train_review_data))

# Creamos el propio corpus
benefits_train_corpus <- Corpus(benefits_train_corpus)
effects_train_corpus <- Corpus(effects_train_corpus)
``` 

```{r}
# Datos test

# Nos quedamos con la única columna del dataset que nos interesa. 
# Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, 
# por lo que usamos as.vector para hacer la conversión
benefits_test_review_data = as.vector(datos_test$benefitsReview)
effects_test_review_data = as.vector(datos_test$sideEffectsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus 
# que lo vamos a utilizar
benefits_test_corpus = (VectorSource(benefits_test_review_data))
effects_test_corpus = (VectorSource(effects_test_review_data))

# Creamos el propio corpus
benefits_test_corpus <- Corpus(benefits_test_corpus)
effects_test_corpus <- Corpus(effects_test_corpus)
``` 

Podemos ver que funciona accediendo a uno cualquiera, de la forma `inspect(benefits_train_corpus[4])`:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_train_corpus1.png}
    \caption{Contenido para benefits\_train\_corpus I}
    \label{benefits1}
\end{figure}

O de la forma `benefits_train_corpus[[4]]$content`:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_train_corpus2.png}
    \caption{Contenido para benefits\_train\_corpus II}
    \label{benefits2}
\end{figure}

Y si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación.

```{r, include=FALSE}
# Si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación
inspect(benefits_train_corpus[4])

benefits_train_corpus[[4]]$content
```

```{r, include=FALSE}
# Si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación
inspect(effects_train_corpus[7])
effects_train_corpus[[7]]$content
```

<!-------------------------------------------------------------------------------------------->

### 2.2.10. Correlación

Una forma de medir la distancia es calcular la correlación entre un término y todos los demás de la matriz. Como en este caso, estamos usando variables textuales, no se aconseja hacer la correlación como tal. Debido a que la correlación indica la fuerza y la dirección de una relación lineal y proporcionalidad entre dos variables estadísticas, ya que está pensada para variables cuantitativas. Por otro lado, si que disponemos de variables categóricas, pero también se ha despreciado hacer la correlación entre ellas, debido a que no podemos prescindir de las etiquetas, ni agrupar distintos medicamentos en uno solo.

Además, la correlación está relacionada con el análisis de componentes principales (PCA), el cual, es una técnica utilizada para describir un conjunto de datos en términos de nuevas variables no correlacionadas. Por lo que se ha despreciado inicialmente realizar tal método.

<!-------------------------------------------------------------------------------------------->

### 2.2.11. Representación gráfica de las frecuencias del Corpus

Una vez creado el corpus y antes de aplicar las técnicas de preprocesamiento, vamos a visualizar las frecuencias para las dos columnas (*benefitsReview* y *sideEffectsReview*) de textos a las que vamos aplicar el preprocesamiento. Para ello, debemos calcular la matriz de términos y obtener los términos con mayor frecuencia.

Como se puede apreciar en la gráfica \ref{benefits3}, los términos que más se repiten son _the_ y _and_, además de otras preposiciones y conjunciones. Si se observa, las palabras que aparecen en la gráfica, no nos aportan información alguna, es por eso que vamos hacer una transformación a los términos, como la eliminación de los _stopwords_.

A continuación, mostramos los términos para la columna *sideEffects*, realizando el mismo procedimiento que antes. Y como se puede ver en la gráfica \ref{benefits4}, obtenemos la misma conclusión, en donde tenemos palabras que no nos aportan nada de información: _very_, _the_, _that_, _and_...

```{r, echo=FALSE, include=FALSE}
# Frecuencias para benefits en train
# https://rstudio-pubs-static.s3.amazonaws.com/40817_63c8586e26ea49d0a06bcba4e794e43d.html

# Cargamos la librería

# Calculamos la matriz de términos
dtm <- DocumentTermMatrix(benefits_train_corpus)

# Calculamos la frecuencia
freq <- sort(colSums(as.matrix(dtm)), decreasing=FALSE)
wf <- data.frame(word=names(freq), freq=freq)

# Dibujamos el histograma
subset(wf, freq>350)    %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat="identity", fill="darkred", colour="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  ggtitle("Frecuencias para benefits en train sin preprocesamiento") 

```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.67\textwidth]{imagenes/frecuencias_benefits.png}
    \caption{Frecuencia de términos para la columna benefitsReview}
    \label{benefits3}
\end{figure}

```{r, echo=FALSE, include=FALSE}
# Frecuencias para sideEffects en train
# https://rstudio-pubs-static.s3.amazonaws.com/40817_63c8586e26ea49d0a06bcba4e794e43d.html

# Calculamos la matriz de términos
dtm <- DocumentTermMatrix(effects_train_corpus)

# Calculamos la frecuencia
freq <- sort(colSums(as.matrix(dtm)), decreasing=FALSE)
wf <- data.frame(word=names(freq), freq=freq)

# Dibujamos el histograma
subset(wf, freq>350)    %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat="identity", fill="darkred", colour="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  ggtitle("Frecuencias para sideEffects en train sin preprocesamiento") 
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.67\textwidth]{imagenes/frecuencias_sideEffects.png}
    \caption{Frecuencia de términos para la columna sideEffectsReview}
    \label{benefits4}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.12. Eliminar signos de puntuación

Como hemos podido ver en el documento que se ha mostrado por pantalla, en él se aprecia el uso de signos de puntuación y exclamación. En un principio, no tiene sentido en \textit{Data Mining} contemplar los signos de puntuación, ya que no nos van a aportar información. Por ello, los quitamos, como se puede ver a continuación. Con `tm_map(corpus, removePunctuation)`, se eliminan los símbolos: ! " $ % & ' () * + , - . / : ; < = > ? @ [ \ ] ^ _ ' { | } ~, tanto para train como test.

```{r, warning=FALSE}
# Una vez que tenemos el corpus creado, continuamos con el procesamiento para datos train
benefits_train_corpus <- tm_map(benefits_train_corpus,
                                content_transformer(removePunctuation))
effects_train_corpus <- tm_map(effects_train_corpus, 
                               content_transformer(removePunctuation))

# Una vez que tenemos el corpus creado, continuamos con el procesamiento para datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, 
                               content_transformer(removePunctuation))
effects_test_corpus <- tm_map(effects_test_corpus, 
                              content_transformer(removePunctuation))
```

Si volvemos a mostrar la opinión número cuatro, vemos como todos los signos han desaparecido. De hecho, podemos inspeccionar el corpus, y se ve como todos los signos de puntuación, exclamación y derivados ya no están.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_signos_puntuacion.png}
    \caption{Contenido de benefits sin signos de puntuación}
    \label{benefits2}
\end{figure}

```{r, include=FALSE}
inspect(benefits_train_corpus[4])
```

Ocurre lo mismo con el comentario de efectos número siete.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_signos_puntuacion.png}
    \caption{Contenido de effects sin signos de puntuación}
    \label{benefits2}
\end{figure}

```{r, include=FALSE}
inspect(effects_train_corpus[7])
```

<!-------------------------------------------------------------------------------------------->

### 2.2.13. Conversión de las mayúsculas en minúsculas

Para poder hacer uso de los términos por igual, debemos convertir las mayúsculas en minúsculas. Normalmente se convierte en minúsculas todas las letras para que los comienzos de oración no sean tratados de manera diferente por los algoritmos, tanto para train como test.

```{r, warning=FALSE}
# Datos train
benefits_train_corpus <- tm_map(benefits_train_corpus, content_transformer(tolower))
effects_train_corpus <- tm_map(effects_train_corpus, content_transformer(tolower))

# Datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, content_transformer(tolower))
effects_test_corpus <- tm_map(effects_test_corpus, content_transformer(tolower))
```

Si volvemos a mostrar las opiniones, vemos como todas las mayúsuculas han desaparecido. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_mayusculas.png}
    \caption{Contenido de benefits sin mayúsculas}
    \label{benefits2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_mayusculas.png}
    \caption{Contenido de effects sin mayúsculas}
    \label{benefits2}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.14. Eliminación de Stopwords

En cualquier idioma, hay palabras que son tan comunes o muy utilizadas que no aportan información relevante, a dichas palabras se las conoce como _stopwords_ o palabras _stop_. Por ejemplo, en español, las palabras "la", "a", "en", "de" son ejemplos de _stopwords_. Este tipo de palabras debemos de suprimirlas de nuestro corpus. Como, en nuestro caso, el contenido del corpus está en inglés, debemos especificar el idioma correcto para que nos elimine del corpus las palabras adecuadas en dicho idioma, tanto en train como en test.

```{r, warning=FALSE}
# Datos train
benefits_train_corpus <- tm_map(benefits_train_corpus, content_transformer(removeWords), 
                                stopwords("english"))
effects_train_corpus <- tm_map(effects_train_corpus, content_transformer(removeWords), 
                               stopwords("english"))

# Datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, content_transformer(removeWords), 
                               stopwords("english"))
effects_test_corpus <- tm_map(effects_test_corpus, content_transformer(removeWords), 
                              stopwords("english"))
```

Si volvemos a mostrar las opiniones, vemos como por ejemplo las palabras como _the_ o _and_, han desaparecido de nuestro corpus.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_stopwords.png}
    \caption{Contenido de benefits sin stopwords}
    \label{benefits2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_stopwords.png}
    \caption{Contenido de effects sin stopwords}
    \label{benefits2}
\end{figure}

Ahora ya hemos eliminado las _stopwords_ de forma correcta, y pasamos a realizar la agrupación de sinónimos.

<!-------------------------------------------------------------------------------------------->

### 2.2.15. Agrupación de sinónimos

Con el fin de disminuir la dimensión del espacio a trabajar, se pueden identificar palabras distintas con el mismo significado y reemplazarlas por una sola palabra. Para ello se toman los sinónimos de dicha palabra. Dentro de las librerías que podemos usar para agrupar sinónimos, destacamos dos: `wordnet` y `rword2vec`. Sin embargo, por su sencillez se va hacer uso de `rword2vec`. Previamente, se obtendrán que palabras son las que mayor frecuencia presentan en nuestro texto, tanto para *benefitsReview* como *sideEffectsReview* del conjunto train y test. Y visualizamos los 4 primeros términos gráficamente para cada columna y conjunto train y test:

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Obtenemos su matriz de términos
matrix_train_benefits_corpus <- TermDocumentMatrix(benefits_train_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_train_benefits_corpus <- as.matrix(matrix_train_benefits_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_train_benefits_corpus <- rowSums(matrix_train_benefits_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_benefits_train_corpus <- sort(matrix_train_benefits_corpus, decreasing = TRUE)
terms_frecuency_benefits_train_corpus <- terms_frecuency_benefits_train_corpus[1:length(benefits_train_corpus)]
# terms_frecuency_benefits_train_corpus
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Obtenemos su matriz de términos
matrix_test_benefits_corpus <- TermDocumentMatrix(benefits_test_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_test_benefits_corpus <- as.matrix(matrix_test_benefits_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_test_benefits_corpus <- rowSums(matrix_test_benefits_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_benefits_test_corpus <- sort(matrix_test_benefits_corpus, decreasing = TRUE)
terms_frecuency_benefits_test_corpus <- terms_frecuency_benefits_test_corpus[1:length(benefits_test_corpus)]
# terms_frecuency_benefits_test_corpus
```

```{r, include=FALSE}
# Columna sideEffectsReview del conjunto train

# Obtenemos su matriz de términos
matrix_train_effects_corpus <- TermDocumentMatrix(effects_train_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_train_effects_corpus <- as.matrix(matrix_train_effects_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_train_effects_corpus <- rowSums(matrix_train_effects_corpus)
# Ordenamos de mayor a menor los términos y nos quedamos con lso 100 primeros
terms_frecuency_effects_train_corpus <- sort(matrix_train_effects_corpus, decreasing = TRUE)
terms_frecuency_effects_train_corpus <- terms_frecuency_effects_train_corpus[1:length(effects_train_corpus)]
# terms_frecuency_effects_train_corpus
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Obtenemos su matriz de términos
matrix_test_effects_corpus <- TermDocumentMatrix(effects_test_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_test_effects_corpus <- as.matrix(matrix_test_effects_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_test_effects_corpus <- rowSums(matrix_test_effects_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_effects_test_corpus <- sort(matrix_test_effects_corpus, decreasing = TRUE)
terms_frecuency_effects_test_corpus <- terms_frecuency_effects_test_corpus[1:length(effects_test_corpus)]
# terms_frecuency_effects_test_corpus
```

```{r, echo=FALSE}
par(mfrow=c(2,2))

graph_terms_frecuency_benefits_train_corpus <- as.matrix(terms_frecuency_benefits_train_corpus)
barplot(graph_terms_frecuency_benefits_train_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("Benefits para train", font = 2))

graph_terms_frecuency_benefits_test_corpus <- as.matrix(terms_frecuency_benefits_test_corpus)
barplot(graph_terms_frecuency_benefits_test_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("Benefits para test", font = 2))

graph_terms_frecuency_effects_train_corpus <- as.matrix(terms_frecuency_effects_train_corpus)
barplot(graph_terms_frecuency_effects_train_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("SideEffects para train", font = 2))

graph_terms_frecuency_effects_test_corpus <- as.matrix(terms_frecuency_effects_test_corpus)
barplot(graph_terms_frecuency_effects_test_corpus[1:4,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=4, name="Zissou1"))
title(main = list("SideEffects paratest", font = 2))
```

Una vez que tenemos los términos con mayor frecuencia en nuestras columnas (*benefitsReview* y *sideEffectsReview*) y su frecuencia asociada, pasamos a matriz dichos datos, con el fin de obtener solo las palabras y descartar su frecuencia.

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_benefits_train_corpus <- as.matrix(terms_frecuency_benefits_train_corpus)
# terms_frecuency_benefits_train_corpus

# Me quedo solo con los términos
terms_benefits_train_corpus <- rownames(terms_frecuency_benefits_train_corpus)
# terms_benefits_train_corpus
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_benefits_test_corpus <- as.matrix(terms_frecuency_benefits_test_corpus)
# terms_frecuency_benefits_test_corpus

# Me quedo solo con los términos
terms_benefits_test_corpus <- rownames(terms_frecuency_benefits_test_corpus)
# terms_benefits_test_corpus
```

```{r, include=FALSE}
# Columna sideEffectsReview del conjunto train

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_effects_train_corpus <- as.matrix(terms_frecuency_effects_train_corpus)
# terms_frecuency_effects_train_corpus

# Me quedo solo con los términos
terms_effects_train_corpus <- rownames(terms_frecuency_effects_train_corpus)
# terms_effects_train_corpus
```

```{r, include=FALSE}
# Columna sideEffectsReview del conjunto test

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_effects_test_corpus <- as.matrix(terms_frecuency_effects_test_corpus)
# terms_frecuency_effects_test_corpus

# Me quedo solo con los términos
terms_effects_test_corpus <- rownames(terms_frecuency_effects_test_corpus)
# terms_effects_test_corpus
```

Como ya sabemos las palabras a usar, es decir, los términos que más se repite, procedemos a la agrupación por sinónimos. En donde, mediante la función *distance(...)* de la libería *rword2vec*, obtendremos todas palabras más similares de nuestro conjunto, en nuestro caso nos vamos a quedar con las 2 primeras, tanto para *benefitsTrainReview* como *sideEffectsReview* del conjunto train y test. A continuación, se muestran los pasos seguidos.

1. Escribir un fichero los datos asociados a dicha columna.
2. Entrenar los datos del fichero, con el fin de obtener los vectores de palabras que nos darán los palabras más similares.
3. Obtener para cada término del documento, la distancia con los térmios del ficheros, quedándonos con las de mayor frecuencia.
4. Guardar en un fichero dichas distancias.

```{r, include=FALSE}
# http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/
# https://github.com/mukul13/rword2vec
# http://www.rpubs.com/mukul13/rword2vec
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Escribo en un fichero la columna "benefitsReview"
# write.table(datos_train$benefitsReview, "benefitsTrainReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_benefits_train = word2vec(train_file = "benefitsTrainReview.txt", output_file = "benefitsTrainReview.bin", binary=1)

#dist_terms_benefits_train_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_benefits_train_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_benefits_train_corpus[i] = distance(file_name = "benefitsTrainReview.bin", 
#                                                 search_word = terms_benefits_train_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_benefits_train_corpus, 'datos/ficheros-sinonimos/benefits/dist_terms_benefits_train_corpus.RData')
dist_terms_benefits_train_corpus_new <- list.load('datos/ficheros-sinonimos/benefits/dist_terms_benefits_train_corpus.RData')
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Escribo en un fichero la columna "benefitsReview"
# write.table(datos_test$benefitsReview, "benefitsTestReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_benefits_test = word2vec(train_file = "benefitsTestReview.txt", output_file = "benefitsTestReview.bin", binary=1)

#dist_terms_benefits_test_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_benefits_test_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_benefits_test_corpus[i] = distance(file_name = "benefitsTestReview.bin", 
#                                                 search_word = terms_benefits_test_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_benefits_test_corpus, 'datos/ficheros-sinonimos/benefits/dist_terms_benefits_test_corpus.RData')
dist_terms_benefits_test_corpus_new <- list.load('datos/ficheros-sinonimos/benefits/dist_terms_benefits_test_corpus.RData')
```

```{r, include=FALSE}
# Columna sideEffects del conjunto train

# Escribo en un fichero la columna "sideEffectsReview"
# write.table(datos_train$sideEffectsReview, "effectsTrainReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_effects_train = word2vec(train_file = "effectsTrainReview.txt", output_file = "effectsTrainReview.bin", binary=1)

#dist_terms_effects_train_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_effects_train_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_effects_train_corpus[i] = distance(file_name = "effectsTrainReview.bin", 
#                                                 search_word = terms_effects_train_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_effects_train_corpus, 'datos/ficheros-sinonimos/effects/dist_terms_effects_train_corpus.RData')
dist_terms_effects_train_corpus_new <- list.load('datos/ficheros-sinonimos/effects/dist_terms_effects_train_corpus.RData')
```

```{r, include=FALSE}
# Columna sideEffects del conjunto test

# Escribo en un fichero la columna "sideEffectsReview"
# write.table(datos_test$sideEffectsReview, "effectsTestReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_effects_test = word2vec(train_file = "effectsTestReview.txt", output_file = "effectsTestReview.bin", binary=1)

#dist_terms_effects_test_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_effects_test_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_effects_test_corpus[i] = distance(file_name = "effectsTestReview.bin", 
#                                                 search_word = terms_effects_test_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_effects_test_corpus, 'datos/ficheros-sinonimos/effects/dist_terms_effects_test_corpus.RData')
dist_terms_effects_test_corpus_new <- list.load('datos/ficheros-sinonimos/effects/dist_terms_effects_test_corpus.RData')
```

Una vez, que tenemos todas las palabras con los 2 términos más similares, procedemos a sustituir todos esos términos por el término general. Veamos un ejemplo sencillo, en donde las palabras "medicine" o "medication", van a ser sustituidas por "drug".

```{r}
# Obtenemos el tercer término -> "drug"
terms_benefits_train_corpus[3]

# Vamos a sustituir "pain" por sus dos palabras más similares
dist_terms_benefits_train_corpus_new[[3]]
```

Se debe tener en cuenta, que los términos más similares han sido creados solo para nuestros documentos. Por último, ya solo nos queda hacer el reemplazamiento, para ello se usará la función *gsub(...)* sobre el corpus (*benefits_corpus* y *sideEffectsReview*). Para sustituir las palabras en el texto, se ha hecho uso de la función `gsub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE, fixed = FALSE, useBytes = FALSE)`. A continuación, se describe el proceso seguido:

1. Iteramos sobre los términos del documento.
2. Iteramos sobre las palabras más frecuentes de cada término.
3. Realizamos el reemplazamiento de las palabras más similares por los términos generales, previa conversión a minúsculas.
4. Guardamos los resultados en ficheros.

```{r, warning=FALSE, include=FALSE}
# Para la columna benefitsReview del conjunto train

#dist_terms_benefits_train_corpus_new <- list.remove(dist_terms_benefits_train_corpus_new, c(446, 506))
#dist_terms_benefits_train_corpus_new <- list.remove(dist_terms_benefits_train_corpus_new, c(447, 508, 651, 678, 686, 815, 982, 996))
# dist_terms_benefits_train_corpus <- list.remove(dist_terms_benefits_train_corpus, c(1049, 1077, 1103, 1123, 1186, 1229, 1562, 1617,1659))

#View(dist_terms_benefits_train_corpus)

#for (i in 1:640) # iteramos sobre los terminos, hasta el 1797, porque si vemos el fichero, ya no hay más palabras
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    benefits_train_corpus_new <- tm_map(benefits_train_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_benefits_train_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_benefits_train_corpus[i]))

# guardar "benefits_train_corpus_new"
#saveRDS(benefits_train_corpus_new, file = "datos/ficheros-sinonimos/benefits/benefits_train_corpus_new.rds")
benefits_train_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/benefits/benefits_train_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(benefits_train_corpus$content, "datos/ficheros-sinonimos/benefits/benefitsTrainSinSinonimos.txt")
write.table(benefits_train_corpus_new_load$content, "datos/ficheros-sinonimos/benefits/benefitsTrainConSinonimos.txt")
```

```{r, warning=FALSE, include=FALSE}
# Para la columna benefitsReview del conjunto test

# dist_terms_benefits_test_corpus_new <- list.remove(dist_terms_benefits_test_corpus_new, c(171, 470))

#for (i in 1:450) # iteramos sobre los terminos 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    benefits_test_corpus_new <- tm_map(benefits_test_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_benefits_test_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_benefits_test_corpus[i]))

# guardar "benefits_train_corpus_new"
#saveRDS(benefits_test_corpus_new, file = "datos/ficheros-sinonimos/benefits/benefits_test_corpus_new.rds")
benefits_test_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/benefits/benefits_test_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(benefits_test_corpus$content, "datos/ficheros-sinonimos/benefits/benefitsTestSinSinonimos.txt")
write.table(benefits_test_corpus_new_load$content, "datos/ficheros-sinonimos/benefits/benefitsTestConSinonimos.txt")
```

```{r, warning=FALSE, include=FALSE}
# Para la columna sideEffectsReview del conjunto train

#dist_terms_effects_train_corpus_new <- list.remove(dist_terms_effects_train_corpus_new, c(318, 504, 654, 706, 734, 991))

#for (i in 1:710) # iteramos sobre los terminos, hasta el 1539, porque si vemos el fichero, ya no hay más palabras 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    effects_train_corpus_new <- tm_map(effects_train_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_effects_train_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_effects_train_corpus[i]))

# guardar "effects_train_corpus_new"
# saveRDS(effects_train_corpus_new, file = "effects_train_corpus_new.rds")
effects_train_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/effects/effects_train_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(effects_train_corpus$content, "datos/ficheros-sinonimos/effects/effectsTrainSinSinonimos.txt")
write.table(effects_train_corpus_new_load$content, "datos/ficheros-sinonimos/effects/effectsTrainConSinonimos.txt")
```


```{r, warning=FALSE, include=FALSE}
# Para la columna sideEffectsReview del conjunto test


#for (i in 1:450) # iteramos sobre los terminos 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    effects_test_corpus_new <- tm_map(effects_test_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_effects_test_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_effects_test_corpus[i]))

# guardar "effects_train_corpus_new"
#saveRDS(effects_test_corpus_new, file = "datos/ficheros-sinonimos/effects/effects_test_corpus_new.rds")
effects_test_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/effects/effects_test_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(effects_test_corpus$content, "datos/ficheros-sinonimos/effects/effectsTestSinSinonimos.txt")
write.table(effects_test_corpus_new_load$content, "datos/ficheros-sinonimos/effects/effectsTestConSinonimos.txt")
```

<!-------------------------------------------------------------------------------------------->

### 2.2.16. TF-IDF

Para estudiar la importancia de los términos de un documento en particular, en lugar de utilizar la frecuencia de cada uno de los términos directamente, se pueden utilizar diferentes ponderaciones denominadas TF-IDF (_Term Frequency-Inverse Document Frecuency_). Estas ponderaciones se calculan como el producto de dos medidas, la frecuencia de aparición del término ($tf$) y la frecuencia inversa del documento ($idf$). La fórmula matemática para esta métrica es la siguiente:

$$ tfidf(t, d, D) = tf(t, d) × idf(t, D)$$

donde $t$ es el término, $d$ denota cada documento, $D$ el espacio total de documentos y $tfidf$ es el peso asignado a ese término en el documento correspondiente.

La combinación de los valores de $tf$ e $idf$ da una métrica que permite saber cómo de únicas son las palabras de un documento. La ponderación asigna un alto peso a un término si se produce con frecuencia en ese documento, pero rara vez en la colección completa. Sin embargo, si el término ocurre pocas veces en el documento, o aparece prácticamente en todos ellos, disminuye el peso asignado por la ponderación $tfidf$.

El peso aumenta proporcionalmente al número de veces que una palabra aparece en el documento, pero es compensada por la frecuencia de la palabra en la colección de documentos, lo que permite filtrar las palabras más comunes. Para ello, necesitamos que convertir nuestro corpus a un _dataframe_, en donde cada columna será una palabra del comentario y cada fila un comentario.

```{r, include=FALSE, echo}
# Convertimos las columnas de review a una tabla en el que cada columna será una palabra del comentario y cada fila pertenece a un comentario
dataframe_benefits_train<-data.frame(text=unlist(sapply(benefits_train_corpus_new_load, `[`)), stringsAsFactors=F)
dataframe_effects_train<-data.frame(text=unlist(sapply(effects_train_corpus_new_load, `[`)), stringsAsFactors=F)

dataframe_benefits_test<-data.frame(text=unlist(sapply(benefits_test_corpus_new_load, `[`)), stringsAsFactors=F)
dataframe_effects_test<-data.frame(text=unlist(sapply(effects_test_corpus_new_load, `[`)), stringsAsFactors=F)

# Crea un vector vacío
vector_benefits_train<- c()
vector_effects_train <- c()

vector_benefits_test<- c()
vector_effects_test <- c()

# Convertimos el dataframe a vector en train
for (i in 1:length(dataframe_benefits_train[[1]])){ 
  vector_benefits_train[i] <- dataframe_benefits_train[[1]][i]
  vector_effects_train[i] <- dataframe_effects_train[[1]][i]
}

# Convertimos el dataframe a vector en test
for (i in 1:length(dataframe_benefits_test[[1]])){ 
  vector_benefits_test[i] <- dataframe_benefits_test[[1]][i]
  vector_effects_test[i] <- dataframe_effects_test[[1]][i]
}  
```

**Frecuencia del término**

La primera parte de la fórmula $tf(t, d)$ es simplemente calcular el número de veces que aparece cada palabra en cada documento:

1. Creamos el corpus utilizando el vector de string que hemos creado previamente.
2. Generamos la matriz de términos.
3. Convertimos a matriz.

```{r, include=FALSE}
# Creamos el corpus utilizando el vector de string que hemos creado previamente
doc_corpus_benefits_train <-Corpus( VectorSource(vector_benefits_train) )
doc_corpus_effects_train <-Corpus( VectorSource(vector_effects_train) )

doc_corpus_benefits_test <-Corpus( VectorSource(vector_benefits_test) )
doc_corpus_effects_test <-Corpus( VectorSource(vector_effects_test) )

# Generamos la matriz de términos
tdm_benefits_train <- TermDocumentMatrix(doc_corpus_benefits_train)
tdm_effects_train <- TermDocumentMatrix(doc_corpus_effects_train)

tdm_benefits_test <- TermDocumentMatrix(doc_corpus_benefits_test)
tdm_effects_test <- TermDocumentMatrix(doc_corpus_benefits_test)


( tf_benefits_train <- as.matrix(tdm_benefits_train) )
( tf_effects_train <- as.matrix(tdm_effects_train) )

( tf_benefits_test <- as.matrix(tdm_benefits_test) )
( tf_effects_test <- as.matrix(tdm_effects_test) )
```

**Frecuencia inversa del documento**

Durante el cálculo de la frecuencia del término se considera que todos los términos tienen igual importancia, no obstante, se conocen casos en los que ciertos términos pueden aparecer muchas veces pero tienen poca importancia. Esta segunda parte de la fórmula completa el análisis de evaluación de los términos y actúa como corrector de $tf$. Usando la matriz de frecuencia de términos, el peso $idf$ se puede calcular de la siguiente forma:

```{r}
# Calculamos los pesos asociados a cada término en train
terms_benefits_train <- ( idf_benefits_train <- log( ncol(tf_benefits_train) 
                                                / ( 1+rowSums(tf_benefits_train != 0))))
terms_effects_train <- ( idf_effects_train <- log( ncol(tf_effects_train) 
                                                / ( 1+rowSums(tf_effects_train != 0))))

# Calculamos los pesos asociados a cada término en test
terms_benefits_test <- ( idf_benefits_test <- log( ncol(tf_benefits_test) 
                                                / ( 1+rowSums(tf_benefits_test != 0))))
terms_effects_test <- ( idf_effects_test <- log( ncol(tf_effects_test) 
                                               / ( 1+rowSums(tf_effects_test != 0))))

# Muestra los pesos asociados a cada término (los 5 primeros)
terms_benefits_train[1:5] 
```

Ahora que tenemos nuestra matriz con el término frecuencia y el peso idf, estamos listos para calcular el peso total de $tf-idf$. Para hacer esta multiplicación de matrices, también tendremos que transformar el vector $idf$ en una matriz diagonal. Ambos cálculos se muestran a continuación.

1. Creamos la matriz diagonal: `( idf_benefits_train <- diag(idf_benefits_train) )`
2. Hacemos la operación para calcular $tf_idf$ como el producto de $td \cdot idf$: `tf_idf_benefits_train<- crossprod(tf_benefits_train, idf_benefits_train)`
3. Guardamos los datos en ficheros, con el fin de reducir el tiempo de procesamiento.

```{r, include=FALSE}
# Creamos la matriz diagonal
( idf_benefits_train <- diag(idf_benefits_train) )
( idf_effects_train  <- diag(idf_effects_train) )

( idf_benefits_test <- diag(idf_benefits_test) )
( idf_effects_test  <- diag(idf_effects_test) )


# Hacemos la operación para calcular tf_idf como el producto de td * idf
#tf_idf_benefits_train<- crossprod(tf_benefits_train, idf_benefits_train)
#----
# guardamos los datos

#write.csv(tf_idf_benefits_train, file = "datos/ficheros-TFIDF/benefits/tf_idf-benefits-train.csv")
tf_idf_benefits_train_new <- read.csv(file="datos/ficheros-TFIDF/benefits/tf_idf-benefits-train.csv", header=TRUE, sep=",")
#----

#tf_idf_effects_train<- crossprod(tf_effects_train, idf_effects_train)
#----
# guardamos los datos
#write.csv(tf_idf_effects_train, file = "datos/ficheros-TFIDF/effects/tf_idf-effects-train.csv")
tf_idf_effects_train_new <- read.csv(file="datos/ficheros-TFIDF/effects/tf_idf-effects-train.csv", header=TRUE, sep=",")
#----

#tf_idf_benefits_test<- crossprod(tf_benefits_test, idf_benefits_test)
#----
# guardamos los datos
#write.csv(tf_idf_benefits_test, file = "datos/ficheros-TFIDF/benefits/tf_idf-benefits-test.csv")
tf_idf_benefits_test_new <- read.csv(file="datos/ficheros-TFIDF/benefits/tf_idf-benefits-test.csv", header=TRUE, sep=",")
#----

#tf_idf_effects_test<- crossprod(tf_effects_test, idf_effects_test)
#----
# guardamos los datos
#write.csv(tf_idf_effects_test, file = "datos/ficheros-TFIDF/effects/tf_idf-effects-test.csv")
tf_idf_effects_test_new <- read.csv(file="datos/ficheros-TFIDF/effects/tf_idf-effects-test.csv", header=TRUE, sep=",")
#----

# Sustituye referencias por términos (columnas de tf_idf son igual a las filas de tf)
colnames(tf_idf_benefits_train_new) <- rownames(tf_benefits_train)
colnames(tf_idf_effects_train_new) <- rownames(tf_effects_train)

colnames(tf_idf_benefits_test_new) <- rownames(tf_benefits_test)
colnames(tf_idf_effects_test_new) <- rownames(tf_effects_test)
```

Hay que recordar que en la sección $tf$ (frecuencia del término), estamos representando cada término como el número de veces que aparecieron en el documento. El principal problema para esta representación es que creará un sesgo hacia documentos largos, ya que un término dado tiene más posibilidades de aparecer en documentos más largos, lo que los hace parecer más importantes de lo que realmente son. Por lo tanto, el enfoque para resolver este problema es la normalización:

$$ t\_benefits\_train = \frac{tf\_idf\_benefits\_train\_new}{\sqrt(rowSums( tf\_idf\_benefits\_train\_new^2 ) )}$$

```{r, include=FALSE}
# Normalización
t_benefits_train <- tf_idf_benefits_train_new / sqrt( rowSums( tf_idf_benefits_train_new^2 ) )
t_effects_train <- tf_idf_effects_train_new / sqrt( rowSums( tf_idf_effects_train_new^2 ) )

t_benefits_test <- tf_idf_benefits_test_new / sqrt( rowSums( tf_idf_benefits_test_new^2 ) )
t_effects_test <- tf_idf_effects_test_new / sqrt( rowSums( tf_idf_effects_test_new^2 ) )


# Creamos un vector vacío
v_benefits_train <- c()
v_effects_train <- c()

v_benefits_test <- c()
v_effects_test <- c()

# Realiza la suma de todos los pesos de los términos y los almacena en un vector
for (i in 1:length(dataframe_benefits_train[[1]])){
  v_benefits_train[i] <- sum(t_benefits_train[,i])
  v_effects_train[i] <- sum(t_effects_train[,i])
}

for (i in 1:length(dataframe_benefits_test[[1]])){
  v_benefits_test[i] <- sum(t_benefits_test[,i])
  v_effects_test[i] <- sum(t_effects_test[,i])
}


# Convertimos a matriz
terms1_benefits_train <- as.matrix(terms_benefits_train)
terms1_effects_train <- as.matrix(terms_effects_train)

terms1_benefits_test <- as.matrix(terms_benefits_test)
terms1_effects_test <- as.matrix(terms_effects_test)


# Me quedo solo con los términos
terms1_benefits_train <- rownames(terms1_benefits_train)
terms1_effects_train <- rownames(terms1_effects_train)

terms1_benefits_test <- rownames(terms1_benefits_test)
terms1_effects_test <- rownames(terms1_effects_test)


# Me quedo solo con los términos
terms1_5_benefits_train <- terms1_benefits_train[1:length(dataframe_benefits_train[[1]])]
terms1_5_effects_train <- terms1_effects_train[1:length(dataframe_effects_train[[1]])]

terms1_5_benefits_test <- terms1_benefits_test[1:length(dataframe_benefits_test[[1]])]
terms1_5_effects_test <- terms1_effects_test[1:length(dataframe_effects_test[[1]])]


# Unimos la tabla de términos y valores en x
x_benefits_train <- cbind(terms1_5_benefits_train,v_benefits_train)
x_effects_train <- cbind(terms1_5_effects_train,v_effects_train)

x_benefits_test <- cbind(terms1_5_benefits_test,v_benefits_test)
x_effects_test <- cbind(terms1_5_effects_test,v_effects_test)


# Convertimos dicha tabla a dataframe
x1_benefits_train <- as.data.frame(x_benefits_train)
x1_effects_train <- as.data.frame(x_effects_train)

x1_benefits_test <- as.data.frame(x_benefits_test)
x1_effects_test <- as.data.frame(x_effects_test)


# Guardamos en z los valores de x1 ordenados
z_benefits_train <- x1_benefits_train[order(v_benefits_train, decreasing = TRUE),]
z_effects_train <- x1_effects_train[order(v_effects_train, decreasing = TRUE),]

z_benefits_test <- x1_benefits_test[order(v_benefits_test, decreasing = TRUE),]
z_effects_test <- x1_effects_test[order(v_effects_test, decreasing = TRUE),]


# Ordenamos los datos, respetando el orden de los niveles de los factores. Referencia :https://rstudio-pubs-static.s3.amazonaws.com/7433_4537ea5073dc4162950abb715f513469.html
z_benefits_train$terms1_5_new_benefits_train <- factor(z_benefits_train$terms1_5_benefits_train, levels = (z_benefits_train$terms1_5_benefits_train[order(z_benefits_train$v_benefits_train, decreasing = TRUE)]))

# Nos quedamos con los primeros 20 valores
z_benefits_train$terms1_5_new_benefits_train[1:20]
```

A continuación, vamos a visualizar los términos que más se repiten para el conjunto train de _benefits_:

```{r}
# Graficamos los resultados para benefits train
ggplot() + 
 geom_bar(data=z_benefits_train[1:10,],
          aes(x=z_benefits_train$terms1_5_new_benefits_train[1:10],
          y=z_benefits_train$v_benefits_train[1:10]), stat='identity', 
          position='dodge') + 
  ggtitle("Las 10 palabras que más se repiten con TFIDF") + 
  xlab("Términos") +
  ylab("Frecuencia de los términos")
```

```{r, warning=FALSE, include=FALSE}
# INTENTAR ARREGLAR
# wordlcoud ver como arreglar
# SIGUE SIN SALIR

z_benefits_train$v2 <- as.numeric(z_benefits_train$v_benefits_train)

wordcloud(
 words = z_benefits_train$terms1_5_benefits_train,
 freq = z_benefits_train$v2,
 max.words = 20,
 random.order = F,
 colorPalette="Dark2"
 )
```

<!-------------------------------------------------------------------------------------------->

### 2.2.17. Stemming

El siguiente paso consiste en reducir el número de palabras totales con las que estamos trabajando. En este caso, se trata de reducir aquellas que no nos aportan nada relevante a lo que ya tenemos. En la columna con la que estamos trabajando en este dataframe, se repite una gran cantidad de veces la palabra "benefit", al igual que "benefits". 

Sin embargo, realizar el análisis de nuestros datos con ambas palabras no tiene gran relevancia, ya que una no aporta nada respecto a la otra. Este es un ejemplo del tipo de casos que se nos dan en nuestro dataset. Igual ocurre con "reduce" y "reduced", por ejemplo. Este tipo de situaciones son las que intentamos corregir con este paso. Vamos a ver un ejemplo de este suceso, que se da por ejemplo en los siguientes valores del corpus (y en muchos más). 

```{r}
inspect(benefits_train_corpus_new_load[183])
inspect(benefits_train_corpus_new_load[213])
```

A continuación, aplicamos el proceso de stemming mediante la siguiente orden:

```{r, warning=FALSE}
benefits_train_corpus_new_load <- tm_map(benefits_train_corpus_new_load, stemDocument)
effects_train_corpus_new_load <- tm_map(effects_train_corpus_new_load, stemDocument)

benefits_test_corpus_new_load <- tm_map(benefits_test_corpus_new_load, stemDocument)
effects_test_corpus_new_load <- tm_map(effects_test_corpus_new_load, stemDocument)
```

Si ahora volvemos a mostrar el contenido de dichas opiniones, podemos ver que el stemming se ha hecho efectivo: donde ponía \textit{benefits}, ahora pone \textit{benefit}, como se puede comprobar si volvemos a mostrar dichos elementos del corpus. De hecho, si nos fijamos, no solo esta palabra ha resultado modificada, sino que se han resumido muchas más palabras en comparación a como teníamos los documentos en el momento previo a la aplicación del método \textit{Stem}. Desde este momento, ya tenemos nuestro conjunto reducido a nivel de concepto.

```{r}
inspect(benefits_train_corpus_new_load[183])
inspect(benefits_train_corpus_new_load[213])
```

<!-------------------------------------------------------------------------------------------->

### 2.2.18. Valores perdidos

Tras el proceso de limpieza anterior en un volumen tan grande de datos cabe esperar que algún documento estuviera formado por tan solo palabras vacías, enlaces o combinaciones de estos, es por ello, que por medio de filtrado básico de R se obtienen aquellos que no contienen ninguna palabra y se elimina del conjunto del dataset para evitar problemas en los procesos posteriores.

```{r, eval=FALSE}
# https://github.com/joseangeldiazg/twitter-text-mining/blob/master/ner.R
# Localizamos posibles valores perdidos que se hayan generado tras el proceso de limpieza
which(benefits_train_corpus_new_load$content=="")
which(effects_train_corpus_new_load$content==" ")
which(benefits_test_corpus_new_load$content=="  ")
which(effects_test_corpus_new_load$content=="   ")

# Vemos que no hay muchos vacios 
benefits_train_corpus_new_load<-benefits_train_corpus_new_load[
  which(benefits_train_corpus_new_load$content!="")]
effects_train_corpus_new_load<-effects_train_corpus_new_load[
  which(effects_train_corpus_new_load$content!=" ")]
benefits_test_corpus_new_load<-benefits_test_corpus_new_load[
  which(benefits_test_corpus_new_load$content!="  ")]
effects_test_corpus_new_load<-effects_test_corpus_new_load[
  which(effects_test_corpus_new_load$content!="   ")]
```

<!-------------------------------------------------------------------------------------------->

### 2.2.19. Borrar espacios en blanco innecesarios

Hasta el momento hemos hecho distintos cambios en el texto de nuestro dataset. No solo hemos modificado algunas palabras, sino que también hemos borrado otras muchas. Por ello, es adecuado asegurarnos de que no hay más espacios en blanco que los que separan las palabras del texto. Para asegurarnos de ello, podemos ejecutar la siguiente orden, que se encarga de suprimir los espacios en blanco sobrantes.

```{r, warning=FALSE}
benefits_train_corpus_new_load <- tm_map(benefits_train_corpus_new_load, stripWhitespace) 
effects_train_corpus_new_load <- tm_map(effects_train_corpus_new_load, stripWhitespace) 

benefits_test_corpus_new_load <- tm_map(benefits_test_corpus_new_load, stripWhitespace) 
effects_test_corpus_new_load <- tm_map(effects_test_corpus_new_load, stripWhitespace) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.20. Sparsity

También puede resultar muy útil eliminar los términos que aparecen en muy pocos documentos antes de proceder a la clasificación. El motivo principal es la factibilidad computacional, ya que este proceso reduce drásticamente el tamaño de la matriz sin perder información significativa. Además puede eliminar errores en los datos, como podrían ser palabras mal escritas. Para suprimir estos términos, denominados escasos, se utiliza el comando `removeSparseTerms()`.

$$ df(t) > N \cdot (1 != sparse)$$
siendo $df$ la frecuencia de documentos del término $t$ y $N$ el número de vectores. El parámetro sparse toma valores entre 0 y 1. En este caso, el umbral de escasez es 0.999, se toman los términos que aparecen en más del 1\% de documentos.

```{r}
dtm <- DocumentTermMatrix(benefits_train_corpus_new_load)
inspect(dtm)
dtm <- removeSparseTerms(dtm, sparse=0.999)
inspect(dtm)
```

Se observa como de 5835 términos pasamos a 1702 términos, por tanto se ha considerado despreciar aplicar esta técnica ya que necesitamos todos los datos para la aplicación de las técnicas posteriores. Luego, en función de la técnica que se aplique, si fuera necesario se reducirá la dimensionalidad. En definitiva, ya tenemos nuestros datos listos.

<!-------------------------------------------------------------------------------------------->

### 2.2.21. Matriz de documentos de los términos

Ahora vamos a mapear nuestro corpus creando una matriz de términos, donde las filas corresponden a los documentos y las columnas a los términos. Para ello usaremos la función TermDocumentMatrix:

```{r}
matrix_corpus <- TermDocumentMatrix(benefits_train_corpus_new_load)
```

Podemos observar que tenemos 5838 términos, esto quiere decir que tenemos 5838 palabras diferentes en nuestro Corpus. Obtengamos la *frecuencia de las palabras*:

```{r, include=FALSE}
class(matrix_corpus)
```

Como podemos ver, actualmente aún no tenemos nuestros datos en la matriz que buscamos, sino en un vector, por tanto:

```{r, include=FALSE}
matrix_corpus <- as.matrix(matrix_corpus)
class(matrix_corpus)
dim(matrix_corpus) 
```

Con este método, hemos obtenido la ocurrencia de las palabras que tenemos en nuestro dataset para cada uno de los documentos/comentarios. Esta matriz tiene 5838 columnas, que representa la totalidad de palabras diferentes que hay en los comentarios de la columna \textit{benefitsReview}, y 3107 filas, donde cada una representa un comentario. Por tanto, en la fila iésima la matriz, tendremos la ocurrencia de las palabras en \textit{benefitsReview} que existen en el comentario \textit{i}.

```{r}
# Sumamos las filas
suma_matrix_corpus <- rowSums(matrix_corpus)
head(suma_matrix_corpus,5)

# Ordenamos de mayor a menor y muestra los 10 primeros
ordena_mayor_matrix_corpus <- sort(suma_matrix_corpus, decreasing = TRUE)
head(ordena_mayor_matrix_corpus,10)
copia_ordena_mayor = ordena_mayor_matrix_corpus # Para graficos (evitando data.frame)

# Ordenamos de menor a mayor y muestra los 10 primeros
ordena_menor_matrix_corpus <- sort(suma_matrix_corpus, decreasing = FALSE)
head(ordena_menor_matrix_corpus,10)
```

```{r}
# Transformamos a objeto data.frame, con dos columnas (palabra, frec), 
#para posteriormente graficarlo.
ordena_mayor_matrix_corpus <- data.frame(palabra = names(ordena_mayor_matrix_corpus), 
                                         frec = ordena_mayor_matrix_corpus)
```

Mostramos las más frecuentes:

```{r}
ordena_mayor_matrix_corpus[1:20,]
```

Y obtenemos la *gráfica*:

```{r}
copia_ordena_mayor <- as.matrix(copia_ordena_mayor)
barplot(copia_ordena_mayor[1:10,],  xlab="Palabras", ylab="Número de frecuencia",
        col = c("lightblue", "mistyrose", "lightcyan",
                "lavender", "cornsilk"))
title(main = list("Las nueve palabras más frecuentes después del preprocesamiento", font = 4))
```

### 2.2.22. Nube de palabras

Por último, vamos a visualizar la nube de palabras para benefits preprocesado, tanto al principio del procesamiento como al final.


```{r, include=FALSE, eval=FALSE}
library(tidyverse)
library(readr)
library(RColorBrewer)
library(tidytext)
library(wordcloud)
library(tm)

data_benefits <- read.csv(file="datos/datos_train_preprocesado.csv")
View(data_benefits)
data_benefits$items <- as.character(data_benefits$benefits_preprocesado) # ordena_mayor_matrix_corpus

# Función para crear el wordcloud 
cloud_negative_positive <- function(data){
#   
  drugstext <- unnest_tokens(data, word, items)
# 
  binarytextscore <- get_sentiments(lexicon = "bing")
#     
  drugscloudbinary <- drugstext %>%
    inner_join(binarytextscore, by = "word") %>%
     count(word, sentiment) %>%
     mutate(color = ifelse(sentiment == "positive", "darkgreen", "red"))
 
   drugscloudbinary
}
#

res <- cloud_negative_positive(data_benefits)
wordcloud(res$word, res$n, random.order = FALSE, colors = res$color, ordered.colors = TRUE)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{imagenes/wordcloud1.png}
    \caption{Wordcloud con preprocesamiento}
    \label{benefits2}
\end{figure}



```{r, warning=FALSE, include=FALSE, eval=FALSE}
# sin preprocesar los datos

library(tidyverse)
library(readr)
library(RColorBrewer)
library(tidytext)
library(wordcloud)
library(tm)

datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",quote = "\"", header=TRUE)
#benefits_corpus = Corpus(VectorSource(datos_train$benefitsReview))
#benefits_corpus <- tm_map(benefits_corpus, content_transformer(tolower))
#benefits_corpus <- tm_map(benefits_corpus, content_transformer(removePunctuation))
#benefits_corpus <- tm_map(benefits_corpus, content_transformer(removeWords), stopwords("english"))
#benefits_corpus <- tm_map(benefits_corpus, stripWhitespace)
datos_train$items <- as.character(datos_train$benefitsReview)

drugstext <- unnest_tokens(datos_train, word, items)
binarytextscore <- get_sentiments(lexicon = "bing")
    
drugscloudbinary <- drugstext %>%
    inner_join(binarytextscore, by = "word") %>%
    count(word, sentiment) %>%
    mutate(color = ifelse(sentiment == "positive", "darkgreen", "red"))
wordcloud(drugscloudbinary$word, drugscloudbinary$n, random.order = FALSE, colors = drugscloudbinary$color, ordered.colors = TRUE)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{imagenes/wordcloud2.png}
    \caption{Wordcloud sin preprcesamiento}
    \label{benefits2}
\end{figure}

<!-------------------------------------------------------------------------------------------->

## 2.2.23. Convertir a dataframe nuestras modificaciones

Por último, con el fin de mejorar los tiempos computacionales y poder hacer uso todos los integrantes del grupo de las columnas preprocesadas, se ha optado por añadir dichos cambios en el dataset y guardarlos en un fichero.

```{r, include=FALSE}
benefits_train_dataframe <- data.frame(text=unlist(sapply(benefits_train_corpus_new_load, `[`)), stringsAsFactors=F)
effects_train_dataframe <- data.frame(text=unlist(sapply(effects_train_corpus_new_load, `[`)), stringsAsFactors=F)

benefits_test_dataframe <- data.frame(text=unlist(sapply(benefits_test_corpus_new_load, `[`)), stringsAsFactors=F)
effects_test_dataframe <- data.frame(text=unlist(sapply(effects_test_corpus_new_load, `[`)), stringsAsFactors=F)

# Añadimos las dos filas train al conjunto
library(data.table)
datos_train_preprocesado = data.frame(datos_train, benefits_train_dataframe)
setnames(datos_train_preprocesado, "text", "benefits_preprocesado")
datos_train_preprocesado = data.frame(datos_train_preprocesado, effects_train_dataframe)
setnames(datos_train_preprocesado, "text", "effects_preprocesado")

# Añadimos las dos filas train al conjunto
library(data.table)
datos_test_preprocesado = data.frame(datos_test, benefits_test_dataframe)
setnames(datos_test_preprocesado, "text", "benefits_preprocesado")
datos_test_preprocesado = data.frame(datos_test_preprocesado, effects_test_dataframe)
setnames(datos_test_preprocesado, "text", "effects_preprocesado")

# Guardamos en ficheros
library(data.table)
write.csv(datos_train_preprocesado, file = "datos/datos_train_preprocesado.csv", row.names = FALSE) # guarda un archivo csv
#View(datos_train_preprocesado)



write.csv(datos_test_preprocesado, file = "datos/datos_test_preprocesado.csv", row.names = FALSE) # guarda un archivo csv
#View(datos_test_preprocesado)
```


**_Nota: Cuando se necesite en las sucesivas técnicas, se realizarán las transformaciones necesarias de acuerdo a cada técnica en cuestión._**

<!----------------->

\newpage



```{r, include=FALSE}
# Cargamos los tados
datos_train <- read.table("datos/datos_train_preprocesado.csv", sep=",", 
                          comment.char="",quote = "\"", header=TRUE)

datos_test <- read.table("datos/datos_test_preprocesado.csv", sep=",", 
                         comment.char="",quote = "\"", header=TRUE)
```


# 3. Análisis exploratorio de los datos

El análisis exploratorio de datos o (EDA) engloba un conjunto de técnicas para poder comprender de manera rápida la naturaleza de una colección de datos o dataset. Se basa principalmente en dos criterios: las **estadísticas de resumen**  y la **visualización de datos**.

En primer lugar, vamos a realizar un resumen de nuestros datos utilizando la función `summary()`. Dicha función nos mostrará información relevante para cada una de las columnas del datataset, mostrando información general como valores mínimos, máximos, media, mediana. El resultado que obtenemos al evaluar nuestro dataset es el siguiente:

```{r}
summary(datos_train)
```

A continuación se va a realizar un análisis de la información más relevante no textual, como el valor de **rating** de los usuarios, la **efectividad** y los **efectos secundarios** de dicho medicamento y por último, la **valoración ponderada del rating** teniendo en cuenta la proporción entre efectividad y efectos secundarios del medicamento.


## 3.1. Valoraciones de los medicamentos por parte de los usuarios.

En primer lugar vamos a analizar si el *rating* aportado por los usuarios sobre los medicamentos son buenos o no. Para ello empezamos obteniendo las frecuencias y porcentaje total de las valoraciones aportadas por los usuarios. Por tanto, se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}
# Obtener frecuencias del rating
table(datos_train$rating)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de cada puntuación respecto del total.
table(datos_train$rating)/numDocuments
```

Como podemos observar, hay una mayoría de valoraciones positivas respecto a las negativas. De hecho el mayor porcentaje (casi el 24%) tienen la máxima valoración. Podemos comprobar ésto mediante el uso de la moda.

```{r}
# Función para calcular la moda. Se le pasa como parámetro un atributo
calcularModa<-function(var){
  frec.var<-table(var)
  valor<-which(frec.var==max(frec.var))  # Elementos con el valor m
  names(valor)
}

# Obtenemos la moda para el rating
calcularModa(datos_train$rating)
```

Como resumen en general del rating, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable. La media es la siguiente:

```{r}
# Media
mean(datos_train$rating)
```

La mediana es la siguiente:

```{r}
# Mediana
median(datos_train$rating)
```

El valor medio obtenido es 7 y la mediana es 8. Podemos concluir con dicha información, que en general las valoraciones sobre los medicamentos son bastante positivas, situándose el 50% de dichas valoraciones en el valor 8.

A continuación, se va a visualizar dicha información gráficamente:


```{r Warning=FALSE}
# Histograma de la valoración dada por los usuarios sobre los medicamentos
ratingExploration <- datos_train$rating

hist(ratingExploration,
     main="Rating de los medicamentos",
     xlab="Rating",
     ylab="Frecuencia",
     border="goldenrod3",
     xlim=c(0,10),
     ylim=c(0,800),
     col= "cornsilk",
     breaks=10,)
```

```{r}
# Diagrama de densidad de la valoración dada por los usuarios sobre los medicamentos
plot(density(ratingExploration), 
     main="Densidad del rating",
     xlim=c(0,10),
     )
```

```{r}
# Diagrama de sectores de las valoraciones dadas por los usuarios
pie(table(datos_train$rating))
```

```{r}
# Diagrama de cajas sobre las valoraciones dadas por los usuarios
boxplot(datos_train$rating,main="Rating", col= "cornsilk" )
```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$rating)
```

Como se puede observar, la desviación típica nos da un valor de 2.93. Esto quiere decir que los valores no están concentrados en un único valor, sino que la mayoría se sitúan en un intervalo con distancia 3 respecto de la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 5 y 10.

Esto también nos da como **conclusión** que en general las **opiniones** sobre los medicamentos **son buenas**, puesto que la mayor cantidad se sitúan en el intervalo [5,10].

## 3.2. Efectividad del medicamento

En esta sección, se va a analizar si se consideran que los medicamentos son efectivos o no. Para ello se va a analizar el atributo **effectivenessNumber** (que mide la efectividad del medicamento, siendo 1 menos efectivo y 5 más efectivo).

Empezamos obteniendo las frecuencias y porcentaje total de las anotaciones de efectividad. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}
# Obtener frecuencias del efectivenessNumber
table(datos_train$effectivenessNumber)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de cada valor de efectividad respecto del total
table(datos_train$effectivenessNumber)/numDocuments
```

Como podemos observar, la mayoría de los medicamentos se consideran que son efectivos. De hecho, la mayoría de los medicamentos se consideran altamente efectivos (con un 42%). Podemos ahora comprobar ésto mediante el uso de la moda.

```{r}
# Obtenemos la moda para el efectivenessNumber
calcularModa(datos_train$effectivenessNumber)
```

Como resumen en general de la efectividad, se va a calcular la media y la mediana para obtener la tendencia central de dicha variable. La media es la siguiente:

```{r}
# Media
mean(datos_train$effectivenessNumber)
```

La mediana es la siguiente:

```{r}
# Mediana
median(datos_train$effectivenessNumber)
```

El valor medio obtenido es 3.93 sobre 5 y la mediana es 4. Podemos concluir con dicha información, que en general los medicamentos son bastantes efectivos, situándose el 50% de dichas mediciones sobre el valor 4.

A continuación, se va a visualizar dicha información gráficamente:

```{r}
# Histograma sobre la efectividad de los medicamentos
efecctivenessNumberExploration <- datos_train$effectivenessNumber

hist(efecctivenessNumberExploration,
     main="Efectividad de los medicamentos",
     xlab="Nivel de efectividad",
     ylab="Frecuencia",
     border="green",
     xlim=c(1,5),
     col= "darkseagreen1",
     breaks=5,
     prob=TRUE
    )
```

```{r}
# Diagrama de densidad de la efectividad de los medicamentos
plot(density(datos_train$effectivenessNumber), 
     main="Densidad de la tasa de efectividad",
     xlim=c(0,5),
     )
```

```{r}
# Diagrama de sectores de la efectividad de los medicamentos
pie(table(datos_train$effectivenessNumber))
```


```{r}
# Diagrama de cajas sobre la efectividad de los medicamentos
boxplot(datos_train$effectivenessNumber,main="Tasa de efectividad", col= "darkseagreen1" )
```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$effectivenessNumber)
```

Como se puede observar, la desviación típica nos da un valor de 1.23. Esto quiere decir que la mayor parte de los valores se sitúan en un intervalo con una distancia de uno de la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 3 y 5.

Esto también nos da como **conclusión** que en general los medicamentos tienen una tasa bastante **buena de efectividad** puesto que su tasa se sitúa entre [3,5].


## 3.3. Efectos secundarios del medicamento

En esta sección, se va a analizar si se consideran que los medicamentos tienen efectos secundarios o no. Para ello se va a analizar el atributo **sideEffectsNumber** (que mide la tasa de efectos secundarios del medicamento, siendo 1 el mínimo de efectos secundarios y 5 el máximo de efectos secundarios). 

Empezamos obteniendo las frecuencias y porcentaje total de las anotaciones de efectos secundarios. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}
# Obtener frecuencias del sideEffectsNumber
table(datos_train$sideEffectsNumber)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de tasa de efectos secundarios respecto del total.
table(datos_train$sideEffectsNumber)/numDocuments
```

Como podemos observar, la mayoría de los medicamentos se consideran que no tienen efectos secundarios severos. De hecho, la mayoría de los medicamentos se sitúan entre sin efectos secundarios (29%) o que tienen efectos secundarios leves (32%).

Podemos comprobar ésto mediante el uso de la moda.

```{r}
# Obtenemos la moda para el sideEffectsNumber
calcularModa(datos_train$sideEffectsNumber)
```

Como resumen en general, sobre la tasa de efectos secundarios, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable. La media es la siguiente:

```{r}
# Media
mean(datos_train$sideEffectsNumber)
```

La mediana es la siguiente:

```{r}
# Mediana
median(datos_train$sideEffectsNumber)
```

El valor medio obtenido es 2.30 sobre 5 y la mediana es 2. Podemos concluir con dicha información, que en general los medicamentos no tienen efectos secundarios o que dichos efectos son leves.

A continuación, se va a visualizar dicha información gráficamente:

```{r}
# Histograma de la tasa de efectos secundarios
sideEffectsNumberExploration <- datos_train$sideEffectsNumber

hist(sideEffectsNumberExploration,
     main="Efectos secundarios de los medicamentos",
     xlab="Nivel de efectos secundarios",
     ylab="Frecuencia",
     border="white",
     xlim=c(1,5),
     col= "firebrick2",
     breaks=5,
     prob=TRUE
    )
```


```{r}
# Diagrama de densidad sobre la tasa de efectos secundarios
plot(density(datos_train$sideEffectsNumber), 
     main="Densidad de la tasa de efectos secundarios",
     xlim=c(0,5),
     )
```

```{r}
# Diagrama de sectores de los efectos secundarios de los medicamentos
pie(table(datos_train$sideEffectsNumber))
```


```{r}
# Diagrama de cajas de los efectos secundarios de los medicamentos
boxplot(datos_train$effectivenessNumber,main="Tasa de efectos secundarios", col= "firebrick2" )
```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$sideEffectsNumber)

```

Como se puede observar, la desviación típica nos da un valor de 1.17. Esto quiere decir que la mayor parte de los valores se sitúan en un intervalo con una distancia de uno respecto la media. Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 1 y 2.

Esto también nos da como **conclusión** que en general los medicamentos **no tienen efectos secundarios o son muy leves**.



## 3.4. Valoración ponderada sobre el medicamento


En esta sección, se va a analizar si se consideran que los medicamentos son buenos o no teniendo en cuenta la relación entre los beneficios que aporta (efectividad) y las inconvenientes que tiene (efectos secundarios). Para ello se va a analizar el atributo **weightedRating** (que mide dicha relación teniendo en cuenta una tasa de efectividad del 30% y una tasa de efectos secundarios del 70%), y siendo 1 peor valorado y 10 mejor valorado.

Empezamos obteniendo las frecuencias y porcentaje total de las anotaciones sobre la puntuación ponderada. Para ello se va a calcular la frecuencia de dicho atributo y su porcentaje respecto del total.

```{r}
# Obtener frecuencias del weightedRating
table(datos_train$weightedRating)

# Calculamos el número de documentos
numDocuments <- dim(datos_train)[1]

# Calculamos el porcentaje de puntuación ponderada respecto del total.
table(datos_train$weightedRating)/numDocuments
```


Como podemos observar, la mayoría de los medicamentos se consideran que son generalmente beneficiosos. De hecho, la mayoría de los medicamentos se sitúan con una valoración de 8 sobre 10 teniendo en cuenta la relación beneficio/perjuicio. Podemos comprobar ésto mediante el uso de la moda.

```{r}
# Obtenemos la moda para el weightedRating
calcularModa(datos_train$weightedRating)
```


Como resumen en general de sobre la tasa de efectos secundarios, se va a calcular la media y la mediana para calcular la tendencia central para dicha variable. La media es la siguiente:

```{r}
# Media
mean(datos_train$weightedRating)
```

La mediana es la siguiente:


```{r}
# Mediana
median(datos_train$weightedRating)
```

El valor medio obtenido es 7.52 sobre 10 y la mediana es 2. Podemos concluir con dicha información que la puntuación general sobre los medicamentos es de **notable**.

A continuación, se va a visualizar dicha información gráficamente:

```{r}
# Histograma de valoración ponderada
weightedRatingExploration <- datos_train$weightedRating

hist(weightedRatingExploration ,
     main="Valoración ponderada de los medicamentos",
     xlab="Rating ponderado",
     ylab="Frecuencia",
     border="blue",
     xlim=c(0,10),
     col= "dodgerblue1",
     breaks=5
     
    )
```



```{r}
# Diagrama de densidad sobre la valoración ponderada
plot(density(datos_train$weightedRating), 
     main="Densidad de valoración ponderada",
     xlim=c(0,10),
     )

```

```{r}
# Diagrama de sectores sobre la valoración ponderada
pie(table(datos_train$weightedRating))
```


```{r}
# Diagrama de cajas sobre la valoración ponderada
boxplot(datos_train$weightedRating,main="Valoración ponderada", col= "dodgerblue1" )
```

Como medidas de dispersión, se va a calcular la **desviación típica**:

```{r}
# Desviación típica
sd(datos_train$weightedRating)
```

Como se puede observar, la desviación típica nos da un valor de 2.07. Esto quiere decir que la mayor parte de los valores se sitúan en un intervalo con una distancia de dos sobre la media.

Este valor concuerda, puesto que si observamos el histograma anterior, vemos que la mayoría de las puntuaciones se sitúan entre 6 y 10.

Esto también nos da como **conclusión** que en general los medicamentos **son convenientes tomarlos**.



## 3.5. Correlación sobre las variables

En esta sección se va a comprobar la correlación que existe entre las variables que miden la efectividad(effectivenessNumber), los efectos secundarios(sideEffectsNumber), la valoración aportada por los usuarios(rating) y la valoración ponderada que se ha realizado sobre el medicamento(weightedRating).

Empezamos calculando la correlación entre la variable que mide la efectividad y los efectos secundarios.

```{r}
# Correlación lineal entre efectivenessNumber y sideEffectsNumber
cor(datos_train[,c(8,9)])
```

Podemos observar que cuantos más efectos secundarios tiene, menor es la efectividad del medicamento. Esto puede estar influido por las valoraciones subjetivas del usuario, ya que si ha tenido una mala experiencia (debido a los efectos secundarios) por la ingesta del medicamento, no va a hacer énfasis en los beneficios del medicamento, sino que hará un mayor énfasis en los aspectos negativos. 


A continuación vamos a calcular la correlación entre la efectividad y la valoración ponderada del medicamento.

```{r}
# Correlación lineal entre efectivenessNumber y weightedRating
cor(datos_train[,9:10])
```

Como se puede observar, cuando el medicamento es más efectivo, la valoración ponderada del medicamento acumenta (como es obvio), y si ahora calculamos la valoración ponderada del medicamento teniendo en cuenta los efectos secundarios.

```{r}
# Correlación lineal entre sideEffectsNumber y weightedRating
cor(datos_train[,c(8,10)])
```

Observamos como si el medicamento tiene una mayor tasa de efectos secundarios, la valoración ponderada disminuye considerablemente (obvio porque el 70% de la valoración ponderada tiene en cuenta los efectos secundarios del medicamento).

Ahora vamos a comprobar la relación que existe entre la valoración dada por el usuario y los efectos secundarios.


```{r}
# Correlación lineal entre rating y sideEffectsNumber
cor(datos_train[,c(2,8)])
```

Podemos comprobar como si el medicamento tiene una mayor tasa de efectos secundarios, la valoración dada por el usuario disminuye.

```{r}
# Correlación lineal entre rating y effectivenessNumber
cor(datos_train[,c(2,9)])
```

Y si la efectividad del medicamento es alta, la valoración del usuario se incrementa.

Como observación general, se puede destacar que **la valoración del usuario está condicionada más por la efectividad del medicamento** (relación 1/0.74) que por los efectos secundarios (relación 1/-0.68).

Por último, vamos a observar en el siguiente gráfico como se relacionan las variables entre sí en función se sus valores.

```{r}
# Gráfico de coordenadas paralelas
library(MASS)
parcoord(datos_train[,c(8,9,2,10)], col=datos_train$rating,var.label=T)
```

Por ejemplo, podemos destacar como si el número de efectos secundarios es 1 (no tiene efectos secundarios) y la efectividad del medicamento es 5 (muy efectivo), entonces la valoración del usuario será 10 y la valoración ponderada será también 10.


\newpage
<!------->

# 4. Análisis de sentimientos

En este apartado vamos a realizar un análisis descriptivo de los datos. En esta ocasión, vamos a visualizar cuáles son los sentimientos que expresan las personas en los comentarios que escriben sobre los distintos medicamentos que se encuentran en nuestro dataset. Lo haremos de los comentarios relacionados con los beneficios y efectos de los medicamentos.

```{r eval=FALSE, include=FALSE}
library(syuzhet)
library(ggplot2)
datos_train <- read.table("datos/datos_train_preprocesado.csv", sep=",", comment.char=""
                          ,quote = "\"", header=TRUE)
```

La idea que se nos ocurrió consiste en saber cuales son los medicamentos y condiciones más frecuentes que ocurren, ya que mostrar toda la información puede saturar la visibilidad de los datos. 

```{r eval=FALSE}
summary(datos_train)

#https://stackoverflow.com/questions/1686569/filter-data-frame-rows-by-a-logical-condition
condiciones = c("depression","acne","anxiety","insomnia","birth control","high blood pressure")
medicamentos = c ("lexapro","prozac","retin-a","zoloft","paxil","propecia")
```

Gracias al resumen de nuestro dataset sabemos rápidamente cuales son las drogas y condiciones más comunes. Ahora vamos a hacer un análisis de sentimientos de los comentarios relacionados con estas drogas y condiciones.

```{r eval=FALSE}
analisis_sentimientos <- function(comentarios,titulo){
  
  comentarios = Corpus(VectorSource(comentarios))
  
  d <- get_nrc_sentiment(comentarios$content)
  
  #https://medium.com/swlh/exploring-sentiment-analysis-a6b53b026131
  dt <- data.frame(t(d))
  
  sentimientos <- data.frame(rowSums(dt))
  
  names(sentimientos)[1] <- "count"
  sentimientos <- cbind("sentiment" = rownames(sentimientos), sentimientos)
  rownames(sentimientos) <- NULL
 
  qplot(sentiment, data=sentimientos[1:8,], weight=count, geom="bar",fill=sentiment)+
    ggtitle(titulo)
  ggsave(paste(titulo,".png"),path = 'figuras/sentimientos')
  
  
  qplot(sentiment, data=sentimientos[9:10,], weight=count, geom="bar",fill=sentiment)+
    ggtitle(titulo)
  ggsave(paste(titulo,"_positivismo.png"),path = 'figuras/sentimientos')

}
```

Básicamente lo que llevamos a cabo en esta función es la generación del Corpus de los comentarios pasados como parámetros (ya preprocesados). El siguiente paso es generar la tabla de sentimientos traspuesta, sino hacemos esto no funciona debido a la disposición de los datos. Luego preparamos una fila en la que aparezcan el nombre de los sentimientos en el mismo orden que la tabla y borramos los nombres de las filas. Esto último se realiza para la correcta visualización de los datos.

Por último se lleva a cabo la representación en forma de gráficas de los comentarios de la gente. Recordemos, están acotadas a conjuntos de comentarios para las drogas y condiciones más comunes, por separado.

Obtenemos las gráficas mencionadas:

```{r  eval=FALSE}
for(cadena in condiciones){
  datos <- datos_train[datos_train$condition==cadena ,]
  analisis_sentimientos(datos$benefits_preprocesado,
                        paste("Comentarios_beneficios_de_condición_",cadena))
}
```

```{r eval=FALSE}
for(cadena in condiciones){
  datos <- datos_train[datos_train$condition==cadena ,]
  analisis_sentimientos(datos$effects_preprocesado,
                        paste("Comentarios_efectos_de_condición_",cadena))
}
```

```{r, eval=FALSE}
for(cadena in medicamentos){
  datos <- datos_train[datos_train$urlDrugName==cadena ,]
  analisis_sentimientos(datos$benefits_preprocesado,
                        paste("Comentarios_beneficio_de_medicamento_",cadena))
}
```

```{r, eval=FALSE}
for(cadena in medicamentos){
  datos <- datos_train[datos_train$urlDrugName==cadena ,]
  analisis_sentimientos(datos$effects_preprocesado,
                        paste("Comentarios_efectos_de_medicamento_",cadena))
}
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figuras/elegidas/Comentarios_beneficio_de_medicamento_propecia.png}
    \caption{Análisis de sentimientos de los comentarios sobre los beneficios de los medicamentos para obtener propecia.}
    \label{fig:sentimientos:propeciaSentimiento}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figuras/elegidas/Comentarios_beneficio_de_medicamento_propecia_positivismo.png}
    \caption{Análisis de positivismo de los comentarios sobre los beneficios de los medicamentos para obtener propecia.}
    \label{fig:sentimientos:propeciaSentimiento}
\end{figure}

Hemos visualizado las imágenes resultantes y llegamos a la conclusión de que, en general, hace una buena descripción de los datos. Por ejemplo, para la **propecia** tenemos un altísimo contenido de sentimientos tales como miedo, tristeza y rabia. Mientras que otros sentimientos pasan más desapercibidos. Sin embargo, parece ser que las personas están contentas de forma genérica para el conjunto de medicamentos que la tratan, ya que los comentarios sobre los beneficios de los medicamentos son más positivos que negativos. En cambio, cuando hablamos de los efectos secundarios de este medicamento, el negativismo vence al positivismo, se ve que los efectos secundarios que pueden acarrear este tipo de medicinas no son muy agradables. Los sentimientos de los efectos son muy similares a los que hablan de los beneficios, vemos que hay una concordancia de los comentarios de las personas.

Otro dato curioso es que, de forma genérica, hay una mayor presencia de negativismo que positivismo. Hay que darse cuenta de que las personas están escribiendo sobre problemas de salud que tienen, por lo que el único punto positivo que podemos extraer es cuando una persona muestra su felicidad al ver que un cierto medicamento está surtiendo efecto (y aún así es posible que se queje igualmente por los efectos secundarios, por ejemplo).

Hay que destacar que los sentimientos están muy entremezclados en los comentarios presentes de nuestro dataset. Los valores del rating vendrán especificados implicitamente dependiendo del peso que le de cada persona a esos sentimientos. En definitiva, nos damos cuenta de que nuestro dataset es bastante subjetivo. Por ejemplo, las personas suelen mostrarse más dispuestas a expresar comentarios para quejarse que para informar de que un medicamento le está funcionando.

Todas estas gráficas pueden apreciarse en el anexo de esta práctica por si se quiere ver el resto de condiciones y medicamentos analizados con esta técnica.


\newpage

# 5. Reglas de Asociación

En esta técnica haremos un análisis descriptivo de los datos de texto. Buscaremos la relación que existe entre las palabras expuestas en los distintos comentarios sobre los medicamentos y tratatemos de asociarlos a distintos conceptos para tener una mejor idea de nuestro dataset. Esto nos permitirá saber de antemano que palabras a priori pueden tener que ver algo con distintos efectos de los medicamentos.

```{r, eval=FALSE, include=FALSE}
datos_train <- read.table("datos/datos_train_preprocesado.csv", sep=",",
                          comment.char="",quote = "\"", header=TRUE)
```

Vamos a crearnos un corpus por cada uno de los tipos de comentarios que tenemos en cada item. Recordar que estos textos ya se encuentran preprocesados como se puede consultar en secciones anteriores de esta documentación.

```{r, eval=FALSE}
benefits_corpus = Corpus(VectorSource(datos_train$benefits_preprocesado))
effects_corpus = Corpus(VectorSource(datos_train$effects_preprocesado))
```

Ahora mismo el dataset es de tipo categórico pero nosotros los necesitamos como una cadena de caracteres para pasos posteriores. Por tanto, todos los datos que se encuentran en estas columnas van a ser transformados. Serán entendidas como palabras diferenciadas.

Una vez que obtenemos las palabras en string, algunas de estas se quedan como palabras vacías, para ello utilizamos la función. Finalmente, ya podemos obtener una base de datos de tipo transaccional.

```{r, eval=FALSE}
items_benefits <- strsplit(as.character(benefits_corpus$content), " ")
items_effects <- strsplit(as.character(effects_corpus$content), " ")

# Para eliminar las cadenas vacías
# https://stackoverflow.com/questions/24178854/remove-blanks-from-strsplit-in-r
items_benefits <- lapply(items_benefits, function(x){x[!x ==""]})
items_effects <- lapply(items_effects, function(x){x[!x ==""]})

transactions_benefits <- as(items_benefits,"transactions")
transactions_effects <- as(items_effects,"transactions")

```

Ya tenemos los datos de textos estructurados en una base de datos transaccional, ahora podemos aplicar la técnica para obtener las reglas de asociación. Vamos a utilizar el algoritmo "a priori" visto en clase. De lo contrario, el coste computacional y de tiempo no sería viable para obtener este conocimineto a partir de los comentarios.

El primer parámetro que encontramos en la función se corresponde con los datos que le proporcionamos y el segundo, un listado de parámetros específicos. En cuanto a estos, el primero es el umbral para el soporte, el segundo el umbral de la confianza, el tercero el target para indicar que buscamos reglas de asociación y en el cuarto indicamos que como mínimo empecemos con itemset de tamaño 2. De esta forma estamos selecciondo un conjunto más reducido de reglas, que es lo que nos interesa desde el principio para ahorrar costes de procesamiento de los datos, al mismo tiempo que perdemos la mínima calidad posible en las reglas.

Ordenamos por "confidence" a vista de mostrar posteriormente los resultados más importantes. Entonces mostraremos las reglas que tienen más confianza (sino no podemos realizar una buena visualización de los datos), y finalmente mostraremos gráficamente el resultado obtenido.

```{r, eval=FALSE}
rules_benefits <- apriori(transactions_benefits, parameter = 
                    list(sup = 0.001, conf = 0.7, target="rules", minlen=2))
rules_effects <- apriori(transactions_effects, parameter =
                    list(sup = 0.001, conf = 0.7, target="rules", minlen=2))

rules_benefits <- sort(rules_benefits, decreasing = TRUE, na.last = NA,
                       by = "confidence")
rules_effects <- sort(rules_effects, decreasing = TRUE, na.last = NA,
                      by = "confidence")

detach(package:tm, unload=TRUE) 
inspect(head(rules_benefits,100))
inspect(head(rules_effects,100))
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figuras/asociacion/reglas_general_beneficios.png}
    \caption{inspect(head(rules\_benefits),100) para visualizar reglas más importantes de los comentarios sobre beneficios.}
    \label{fig:asociacion:reglasBenefits}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figuras/asociacion/reglas_general_beneficios.png}
    \caption{inspect(head(rules\_effects),100) para visualizar reglas más importantes de los comentarios sobre efectos secundarios.}
    \label{fig:asociacion:reglasEffects}
\end{figure}

```{r, eval=FALSE}
plot(rules_benefits, method="graph")
title("Reglas de asociación sobre comentarios de beneficios")
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figuras/asociacion/asociacion_beneficios.png}
    \caption{Mapa de reglas de asociación sobre los comentarios de beneficios.}
    \label{fig:asociacion:benefits}
\end{figure}

Al intentar pintar las reglas de asociación, nos dimos cuenta de que plot no puede con tantas reglas al mismo tiempo, por lo que se queda con las 100 primeras. Como las tenemos ordenadas por confianza, no nos resulta un problema, ya que siempre que ocurra esto cogerá las 100 que más nos interesan.

Tal y como se aprecia en el mapa de asociaciones realizado, vemos que a simple vista las asociaciones obtenidas tienen mucho sentido. Por ejemplo, tenemos *attack* junto con *panic* que están relacionados con un lift considerable a *anxieti*. Cuanto más oscuros sean los puntos quieren decir que el lift es más alto. Por tanto, la aparición de una de las plabaras favorece la aparición de otra.

Vemos que hay consecuentes en las reglas muy frecuentes, que ocupan el centro o núcleo de las reglas de asociación en el mapa. Estas palabras son principalmente *effect* y *side*. Esto también nos parece prometedor, ya que tiene todo el sentido del mundo que la gente haga comentarios siempre en torno a los efectos que tienen los medicamentos que están probando.

Podríamos poner mil ejemplos más. La palabra *acid* favorece que aparezca la palabra *reflux*. La gente cuando habla de reflujo, se refiere al ácido del estómago que sube de forma accidental por el esófago y cauza quemazón.

En definitiva, es una buena forma de tener una vista general sobre lo que hablan las personas en el conjunto de comentarios y tener una idea de que conceptos utilizan más y cómo para expresar los efectos que tienen los medicamentos.

Hicimos lo mismo para los comentarios relacionados con los efectos secundarios.

```{r, eval=FALSE}
plot(rules_effects, method="graph")
title("Reglas de asociación sobre comentarios de efectos secundarios")
```

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{figuras/asociacion/asociacion_efectos.png}
    \caption{Mapa de regla de asociación sobre los comentarios de efectos secundarios.}
    \label{fig:asociacion:effects}
\end{figure}

En este caso, vemos que no hay demasiadas asociaciones con un valor de lift por encima significativamente del resto. Creemos que se debe a que en este punto la gente escribe una diversidad de tipos de comentarios mucho más grande. Es decir, quizás los comentarios sobre efectos secundarios pueda tener una mayor cantidad de variedad sobre lo que se habla que en los comentarios sobre los beneficios.

No obstante, volvemos a tener los mismos consecuentes más frecuentes. Ocupando una vez más el núcleo del mapa de las reglas de asociación: *side* y *effect*. Tiene sentido ya que en los efectos secundarios vuelven a hablar de este tema de forma general, sólo que desde un punto de vista diferente (por eso la estructura principal del mapa y las reglas de asociación son diferentes).

Hay conceptos interesantes como *nausea*, *headach*, *pain*... Conceptos que están estrechamente relacionados con efectos secundarios.

## 5.1. Reglas de asociación específicas 

Llegados a este punto, quisimos darle un nuevo enfoque a la extracción de reglas de asociación a partir de estos comentarios. En los mapas anteriores, veíamos que había demasiadas reglas enfocadas a una misma cosa, incluso llegando a ser difícil de visualizar en algunos sitios concretos.

Por otro lado, temíamos estar tomando solo las reglas de asociación relacionadas con *effects* y *side* por ser las reglas con una mayor confianza y despreciando otras que podían ser interesantes y que tuvieran consecuentes en otros conceptos.

Entonces, se nos ocurrió la siguiente idea: ¿Y si enfocamos la selección de reglas en la que el consecuente sea un término concreto que consideremos interesante? En otras palabras, queremos realizar un filtrado de reglas interesantes directamente guiadas por el usuario, tal y como se ha visto en teoría.

Queremos obtener las reglas en la que los consecuentes sean los valores de efectividad de nuestro dataset. Aquí realizamos un "mini-preprocesamiento", ya que está realizado en apartado anteriores, pero en esta técnica especificamente vimos conveniente realizar estos pequeños cambios y añadirlos en una nueva columna del dataset.

Lo primero que debíamos de hacer es tener la efectividad unida en una sola cadena sin espacios, ya que de lo contrario no sería reconocida como un término a la hora de generar la estructura transaccional posterior.

```{r, eval=FALSE}
datos_train$effectivenessGuion[datos_train$effectiveness == 
                                 "Highly Effective"] <- "Highly-Effective"
datos_train$effectivenessGuion[datos_train$effectiveness == 
                                 "Considerably Effective"] <- "Considerably-Effective"
datos_train$effectivenessGuion[datos_train$effectiveness ==
                                 "Moderately Effective"] <- "Moderately-Effective"
datos_train$effectivenessGuion[datos_train$effectiveness ==
                                 "Marginally Effective"] <- "Marginally-Effective"
datos_train$effectivenessGuion[datos_train$effectiveness ==
                                 "Ineffective"] <- "Ineffective"

# Pasamos a factor el effectivenes unido por guiones para 
# concatenarlo con los comentarios
datos_train$effectivenessGuion = as.factor(datos_train$effectivenessGuion)
```

¿Cómo podemos hacer que estas efectividades sean cosas frecuentes en las reglas en función de los comentarios? Tuvimos una buena idea en este punto. Mientras discutiamos en cómo hacer que el algoritmo a priori pudiera generar estas reglas, pensamos en coger estas etiquetas de efectividad y ponerlas al final de cada comentario como un término más (fila por fila). De esta forma cada comentario tendría una palabra final en la que aparece el nivel de efectividad que el usuario reconoce en el medicamento y podemos pasarlo de esa forma directamente al algoritmo.

```{r, eval=FALSE}
# Juntamos las cadenas en una nueva columna del dataset que combina con los
# comentarios con los beneficios
datos_train$benefits_effectiveness <- with(datos_train, 
                    interaction(benefits_preprocesado,effectivenessGuion), sep=" ")
datos_train$benefits_effectiveness <- gsub("[.]", " ", datos_train$benefits_effectiveness)

# Hacemos lo mismo pero para los comentatios de efectos secundarios
datos_train$effects_effectiveness <- with(datos_train, interaction
                               (effects_preprocesado,effectivenessGuion), sep=" ")
datos_train$effects_effectiveness <- gsub("[.]", " ", datos_train$benefits_effectiveness)

datos_train$effects_effectiveness[1:10]

```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/asociacion/ejemplo_effects_effectiveness.png}
    \caption{Ilustración de preprocesamiento específico para reglas de asociación acotada a efectividad.}
    \label{fig:asociacion:preprocesamientoAsociacion}
\end{figure}

Los pasos siguientes ya son muy parecidos a los explicados anteriormente. Generamos los corpus.

```{r, eval=FALSE}
# Generamos los corpus con estas nuevas columnas en la que 
# añadimos la efectividad como término en cada comentario
benefits_corpus = Corpus(VectorSource(datos_train$benefits_effectiveness))
effects_corpus = Corpus(VectorSource(datos_train$effects_effectiveness))
```

Separamos los términos y eliminamos términos vacíos.

```{r, eval=FALSE}
#Separamos todas las palabras entre sí
benefits_items <- strsplit(as.character(benefits_corpus$content), " ")
effects_items <- strsplit(as.character(effects_corpus$content), " ")
# Para eliminar las cadenas vacías
# https://stackoverflow.com/questions/24178854/remove-blanks-from-strsplit-in-r
benefits_items <- lapply(benefits_items, function(x){x[!x ==""]})
effects_items <- lapply(effects_items, function(x){x[!x ==""]})
```

Generamos las estructuras transaccionales.

```{r, eval=FALSE}
#Generamos la estructura de datos transaccional
benefits_transactions <- as(benefits_items,"transactions")
effects_transactions <- as(effects_items,"transactions")
```

Ahora tenemos que aplicar el algoritmo a priori. La estrategia consiste en hacer que los consecuentes frecuentes sean los tipos de efectividad que puede tener los medicamentos, es una forma más de filtrar reglas y no quedarnos con todas (ya que hemos visto en teoría que esto es computacionalmente muy costoso). Por ello, especificamos que los consecuentes de las reglas obtenidas sean cada una de las etiquetas posibles de este campo (con el guión puesto para las palabras compuestas como hicimos anteriormente). Los parámetros han sido fijados para que nos devuelva un conjunto de reglas razonable.

Finalmente, ordenamos las reglas obtenidas por la confianza que tienen de mayor a menor.

```{r, eval=FALSE}
benefits_rulesInnefective <- apriori (data=benefits_transactions, 
                             parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                             appearance = list(default="lhs",rhs=c("Ineffective")), 
                             control = list (verbose=F))

benefits_rulesHighlyEffective <- apriori (data=benefits_transactions, 
                             parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                             appearance = list(default="lhs",
                                               rhs=c("Highly-Effective")), 
                             control = list (verbose=F))

benefits_rulesConsiderablyEffective <- apriori (data=benefits_transactions, 
                              parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                              appearance = list(default="lhs",
                                                rhs=c("Considerably-Effective")), 
                              control = list (verbose=F))

benefits_rulesModeratelyEffective <- apriori (data=benefits_transactions, 
                              parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                              appearance = list(default="lhs",
                                                rhs=c("Moderately-Effective")), 
                              control = list (verbose=F))

benefits_rulesMarginallyEffective <- apriori (data=benefits_transactions, 
                             parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                             appearance = list(default="lhs",
                                               rhs=c("Marginally-Effective")), 
                             control = list (verbose=F))

benefits_rulesInnefective <- 
  sort(benefits_rulesInnefective, decreasing=TRUE, na.last=NA, by="confidence")
benefits_rulesHighlyEffective <- 
  sort(benefits_rulesHighlyEffective, decreasing=TRUE, na.last = NA, by="confidence")
benefits_rulesConsiderablyEffective <- 
  sort(benefits_rulesConsiderablyEffective, decreasing=TRUE, na.last=NA, by="confidence")
benefits_rulesModeratelyEffective <- 
  sort(benefits_rulesModeratelyEffective, decreasing=TRUE, na.last=NA, by="confidence")
benefits_rulesMarginallyEffective <- 
  sort(benefits_rulesMarginallyEffective, decreasing=TRUE, na.last=NA, by="confidence")
```

Podemos mostrar las 10 reglas de mayor confianza relacionadas con cada uno de los consecuentes.

```{r, eval=FALSE}
detach(package:tm, unload=TRUE)
inspect(head(benefits_rulesInnefective,10))
inspect(head(benefits_rulesHighlyEffective,10))
inspect(head(benefits_rulesConsiderablyEffective,10))
inspect(head(benefits_rulesModeratelyEffective,10))
inspect(head(benefits_rulesMarginallyEffective,10))
library(tm)
```

Hacemos el mismo proceso pero con los comentatios de los efectos secundarios.

```{r, eval=FALSE}
effects_rulesInnefective <- apriori (data=effects_transactions, 
                                 parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                                 appearance = list(default="lhs",rhs=c("Ineffective")), 
                                 control = list (verbose=F))

effects_rulesHighlyEffective <- apriori (data=effects_transactions, 
                             parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                             appearance = list(default="lhs",rhs=c("Highly-Effective")), 
                             control = list (verbose=F))

effects_rulesConsiderablyEffective <- apriori (data=effects_transactions, 
                                parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                                appearance = list(default="lhs",
                                                  rhs=c("Considerably-Effective")), 
                                control = list (verbose=F))

effects_rulesModeratelyEffective <- apriori (data=effects_transactions, 
                                parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                                appearance = list(default="lhs",
                                                  rhs=c("Moderately-Effective")), 
                                control = list (verbose=F))

effects_rulesMarginallyEffective <- apriori (data=effects_transactions, 
                                     parameter=list (supp=0.0007,conf = 0.9, minlen=2), 
                                     appearance = list(default="lhs",
                                                       rhs=c("Marginally-Effective")), 
                                     control = list (verbose=F))


effects_rulesInnefective <- sort(effects_rulesInnefective, 
                                 decreasing=TRUE, na.last=NA, by="confidence")
effects_rulesHighlyEffective <- sort(effects_rulesHighlyEffective, 
                                     decreasing=TRUE, na.last=NA, by="confidence")
effects_rulesConsiderablyEffective <- sort(effects_rulesConsiderablyEffective, 
                                           decreasing=TRUE, na.last = NA, by="confidence")
effects_rulesModeratelyEffective <- sort(effects_rulesModeratelyEffective, 
                                         decreasing=TRUE, na.last = NA, by="confidence")
effects_rulesMarginallyEffective <- sort(effects_rulesMarginallyEffective,
                                         decreasing=TRUE, na.last=NA, by="confidence")
```

Podríamos mostrar las 10 reglas con mayor confianza relacionadas con cada uno de los consecuentes si lo deseamos.

```{r, eval=FALSE}
detach(package:tm, unload=TRUE)
inspect(head(effects_rulesInnefective,10))
inspect(head(effects_rulesHighlyEffective,10))
inspect(head(effects_rulesConsiderablyEffective,10))
inspect(head(effects_rulesModeratelyEffective,10))
inspect(head(effects_rulesMarginallyEffective,10))
library(tm)
```

Finalmente podemos extraer todas los mapas de estas reglas de asociación.

```{r, eval=FALSE}
#Obtenemos las imágenes relacionadas con los comentarios sobre beneficios
# de los medicamentos
png("figuras/asociacion/benefits_Innefective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(benefits_rulesInnefective, method="graph")
title("Comentarios beneficios sobre inefectividad")
dev.off()

png("figuras/asociacion/benefits_HighlyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(benefits_rulesHighlyEffective, method="graph")
title("Comentarios beneficios sobre altamente efectivos")
dev.off()

png("figuras/asociacion/benefits_ConsiderablyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(benefits_rulesConsiderablyEffective, method="graph")
title("Comentarios beneficios sobre considerablemente efectivos")
dev.off()

png("figuras/asociacion/benefits_ModeratelyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(benefits_rulesModeratelyEffective, method="graph")
title("Comentarios beneficios sobre moderadamente efectivos")
dev.off()

png("figuras/asociacion/benefits_MarginallyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(benefits_rulesMarginallyEffective, method="graph")
title("Comentarios beneficios sobre casi inefectivo")
dev.off()
```

Podemos ver que los mapas de reglas salen bastante saturadas igualmente, ya que saca bastantes. Podríamos reducir el número de reglas manipulando los umbrales de soporte y confianza si lo deseamos, aunque llevaría tiempo de computación realizar esas pruebas.

Vamos a comentar por ejemplo la inefectividad, que ha salido más simple y fácil de visualizar:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/asociacion/benefits_Innefective.png}
    \caption{Mapa de reglas de asociación con Innefective en el consecuente en comentarios sobre beneficios.}
    \label{fig:asociacion:innefectiveAsociacion}
\end{figure}

Como se puede ver en la imagen, los términos que giran en torno de a la inefectividad tienen bastante sentido. Por ejemplo, la palabra *none*. Lo normal es que, cuando un medicamente es inefectivo, las personas realicen comentarios del estilo "no me ha hecho nada" o "no sirve de nada". Otros como *pain* o *problem* tienen sentido ya que si un medicamento es inefectivo es normal que aparezcan palabras "negativas". 

```{r, eval=FALSE}
# Obtenemos las imágenes relacionadas con los comentarios 
# sobre efectos secundarios de los medicamentos
png("figuras/asociacion/effects_Innefective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(effects_rulesInnefective, method="graph")
title("Comentarios efectos secundarios sobre inefectividad")
dev.off()

png("figuras/asociacion/effects_HighlyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(effects_rulesHighlyEffective, method="graph")
title("Comentarios efectos secundarios sobre altamente efectivos")
dev.off()

png("figuras/asociacion/effects_ConsiderablyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(effects_rulesConsiderablyEffective, method="graph")
title("Comentarios efectos secundarios sobre considerablemente efectivos")
dev.off()

png("figuras/asociacion/effects_ModeratelyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(effects_rulesModeratelyEffective, method="graph")
title("Comentarios efectos secundarios sobre moderadamente efectivos")
dev.off()

png("figuras/asociacion/effects_MarginallyEffective.png",width=1800,
    height=1700,units="px",pointsize=10,bg="white",res=300)
plot(effects_rulesMarginallyEffective, method="graph")
title("Comentarios efectos secundarios sobre casi inefectivo")
dev.off()
```

Sobre los comentarios de efectos secundarios podemos analizar, por ejemplo, el concepto de altamente efectivo:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/asociacion/effects_HighlyEffective.png}
    \caption{Mapa de reglas de asociación con Highly-Effective en el consecuente en comentarios sobre efectos secundarios.}
    \label{fig:asociacion:innefectiveAsociacion}
\end{figure}

Como podemos apreciar en la imagen, el mapa de por sí es poco visualizable debido a la cantidad de reglas que aparecen en tan poco espacio. En definitiva, si nos fijamos bien podemos darnos cuenta de que tiene bastante sentido. 

\newpage

<!------->

<!------->

# 6. Agrupamiento y Clustering


## 6.1. KNN

En esta sección vamos a realizar técnicas de clasificación basada en instancias. Concretamente el de vecinos más cercanos (KNN). Esta técnica es puramente predictiva, por lo que no proporciona ninguna información acerca de la dependecia de variables. Dado un texto, busca en el conjunto de entrenamiento los items que tienen un mayor parentesco del que estamos tratando de deducir y copia su clase. La clase que vamos a intentar reducir es **ratingLabel** que es la columna preprocesada de **rating**. Nos hubiera gustado probar y comentar esta técnica tratando de clasificar otras clases, pero no tenemos tiempo suficiente como para ello.

Esta técnica es buena cuando el conjunto de items se encuentran disjuntos entre sí debido a sus clases. Aunque el clustering es una técnica no supervisada en la que de antemano no teníamos etiquetas concretas que clasificar, nos dimos cuenta de que no era una opción que nos aportara mucho debido a este hecho (la nube de puntos no se encontraba disjuntas en grupos claros). Por lo que de antemano pensamos que no va a devolvernos unas predicciones muy prometedoras.

Antes de comenzar, destacar que probamos con variables numéricas antes de trabajar con los textos. Como nuestro dataset no tiene variables continuas, probamos con variables discretas. Tal y como se dice en la teoría de esta asignatura, este algoritmo no trabaja bien con este tipo de valores numéricos debido a que el cálculo de la distancias hacía que hubiera una gran cantidad de distancias iguales e items superpuestos en un plano bidimensional. En definitiva, tuvimos problemas a la hora de procesar el algoritmo (concretamente "too many ties in KNN", debido a lo comentado anteriormente). Así que nos pusimos a trabajar con cálculos de distancias en los comentarios, lo cual es más apropiado para esta técnica debido a que no tenemos valores continuos como tal en nuestro dataset.

Nos encontramos con un problema que tuvimos en la implementación de este algoritmo y el cual nos llevó mucho tiempo detectar y solucionar. Básicamente, nosotros estamos trabajando con dos dataset ya diferenciados desde el comienzo; el train y el test. Para esta técnica debemos de calcular la matriz de términos, si lo hacemos de los dos dataset por separado, tenemos el problema de que ambas matrices de términos no tienen exactamente el mismo formato (las columnas pueden tener diferentes palabras). Entonces, teníamos errores de dimensiones al aplicar el algoritmo, ya que obteníamos un clasificador que no era apto para predecir el test.

La solución, calcular la matriz de términos de un dataset, una vez realizados todos los cálculos y preparación de la matriz de términos que explicaremos más adelante, separamos esa misma matriz de términos (un 70% para el train y un 30% para el test). De esta forma nos aseguramos de que ambas matrices tienen exactamente las mismas columnas y los mismos términos y ya podemos trabajar correctamente con el algoritmo KNN.

Dicho esto, vamos a comenzar. Primero cargamos los datos.

```{r, eval=FALSE}
datos_preprocesados <- read.csv(file="datos/datos_train_preprocesado.csv")
```

El siguiente paso consiste en obtener el Corpus como hemos hecho en técnicas anteriores. Primero vamos a hacerlo sobre los comentarios acerca de los beneficios de los medicamentos. Acto seguido, obtenemos la matriz de términos correspondiente con sus vectores de pesos.

Para que el algoritmo funcione, es importante que esa matriz sea de tipo *matrix*. Una vez hecho esto, podemos separar la matriz en el conjunto de entrenamiento y prueba. Obtenemos el clasificador y predecimos solo el error del test porque la función obtiene el clasificador y la predicción en la misma llamada, por lo que para calcular el error de entrenamiento tendríamos que recalcular el mismo clasificador y nos parecía ineficiente.

Como ya hemos mencionado anteriormente, KNN selecciona los **k** items del conjunto de entrenamiento más parecidos al que estamos deduciendo (calculando este parentesco con distancia euclidea). Acto seguido, el algoritmo deduce la clase del item siendo la clase más frecuente de entre sus vecinos.

Por consiguiente, el valor de **k** es muy importante a la hora de realizar el clasificador. Un valor muy alto puede producir sobreaprendizaje y un valor muy bajo puede producir un aumento significativo en la tasa de error, por lo que probaremos con distintos valores. 

```{r, eval=FALSE}
# Para train KNN
corpus = tm::Corpus(tm::VectorSource(datos_preprocesados$benefits_preprocesado))
tdm <- tm::DocumentTermMatrix(corpus)

# Transform dtm to matrix and then back into a data frame for modeling
mat.df <- as.data.frame(data.matrix(tdm), stringsAsfactors = FALSE)

# Column bind category (known classification)
mat.df <- cbind(mat.df, datos_preprocesados$ratingLabel, row.names = NULL)

colnames(mat.df)[ncol(mat.df)] <- "ratingLabel"

# Classifier variable based on the personality typ
cl <- mat.df[,"ratingLabel"]

# Create model data and remove “type”
modeldata <- mat.df[,!colnames(mat.df) %in% "ratingLabel"]

train <- sample(nrow(mat.df), ceiling(nrow(mat.df) * .70))
test <- (1:nrow(mat.df))[- train]
```

Para **k=1**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=1) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)

```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k1.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=1).}
    \label{fig:KNN:benefitsK1}
\end{figure}

Para K=1 vemos que obtenemos de por sí una tasa de precisión razonable a sabiendas de que no iba a funcionar muy bien. Es decir, clasifica bien el ratingLabel en más de la mitad de las ocasiones.

Como podemos observar en la matriz de confusión, tiene un error alrededor del 40% para el conjunto del test. Tal y como nos temíamos, la técnica no es muy apropiada para nuestro problema debido a la disposición del los textos. Sin embargo, vamos a probar con valores distintos de k para intentar mejorar hasta cierto punto el desempeño del algoritmo. 

Para **k=3**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=3) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)

```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k3.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=3).}
    \label{fig:KNN:benefitsK3}
\end{figure}

Para k=3 el cambio no es significativo, incluso empeora un poco. Probamos con **k=5**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=5) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)

```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k5.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=5).}
    \label{fig:KNN:benefitsK5}
\end{figure}

Para k=5 tenemos el mejor clasificador hasta el momento, aunque vemos que se mantiene bastante estable, sin cambios realmente significativos.

Para **k=10**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=10) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k10.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=10).}
    \label{fig:KNN:benefitsK10}
\end{figure}

En este punto, el clasificador tiene un bajón de un 6% en la precisión. Vemos que siempre tenemos más falsos positivos que negativos. Es decir, el clasificador es positivo y suele dar más ratings altos que bajos cuando se equivoca.

Para **k=15**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=15) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k15.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=15).}
    \label{fig:KNN:benefitsK15}
\end{figure}

Para **k=30**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=30) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k30.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=30).}
    \label{fig:KNN:benefitsK30}
\end{figure}

Para **k=50**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=50) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/benefits_k50.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con beneficios (k=50).}
    \label{fig:KNN:benefitsK50}
\end{figure}

Como podemos observar, el modelo mantiene una precisión estable. Sin embargo a partir del valor 5 para **k** cuanto más vecinos, peor es el modelo. Podemos verlo de una forma más sencilla en la siguiente gráfica.

```{r, eval=FALSE}
valores_k <- c(1,3,5,10,15,30,50)
precision <- c(60.79484,60.47261,60.90226,54.24275,47.79807,34.80129,29.32331)

plot(x=valores_k,y=precision, xlab = "Valores de K", ylab="Precisión(%)", 
     ylim = c(0,100), type="o", col="green")
title("Precisión del modelo KNN en función del número de vecinos(K)")


```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/grafico_benefits.png}
    \caption{Gráfico del progreso del modelo KNN en función del valor de k.}
    \label{fig:KNN:grafica}
\end{figure}

Hacemos lo mismo para los comentarios de efectos secundarios que tenemos disponibles en nuestro dataset.

```{r, eval=FALSE}

# Para train KNN
corpus = tm::Corpus(tm::VectorSource(datos_preprocesados$effects_preprocesado))
tdm <- tm::DocumentTermMatrix(corpus)

# Transform dtm to matrix and then back into a data frame for modeling
mat.df <- as.data.frame(data.matrix(tdm), stringsAsfactors = FALSE)

# Column bind category (known classification)
mat.df <- cbind(mat.df, datos_preprocesados$ratingLabel, row.names = NULL)

colnames(mat.df)[ncol(mat.df)] <- "ratingLabel"

# Classifier variable based on the personality typ
cl <- mat.df[,"ratingLabel"]

# Create model data and remove “type”
modeldata <- mat.df[,!colnames(mat.df) %in% "ratingLabel"]

train <- sample(nrow(mat.df), ceiling(nrow(mat.df) * .70))
test <- (1:nrow(mat.df))[- train]
```

Para **k=1**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=1) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)

```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/effects_k1.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con efectos secundarios (k=1).}
    \label{fig:KNN:effectsK1}
\end{figure}

Para **k=3**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=3) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)

```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/effects_k3.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con efectos secundarios (k=3).}
    \label{fig:KNN:effectsK3}
\end{figure}

Para **k=5**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=5) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)

```

Parece que este vuelve a ser el mejor valor para k en la construcción del modelo.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/effects_k5.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con efectos secundarios (k=5).}
    \label{fig:KNN:effectsK5}
\end{figure}

Para **k=15**:

```{r, eval=FALSE}
knn.pred <- knn(modeldata[train,], modeldata[test,], cl[train], k=15) 

conf.mat <- table("Predictions" = knn.pred, Actual = cl[test])
conf.mat

(accuracy <- sum(diag(conf.mat))/length(test) * 100)
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/KNN/effects_k15.png}
    \caption{Matriz de confusión y tasa de precisión en modelo KNN con efectos secundarios (k=15).}
    \label{fig:KNN:effectsK15}
\end{figure}

Es curioso que en este último caso solo tiene falsos positivos, no negativos. 

Vemos que ocurre algo similar que con los comentarios de beneficios, solo que con una tasa de precisión más alta (solo se equivocaría 1 de cada 5 predicciones aproximadamente). Por algún motivo, es capaz de predecir mejor este tipo de comentarios sobre efectos secundarios. Suponemos que porque la nube de puntos es más apropiada en esta ocasión para esta técnica. 

Llegamos a la conclusión en ambos tipo de comentarios que los valores apropiados para k deben ser bajos (valor de 5), por los datos mostrados anteriormente.



<!------->

\newpage

# 7. Árboles de decisión y Clasificación

## 7.1. SVM

En esta sección vamos a hablar sobre la técnica de Support Vector Machine (SVM). Principalmente presenta el inconveniente de que es poco escalable y costosa (computacionalmente y en tiempo), por lo que no vamos a hacer un análisis muy detallado del mismo.

```{r, eval=FALSE, include=FALSE}
# Cargamos los tados
datos_train <- read.table("datos/datos_train_preprocesado.csv", sep=",",
                          comment.char="",quote = "\"", header=TRUE)
datos_test <- read.table("datos/datos_test_preprocesado.csv", sep=",",
                         comment.char="",quote = "\"", header=TRUE)
# Establecemos la semilla
set.seed(3)
```

Inicialmente, tratamos de utilizarlo con valores numéricos de nuestro dataset. El problema es que solo tenemos valores discretos y categóricos, por lo que esta técnica no funcionaba de forma correcta a la hora de calcular distancias. Tratar de hacer continuo un valor discreto es una pérdida de tiempo, ya que no podemos basarnos en nada para decidir el valor exacto que alcanzaría un valor discreto en un espacio continuo.

Tras darnos cuenta de esto, nos pasamos directamente al tratamiento del texto. Los pasos que llevamos a cabo fueron los siguientes:

```{r, eval=FALSE}
# Creamos la matriz de términos
dtm_train <- create_matrix(datos_train$benefits_preprocesado)

# Creamos un contenedor a partir de la matriz de términos
contenedor <- create_container(dtm_train,datos_train$ratingLabel,
                               trainSize=1:length(dtm_train),virgin=FALSE)

# Entrenamos el modelo SVM con los parámetros que queramos 
modelo_svm <- train_model(contenedor,"SVM",kernel="radial")

# Creamos la matriz de términos para el conjunto de test
dtm_test <- create_matrix(as.list(datos_test$benefits_preprocesado), 
                          originalMatrix = dtm_train)

#Obtenemos el contenedor correspondiente a la matriz de términos del conjunto de Test
contenedor_test <- create_container(dtm_test,labels=as.factor(datos_test$ratingLabel),
                         testSize=1:length(datos_test$ratingLabel),virgin=FALSE) 

resultados_svm <- classify_model(contenedor_test,modelo_svm)
resultados_svm
```

Destacar de este proceso que hacemos uso de la matriz de términos como viene siendo común a la hora de manipular texto. Utilizamos el kernel de tipo radial y la totalidad del conjunto de entrenamiento para llevar a cabo la construcción del modelo.

Pero nos daba un error a la hora de ejecutar este código. Esto retrasó mucho el avance de la práctica ya que no conseguíamos darnos cuenta de que es lo que ocurría. Finalmente, parece ser una incompatibilidad de la librería en create_matrix. Por lo que tuvimos que cambiarla con la ayuda de *trace*. En el código hay un comentario que especifíca el cambio a realizar en caso de tener este problema.


Posteriormente, tratamos de deducir el _ratingLabel_ a partir de los cometarios sobre los beneficios de los medicamentos. Obteniendo finalemte los siguientes resultados:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/svm/resultado.png}
    \caption{Salida de SVM para el ratingLabel a partir de los comentarios de texto sobre los beneficios.}
    \label{fig:svm:resultados}
\end{figure}

Como podemos ver, el clasificador no funciona bien. Etiqueta todo a 0. Creemos que el error viene dado debido a la disposición de los términos (igual que vimos en el clustering). Al tener una nube de puntos tan densa y tan poco disjunta, esto hace que no haya una función aceptable para poder separarlas.

Por otro lado, SVM no funciona bien con texto a no ser que tengas las mismas palabras tanto en el test como en el train, cosa que no ocurre en nuestro caso. Esto hace que SVM no tenga todo lo necesario para generar una buena función. Cosa que sí ocurre, por ejemplo, en este tutorial \url{https://www.svm-tutorial.com/2014/11/svm-classify-text-r/}.

En definitiva, decidimos no perder más tiempo con esta técnica, ya que parece no ser adecuada para nuestro dataset y seguir avanzando en el resto que proponemos con esta práctica.

<!------->

\newpage

```{r, include=FALSE}
# Lectura de los datos train preprocesados
datos_train_preprocesados <- read.csv(file="datos/datos_train_preprocesado.csv")

# Lectura de los datos test preprocesados
datos_test_preprocesados <- read.csv(file="datos/datos_test_preprocesado.csv")
```

# 8. Regresión

En este apartado se va hacer uso de la técnica de **regresión**, con el objetivo de describir dependencias significativas entre las variables incluidas en la base de datos. La regresión es un modelo de predicción de variables continuas, en donde las variables independientes tambien son continuas o al menos numéricas. Dicho proceso viene caracterizado por aprender una función que aplica un conjunto de atributos $X_1..X_n$ en otro atributo $Y$. En nuestro caso, vamos a hacer uso de las columnas:

- **ratingLabel**: etiqueta de 0 ó 1, que contempla la opinión del paciente sobre el medicamento si es favorable (1) o no es favorable (0).
- **effectivenessNumber**: clasificación de la efectividad del medicamento según el paciente (5 posibles valores), en donde el 1 significa que es ineficaz y el 5 que es altamente eficaz.
- **sideEffectsInverse**: clasificación de los efectos secundarios del medicamento según el paciente (5 posibles valores), en donde el 1 significa que tiene efectos secundarios extremadamente graves y el 5 que es sin efectos secundarios.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{imagenes/regresion/1.png}
    \caption{Visualización de las columnas a las que aplica regresión}
    \label{1}
\end{figure}

Como se observa en la gráfica \ref{1}, se va hacer uso de variables discretas. El objetivo de aplicar regresión, es obtener la curva ROC, la matriz de confusión y el error en el conjunto test, para obtener así la precisión de nuestro modelo y saber según el paciente qué medicamentos son favorables o no, tienen efectos secundarios o son efectivos. 

Como se ha comentado, se va hacer uso de la matriz de confusión, la cual es una herramienta que permite la visualización del desempeño de un algoritmo, en donde cada columna de la matriz representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real. Una de sus ventajas es que permite ver si la predicción falla o no. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{imagenes/regresion/2.png}
    \caption{Matriz de confusión para clasificador binario.}
    \label{2}
\end{figure}

De esta forma, se observa como en la figura \ref{2}, la diagonal principal contiene la suma de todas las predicciones correctas (el modelo dice “S” y acierta, tiene efectos secundarios, o dice “N” y acierta también, no tiene efectos secundarios). La otra diagonal refleja los errores del clasificador: los falsos positivos o “true positives” (dice que tiene efectos secundarios “S”, pero en realidad no tiene “n”), o los falsos negativos o “false negatives” (dice que no tiene efectos secundarios “N”, pero en realidad los tiene “p”). Además, otra de las medidas a usar, será la curva ROC, para caracterizar el comportamiento de la predicción.

Pero previo a la realización de las técnicas, se ha optado por eliminar los fármacos repetidos, para así obtener una predicción más acertada. Para dicha eliminación, se han cogido todos los medicamentos duplicados y eliminados los innecesarios. Así que si tenemos 5 filas de un mismo medicamento, se eliminan las 4 consecutivas al primero.

```{r, include=FALSE}
# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r

# Cogemos las columnas que queremos del train
datos_train2 <- datos_train_preprocesados[c(11,9,12)]

# Cogemos los farmacos
nombres_farmacos <- unique(datos_train_preprocesados[,1])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. 
# En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" 
# y "effectivenessNumber".
datos_procesados_train <- matrix(ncol=3, nrow=length(nombres_farmacos))

# Recorremos la lista de fármacos
for(i in 1:length(nombres_farmacos)) {
  
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_train2[which(datos_train_preprocesados$urlDrugName == nombres_farmacos[i]),]
  datos_farmaco = filas_farmaco[1,]
  datos_procesados_train[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_train_procesado <- data.frame(datos_procesados_train)
rownames(data_train_procesado) <- nombres_farmacos
colnames(data_train_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")
# A partir de ahora "data_train_procesado"
```

```{r, include=FALSE}
# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r

# Cogemos las columnas que queremos del test
datos_test2 <- datos_test_preprocesados[c(11,9,12)]

# Cogemos los farmacos
nombres_farmacos <- unique(datos_test_preprocesados[,1])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. 
# En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" 
# y "effectivenessNumber".
datos_procesados_test <- matrix(ncol=3, nrow=length(nombres_farmacos))

# Recorremos la lista de fármacos
for(i in 1:length(nombres_farmacos)){
  
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_test2[which(datos_test_preprocesados$urlDrugName == nombres_farmacos[i]),]
  datos_farmaco = filas_farmaco[1,]
  datos_procesados_test[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_test_procesado <- data.frame(datos_procesados_test)
rownames(data_test_procesado) <- nombres_farmacos
colnames(data_test_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")
# A partir de ahora "data_test_procesado"
```

## 8.1. Regresión Lineal

La regresión lineal simple consiste en generar un modelo de regresión (ecuación de una recta) que permita explicar la relación lineal que existe entre dos variables. A la variable dependiente o respuesta se le identifica como $Y$ y a la variable predictora o independiente como $X$. Con el comando `lm()` podemos ajustar el modelo. Algunos parámetros importantes de esta función son:
 
`lm(formula, data, subset, weights)`

- _fórmula_: definimos el modelo como: $Y \sim X$.
    - Regresion Múltiple: $y \sim X_1+X_2+...X_n$.
    - Regresión Polinómica: $y \sim poly(x = X, degree = k)$
    - Interacción de variables: $y \sim X_1 \cdot X_2$. Si sólo queremos el término de interacción: $X1:X2$
- _data_ : especificamos el dataset a utilizar
- _subset_ : si dividimos la muestra en training y testing, podemos indicar el subconjunto de entrenamiento con un vector que indique sus números de fila.


### 8.1.1. Regresión Lineal Simple

Se pretende predecir el valor del rating (etiqueta 0-1) en función de la puntuación de los medicamentos y, por otro lado para los efectos secundarios del mismo. Para ello se va a emplear la función `lm()`, la cual genera un modelo de regresión lineal por mínimos cuadrados en el que la variable respuesta es ratingLabel y el predictor sideEffectsInverse, y por otro lado, la variable respuesta será ratingLabel y el predictor effectivenessNumber. 

El modelo de regresión lineal simple se describe de acuerdo a la siguiente ecuación:

$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$$

Siendo $\beta_0$ la ordenada en el origen, $\beta_1$ la pendiente y $\epsilon$ el error aleatorio. Este último representa la diferencia entre el valor ajustado por la recta y el valor real y recoge el efecto de todas aquellas variables que influyen en $Y$ pero que no se incluyen en el modelo como predictores. Al error aleatorio también se le conoce como residuo.

A continuación, se realiza una función con la cual obtener los errores dentro y fuera de la muestra, y la matriz de confusión. 

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_lineal <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  # Calculamos Etest y mostramos la matriz de confusión
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) 
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  # Devolvemos el error para el conjunto train y test
  list(Etrain=Etrain*100, Etest=Etest*100)
}
```

Primero vamos a obtener un modelo en donde la variable respuesta es ratingLabel y el predictor sideEffectsInverse. Con el fin de obtener, que medicamentos favorables tienen efectos secundarios. Por lo que tendremos que hacer caso a la otra diaganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
lm_effects = lm(data = data_train_procesado, formula = ratingLabel ~ sideEffectsInverse)
summary(lm_effects)
# Evaluamos el modelo
errorres_regresion_lineal(lm_effects)
```

Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05). El valor de R^2 indica que el modelo calculado explica el 26.91% de la variabilidad presente en la variable respuesta (ratingLabel) mediante la variable independiente (sideEffectsInverse). Como se observa se obtiene que hay 11 falsos positivos, es decir, medicamentos que se dicen que tienen efectos secundarios pero no los tienen. Y existen 27 falsos negativos, es decir, medicamentos que se dicen que no tienen efectos secundarios pero que los tienen. Dichos resultados son los obtenidos según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

A continuación, vamos a crear el modelo para la variable respuesta ratingLabel y el predictor effectivenessNumber. Con el fin de obtener, que medicamentos favorables son efectivos. Por lo que tendremos que hacer caso a la otra diaganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
lm_effectiveness = lm(data = data_train_procesado, formula = ratingLabel ~ effectivenessNumber)
summary(lm_effectiveness)
# Evaluamos el modelo
errorres_regresion_lineal(lm_effectiveness)
```

Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05). El valor de R^2 indica que el modelo calculado explica el 36.98% de la variabilidad presente en la variable respuesta (ratingLabel) mediante la variable independiente (effectivenessNumber). Como se observa se obtiene que hay 3 falsos positivos, es decir, medicamentos que se dicen que son efectivos pero que no lo son. Y existen 35 falsos negativos, es decir, medicamentos que se dicen que no son efectivos pero los son. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

Una vez que hemos obtenidos las prediciones para nuestro modelo, vamos a obtener las probabilidades para el mismo con el fin de obtener la curva ROC.

```{r}
# Función que dibuja una curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  
  # Realizamos la predicción con la función de RORCR
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, 
       main="Curva ROC - Regresión Lineal - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}
```

```{r, echo=FALSE}
# Obtenemos las probabilidades para effects
prob_LM_effects = predict(lm_effects, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_LM_effects, data_test_procesado$ratingLabel)

# Obtenemos las probabilidades para effectiveness
prob_LM_effectiveness = predict(lm_effectiveness, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_LM_effectiveness, data_test_procesado$ratingLabel)
```


#### 8.1.1.1. Casos atípicos

A continuación para el modelo lineal simple, vamos a obtener los casos atípicos, una forma rápida de identificarlos es usando la función `influencePlot()` del paquete `car`. Esta función produce un gráfico que señala a los casos atípicos influyentes. 

Una de las fuentes de violaciones de los supuestos en el modelado lineal es la presencia de casos atípicos. Un caso atípico es aquel que, dados ciertos valores de $x \sim 1$, $x \sim 2$, $x \sim n$ tiene valores de $y$ muy diferentes a los demás y por lo tanto producen un residuo muy alto. Estos casos atípicos pueden tener gran influencia sobre el modelo, ya que el criterio de mínimos cuadrados buscará minimizar el error y cambiará la pendiente para dar cuenta de estos casos.

Primero vamos a obtener los casos atípicos para el modelo de los efectos secundarios del medicamento.

```{r}
# Detección y visualización de observaciones influyentes para effects
influencePlot(lm_effects, xlab="Hat-Values", ylab="Studentized Residuals")
```

Para dicho modelo, los medicamentos _claritin_, _lipitor_, _ultram-er_, _metronidazole_, _toradol_ y _bactroban_ aparecen como casos atípicos. A continuación, vamos a obtener los casos atípicos para el modelo de la efectividad del medicamento.

```{r}
# Detección y visualización de observaciones influyentes para effectivenessNumber
influencePlot(lm_effectiveness, xlab="Hat-Values", ylab="Studentized Residuals")
```

Para dicho modelo, los medicamentos _propecia_, _claritin_, _depakote_, _anafranil_ y _fluvoxamine_ aparecen como casos atípicos.

#### 8.1.1.2. Regresión Robusta

Una alternativa para controlar los casos atípicos es ajustar un modelo lineal robusto. El modelo lineal robusto utiliza criterios diferentes al de los mínimos cuadrados y pondera la influencia de los casos atípicos, por lo que producen coeficientes y sobre todo errores estándar más confiables. El paquete `MASS` incluye la función `rlm()`, de sintaxis similar a `lm()` que implementa el método para el ajuste de los coeficientes y cálculo de los errores estándar.

Primero, calcularemos el modelo en donde la variable respuesta es ratingLabel y el predictor sideEffectsInverse. Con el fin de obtener, que medicamentos favorables tienen efectos secundarios. Por lo que tendremos que hacer caso a la otra diaganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
rlm_effects = MASS::rlm(ratingLabel ~ sideEffectsInverse, data = data_train_procesado)
stargazer(lm_effects, rlm_effects, type = "text", model.numbers = FALSE, 
          title="Comparación de modelo OLS y Robusto")
```

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
rlm_effectiveness = MASS::rlm(ratingLabel ~ effectivenessNumber, 
                              data = data_train_procesado)
stargazer(lm_effectiveness, rlm_effectiveness, type = "text", model.numbers = FALSE, 
          title="Comparación de modelo OLS y Robusto")
```

El modelo robusto aumenta los coeficientes y reduce los errores estándar, aunque no en gran cuantía. En este caso interpretamos que los casos atípicos no son un problema grave.

### 8.1.2. Regresión Lineal Múltiple

Una vez que hemos la regresión lineal simple, vamos a intentar predecir el valor del ratingLabel en función de la puntuación de los medicamentos y de los efectos secundarios del mismo. Para ello se va a emplear la misma (`lm()`), la cual genera un modelo de regresión lineal por mínimos cuadrados en el que la variable respuesta es ratingLabel y los predictores son sideEffectsInverse y effectivenessNumber. Previamente a la realización del modelo, vamos a comprobar que las variables a usar pueden ser aplicadas juntas con la función `step()`, para así determinar la calidad del modelo.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber + sideEffectsInverse 
lm_multiple <- lm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, 
                  data = data_train_procesado)

# https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple
# Nos dice si existe alguna variable que estamos usando que no nos hace falta
step(lm_multiple, direction = "both", trace = 1)

# Obtenemos el error d
errorres_regresion_lineal(lm_multiple)
```

Como se aprecia en salida de la función `step(lm_multiple, direction = "both", trace = 1)`, las dos variables deben ser incluidas en el proceso de selección. 

Por tanto, se observa que se obtiene que hay 5 falsos positivos, es decir, medicamentos que se dicen que son favorables pero que no lo son. Y existen 24 falsos negativos, es decir, medicamentos que se dicen que no son favorables pero los son. Se debe tener en cuenta que dichos resultados obtenidos han sido según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 9.265176, un buen error si tenemos en cuenta, los obtenidos con la regresión simple.


## 8.2. Regresión Logística

A continuación, vamos a ajustar un modelo con regresión logística binario sin regularización. De este modo vamos a comprobar, si se puede intentar encontrar un buen modelo lineal para nuestro problema. Además, discutiremos las necesidades de regularización, para ver si de esta forma conseguimos mejorarlo en cuanto a resultados. 

Para la obtención de la regresión, vamos hacer uso del comando `glm()`.

### 8.2.1. Regresión Logística Simple

La regresión logística simple, es un método de regresión que permite estimar la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. Una de las principales aplicaciones de la regresión logística es la de clasificación binaria, en el que las observaciones se clasifican en un grupo u otro dependiendo del valor que tome la variable empleada como predictor. Es decir para predecir la probabilidad de pertenencia o no a una determinada clase (efectividad - no efectividad).

Para ello, vamos a utilizar la función `glm(..)` que en base al conjunto de muestras de entrenamiento suministrado, es capaz de calcular una probabilidad para cada dato. Si esta probabilidad sobrepasa el valor 0.5, entonces consideramos que dicha muestra pertence a la clase 1, sin embargo, si su probabilidad es menor que 0.5, entonces consideramos que se encuentra en la clase con etiqueta 0. Una vez tengamos las etiquetas predichas a partir de las probabilidades que calcula el modelo, vamos a calcular el error dentro de la muestra y el error fuera de la muestra. Para ello, vamos a especificar como primer argumento, la variable respuesta denominada ratingLabel y a continuación, la variable en la que nos vamos a fijar para ajustar el modelo. 

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_logistica <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) # Calculamos Etest
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  list(Etrain=Etrain*100, Etest=Etest*100)
}
```

Primero vamos a obtener el modelo, que predice la variable sideEffectsInverse a partir del ratingLabel.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
gml_effects = glm(ratingLabel ~ sideEffectsInverse, family = binomial(logit), 
                  data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(gml_effects)
```

Como se observa se obtiene que hay 11 falsos positivos, es decir, medicamentos que se dicen que tienen efectos secundarios pero no los tienen. Y existen 27 falsos negativos, es decir, medicamentos que se dicen que no tienen efectos secundarios pero que los tienen. Dichos resultados son los obtenidos según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero se ha comprobado, que se obtiene un mejor error con la regresión lineal múltiple.

A continuación, vamos a crear el modelo para la variable de respuesta ratingLabel y el predictor effectivenessNumber. Con el fin de obtener, que medicamentos favorables son efectivos. Por lo que tendremos que hacer caso a la otra diagonal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
gml_effectiveness = glm(ratingLabel ~ effectivenessNumber, family = binomial(logit), 
                        data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(gml_effectiveness)
```

Como se observa se obtiene que hay 3 falsos positivos, es decir, medicamentos que se dicen que son efectivos pero que no lo son. Y existen 35 falsos negativos, es decir, medicamentos que se dicen que no son efectivos pero los son. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

Una vez que hemos obtenidos las prediciones para nuestro modelo, vamos a obtener la curva ROC.

```{r, echo=FALSE}
# Obtenemos las probabilidades para effects
prob_GLM_effects = predict(gml_effects, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo logística
plotROC(prob_GLM_effects, data_test_procesado$ratingLabel)
```

```{r, echo=FALSE}
# Obtenemos las probabilidades para effectiveness
prob_GLM_effectiveness = predict(gml_effectiveness, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effectiveness, data_test_procesado$ratingLabel)
```

### 8.2.2. Regresión Logística Multivariable

Una vez que hemos la regresión logística simple, vamos a intentar predecir el valor del ratingLabel en función de la puntuación de los medicamentos y de los efectos secundarios del mismo. Para ello se va a emplear la misma (`glm()`).

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse + effectivenessNumber
modelo_glm_multiple <- glm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(modelo_glm_multiple)
```


### 8.2.3. Regularización en Regresión Logística

En este apartado vamos a ajustar un modelo a través de la regresión logística con regularización meidante la técnica Lasso Regression.

#### 8.2.3.1. Rigde Regression

Esta ténica, en esencia, es la regresión lineal con Weight Decay que utilizamos en la Práctica 2, y cuya fórmula es: $(XTX + lambdaI)-1 *XˆT$. Es el parámetro lambda, el que en función de su valor, marca el equilibrio entre los componentes de sesgo y varianza. Cuanto mayor sea su valor, mayor sesgo pero menor varianza. Es decir, cuanto mayor valor tenga lambda, mayor penalización y mayor reducción se les aplica a los valores de los coeficientes.


#### 8.2.3.2. Lasso Regression

Esta técnica, además de realizar la misma tarea que la anterior, pero con una fórmula distinta para aplicar la penalización. Aún así, también utiliza el parámetro lambda para concretar el equilibrio entre sesgo y varianza. Además, también es capaz de realizar una selección de variables, anulando algunos coeficientes. Por lo que además de la reducción de los valores de estos coeficientes también reduce el número de estos necesarios para ajustar el modelo.

Por tanto, para aplicar la regularización, primero debemos averiguar el valor de alpha, que representa la técnica a utilizar. Si alpha=0 entonces la regularización se aplica con la técnica Ridge Regression. Si por el contrario alpha=1, entonces la técnica a utilizar será Lasso Regression. Una vez sabemos qué técnica aplicar a través del valor de alpha, tendremos que concretar el valor de lambda, para
que dicha técnica pueda ajustar el modelo con su respectiva penalización.

Para ello, vamos a usar la función `train(..)` que es capaz de probar distintos valores para alpha y lambda a través del ajuste de varios modelos, de modo que devuelve el mejor valor de lambda y el mejor valor de alpha. Para ello, como primer argumento debemos indicarle los valores de las etiquetas, que se corresponden con los valores de la variable explicativa. A continuación, vamos a darle la oportunidad de explorar con las columnas sideEffectsInverse + effectivenessNumber. Como segundo argumento le proporcionamos el conjunto de entrenamiento. El tercer argumento especifica el tipo de técnica a utilizar para explorar todos los modelos posibles. Con `glmnet`(), le concretamos que
queremos que ajuste dichos modelos a través de la Lasso Regression y de Ridge Regression. Y por último, como cuarto argumento le especificamos la clase de funciones que debe utilizar para ajustar un modelo a través de regresión logística.

```{r}
library(glmnet)
# Ajustamos un modelo a través de Regresión Logística multiclase
modelbest = train(form=as.factor(ratingLabel) ~ sideEffectsInverse + effectivenessNumber, 
                  data=data_train_procesado, method="glmnet", family="binomial")

modelbest$bestTune$alpha
modelbest$bestTune$lambda
```

Como se puede observar, la función nos dice que el mejor modelo que podemos ajustar para nuestro conjunto de entrenamiento, es el que tiene el valor de alpha 0.1. Con este valor tan cercano a 0 podemos intuir que la técnica que va a emplear es Ridge Regression, ya que esta se representa a través de alpha = 0.

En cuanto al valor de lambda, podemos comprobar que es bastante próximo a 0, y que por tanto, la penalización que va a aplicar Ridge Regression no es demasiado agresiva. Por lo que podemos intuir que el modelo ajustado tendrá un cierto grado de flexibilidad en referencia a las muestras mal clasificadas. También indica, que el modelo que va a ajustar, por el valor pequeño de lambda, se puede caracterizar por un
bajo sesgo pero una alta varianza. Lo que puede desembocar en un modelo sobreajustado a los datos de entrenamiento, con una capacidad de generalización bastante escasa.

Para ajustar este modelo hemos utilizado la función `glmnet(..)`. Como primer argumento especificamos una matriz con las muestras de entrenamiento pero sin sus etiquetas, las cuales se le proporcionan a la función en el segundo argumento. Como tercer argumento le volvemos a indicar la familia de funciones que debe utilizar para que sea un modelo ajustado a partir de regresión logística. Los dos siguientes parámetros se corresponden con el mejor alpha y el mejor lambda que hemos obtenido en el proceso anterior.

```{r}
# Conjunto Train

# Primero generamos una matriz con el conjunto de train separando las etiquetas de los datos
x = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, 
                 data_train_procesado)[,-ncol(data_train_procesado)]
y = data_train_procesado$ratingLabel

# Conjunto Test
x.test = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, 
                      data_test_procesado)[,-ncol(data_test_procesado)]
y.test = data_test_procesado$ratingLabel

# Reproducimos el modelo ajustado con el mejor lambda y el mejor alpha
ridge.mod = glmnet(x=x, y=y, family="binomial", alpha=modelbest$bestTune$alpha,
                   lambda=modelbest$bestTune$lambda,thresh=1e-12)

# Calculamos la predicción
predicciones.ridge = predict(ridge.mod, s=ridge.mod$lambda, 
                             newx=x.test, type="response")

# Error de regresión con penalización Ridge
error.ridge = mean (( predicciones.ridge - y.test)^2)
cat("Error con la técnica Ridge Regression: ",error.ridge*100,"%\n")
```

Como se observa, se obtiene un error similar a los anteriores.

## 8.3. Regresión Polinomial

En algunos casos, la verdadera relación entre la variable respuesta y los predictores puede no ser lineal, por lo que podemos aplicar por ejemplo una regresión polinomial. Una forma simple de incorporar asociaciones no lineales en un modelo lineal es incluir versiones transformadas de los predictores, elevándolos a distintas potencias, evitando un exceso de grados para evitar el sobreajuste o overfitting.

La forma más sencilla de incorporar flexibilidad a un modelo lineal es introduciendo nuevos predictores obtenidos al elevar a distintas potencias el predictor original.

Partiendo del modelo lineal: $Y_i = \beta_0 + \beta_1 X_i + \epsilon$

Se obtiene un modelo polinómico de grado d a partir de la ecuación:

$$Y_i = \beta_0 + \beta_1 x_i + \beta_2 x^2_i + \beta_3 x^3_i + ... + \beta_d x^d_i + \epsilon_i$$

```{r}
# Hacemos uso del poly para 2
lm_poly = lm(data = data_train_procesado, 
    formula = ratingLabel ~ poly(sideEffectsInverse, 2) + effectivenessNumber)
summary(lm_poly)
errorres_regresion_lineal(lm_poly)
```

Los p-values individuales de sideEffectsInverse, apuntan a que un polinomio de grado 2 es suficiente para modelar el ratingLabel en función de sideEffectsInverse.

```{r}
# Calculo del polinomio de grado 2
modelo_poli2 <- lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2))
summary(modelo_poli2)

# Interpolacion de puntos dentro del rango predictos
limites <- range(data_train_procesado$sideEffectsInverse)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos <- data.frame(sideEffectsInverse = nuevos_puntos)

# Predicción de la variable respuesta y del error estándar
predicciones <- predict(modelo_poli2, newdata = nuevos_puntos, se.fit = TRUE,
                        level = 0.95)

# Cálculo del intervalo de confianza superior e inferior 95%
intervalo_conf <- data.frame(inferior = predicciones$fit -
                                        1.96*predicciones$se.fit,
                             superior = predicciones$fit +
                                        1.96*predicciones$se.fit)

attach(data_train_procesado)
plot(x = sideEffectsInverse, y = ratingLabel, pch = 20, col = "darkgrey")
title("Polinomio de grado 2: ratingLabel ~ sideEffectsInverse")
lines(x = nuevos_puntos$sideEffectsInverse, predicciones$fit, col = "red", pch = 20)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$inferior, col = "blue", pch = 4)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$superior, col = "blue", pch = 4)
```

En la gráfica, que acabamos de visualizar se puede observar como existe una relación, en donde a mayor valor de sideEffectsInverse, mayor ratingLavel, es decir, cuanto más favorable es un medicamento menos efectos secundarios tiene.

Por tanto, se ha observado como el método de regresión sobre las variables numéricas, obtiene unas predicciones de etiquetas muy buenas, obteniendo con la regresión logística multivariable el mínimo error fuera de la muestra. Ya que dicho método, permite estimar de manera muy aceptable la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. 

\newpage

# 9. Conclusiones

Después de realizar las técnicas que acabamos de comentar, hemos comprendido la importancia que tiene el preprocesamiento en nuestros datos, los cuales sirven como entrada para las técnicas implementadas en la Minería de Textos. Es por eso que a partir de una base de datos sin estructura, hemos ido transformando dichos datos en datos con una coherencia y sentido. Debido a que nuestro dataset de primeras disponía de mucho ruido, cosa que hubiera afectado negativamente a la precisión de los predictores. Es por eso que se llevó a cabo un debido filtrado, como se pudo ver en el apartado 2. Una vez que tuvimos los datos tratados adecuadamente, se procedió a la realización del análisis exploratorio de los datos. Dicho análisis, fue llevado a cabo, principalmente, para saber y comprender en mayor medida el conjunto con el que estamos trabajando y, en particular, para estudiar la efectividad y los efectos secundarios de los medicamentos. 

Por otro lado, se llevó a cabo un análisis de sentimientos sobre los sentimientos de las personas, mediante la opinión que tienen sobre los distintos medicamentos que se encuentran en nuestro dataset. Dicho análisis nos llevó a la conclusión, de que se tiene una opinión más negativa que positiva sobre la aplicación de los medicamentos. Sin embargo, esta conclusión tiene coherencia, ya que las personas tiende a extraer los contras de los medicamentos. Y a no ser que el medicamento cumpla su función eficazmente, el paciente no tenderá a ser positivo respecto al mismo.

Con respecto a las técnicas, debemos destacar la componente subjetiva que tienen las reglas de asociación a la hora de su elección. Se observó, como los consecuentes más frecuentes fueron effect y side, lo que es lógico ya que estamos midiendo los efectos que tienen los medicamentos. 
Por otro lado, se aplicó el método de regresión sobre las variables numéricas, dicho método obtuvo unas predicciones de etiquetas muy buenas, obteniendo con la regresión logística multivariable el mínimo error fuera de la muestra. Ya que dicho método, permite estimar de manera muy aceptable la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. 