---
title: "clasificacion"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<!-------------------------------------------------------------------------------------------->

## 2.1. Lectura del dataset

A continuación, mediante la función `read.table` procedemos a la lectura de los datos.

### 2.1.1. Lectura de datos train

Se va a procedeer a la lectura del conjunto de datos de entrenamiento.

```{r, warning=FALSE}
# Lectura de datos train
datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",
                          quote = "\"", header=TRUE)
```

Disponemos de una matriz de 3107 filas x 9 columnas, asimismo vamos a ver un ejemplo de como distribuida la información, en donde para la fila tercera encontramos la siguiente información:

\begin{table}[h]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{X} & \textbf{urlDrugName} & \textbf{rating} & \textbf{effectiveness} 
      & \textbf{sideEffects} &\textbf{condition} \\ \hline
      1146 & ponstel & 10 & Highly Effective & No Side Effects & menstrual cramps  \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de entrenamiento I}
  \label{tabla:datos_trainI}
\end{table}

\begin{table}[h]
  \centering
    \begin{tabular}{|m{5cm}|m{3cm}|m{7cm}|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{benefitsReview} & \textbf{sideEffectsReview} & \textbf{commentsReview} \\ \hline
      I was used to having cramps so badly that they would leave me balled up in bed for at least 2 days. The Ponstel doesn't take the pain away completely, but takes the edge off so much that normal activities were possible. Definitely a miracle medication!! & Heavier bleeding and clotting than normal. & I took 2 pills at the onset of my menstrual cramps and then every 8-12 hours took 1 pill as needed for about 3-4 days until cramps were over. If cramps are bad, make sure to take every 8 hours on the dot because the medication stops working suddenly and unfortunately takes about an hour to an hour and a half to kick back in.. if cramps are only moderate, taking every 12 hours is okay. \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de entrenamiento II}
  \label{tabla:datos_trainII}
\end{table}

De las tablas \ref{tabla:datos_trainI} y \ref{tabla:datos_trainII} podemos extraer que el medicamento \textbf{ponstel} con identificador \textbf{1146}, tiene la máxima puntuación por parte del paciente (\textbf{rating = 10}), el cual tiene un alto nivel de efectividad (\textbf{Highly Effective}) sin efectos secundarios (\textbf{No Side Effects}), usado para dolores menstruales (\textbf{menstrual cramps}), en donde el paciente dice que de estar tumbado en la cama con dolores ha pasado a poder realizar las actividades sin ningún impedimento. Además, asegura que tomar este medicamento le ha supuesto un sangrado más abundante y coagulación de lo normal. La dosis del medicamento oscila entre una píldora cada 8-12 horas durante 3-4 días.

```{r, warning=FALSE, include=FALSE}
# Visualizar las 5 primeras filas para los datos train
head(datos_train, 5) 
# Resumen sobre los datos train
summary(datos_train) 
```

### 2.1.2. Lectura de datos test

Se va a procedeer a la lectura del conjunto de datos de prueba.

```{r, warning=FALSE}
# Lectura de datos test
datos_test <- read.table("./datos/drugLibTest_raw.tsv", sep="\t", comment.char="",
                         quote = "\"", header=TRUE)
```

Disponemos una matriz de 1036 filas x 9 columnas, asimismo vamos a ver un ejemplo de como distribuida la información, en donde para la fila primera encontramos la siguiente información:

```{r, warning=FALSE, include=FALSE}
# Visualizar las 5 primeras filas para los datos test
head(datos_test, 5) 
# información sobre los datos test
summary(datos_test) 
```

De las tablas \ref{tabla:datos_testI} y \ref{tabla:datos_testII} podemos extraer que el medicamento \textbf{biaxin} con identificador \textbf{1366}, tiene una puntuación de 9 por parte del paciente (\textbf{rating = 9}), el cual tiene un nive considerable de efectividad (\textbf{Considerably Effective}) con efectos secundarios leves (\textbf{Mild Side Effects}), usado para la infección sinusal   (\textbf{sinus infection}), en donde el paciente dice que no está muy seguro de si el antibiótico ha destruido las bacterias que causan su infección sinusal. Además, asegura que tomar este medicamento le da algo de dolor de espalda y algunas náuseas. El paciente tomó los antibióticos durante 14 días y la infección sinusal desapareció al sexto día.

\begin{table}[h]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{X} & \textbf{urlDrugName} & \textbf{rating} & \textbf{effectiveness} 
      & \textbf{sideEffects} &\textbf{condition} \\ \hline
      1366 & biaxin & 9 & Considerably Effective & Mild Side Effects & sinus infection  \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de prueba I}
  \label{tabla:datos_testI}
\end{table}

\begin{table}[h]
  \centering
    \begin{tabular}{|m{7cm}|m{3cm}|m{5cm}|}
      \hline
      \rowcolor[rgb]{0.94,0.97,1.0} \textbf{benefitsReview} & \textbf{sideEffectsReview} & \textbf{commentsReview} \\ \hline
      The antibiotic may have destroyed bacteria causing my sinus infection. But it may also have been caused by a virus, so its hard to say. & Some back pain, some nauseau. & Took the antibiotics for 14 days. Sinus infection was gone after the 6th day. \\ \hline
    \end{tabular}
  \caption{Información contenida en una fila del conjunto de prueba II}
  \label{tabla:datos_testII}
\end{table}

```{r lectura, warning=FALSE, eval=FALSE, include=FALSE}
View(datos_train)    # vista de la tabla
View(datos_test)    # vista de la tabla
```

<!-------------------------------------------------------------------------------------------->

<!--- ## 2.2. Falta de datos, categorización, normalización, reducción de dimensionalidad. --->

<!--- Borrar si añgún atributo no nos da información como un ID, hacer una transformación con los atributos asimétricos, ya que son necesarios para la aplicación de algunos métodos de aprendizaje sensibles a distancias. Se consideran asimétricos cuando el valor skewness se aleja de 0, podemos eliminar las variables con varianza 0 o muy próximas. --->

La representación del documento se llevará a cabo utilizando palabras, después de un debido filtrado para minimizar la dimensión del espacio de trabajo.

## 2.2. Procesamiento de los datos

Dado que la representación total del documento puede tener una alta dimensión, se va a procedeer a construir un corpus, necesario para la aplicación de métodos de limpieza y esructuración del texto de entrada e identificación de un subconjunto simplificado de las características del documento con el fin de poder ser representado en un análisis posterior.

<!-------------------------------------------------------------------------------------------->

### 2.2.1. Eliminar columnas

El primer paso que vamos a realizar es la **eliminación de columnas**, las cuales contienen información irrelevante para nuestro análisis.

#### Eliminar columna ID

Al conjunto de datos utilizado se le ha añadido de forma automática una novena columna, que representa un ID para cada uno de los datos con los que estamos trabajando. Como este ID no nos aporta información alguna, hemos decidido quitarla directamente del _dataframe_. Esta columna se corresponde con la primera columna, por lo cuál, debemos eliminar la columna que se corresponde con la posición 1. Los cambios que hacemos en el _dataset_ deben modificarse tanto en el conjunto de test como el de train, para que los resultados sean consistentes.

```{r}
datos_train = datos_train[-1] # Eliminar columna para el ID en el train
datos_test = datos_test[-1] # Eliminar columna para el ID en el test
```

#### Eliminar columna de commentsReview

Consideramos que la información contenida en _commentsReview_ no es de nuestro interés. En este atributo se almacena texto, en el cual los consumidores de los medicamentos suelen poner en la mayoría de casos la frecuencia o la dosis con la que consumen la misma. En otros casos menos frecuentes, se establecen comentarios más arbitrarios en el que se muestran sus sensaciones o información sin relevancia. Incluso en algunos casos este campo aparece vacío. Es por eso, que hemos decidido eliminar la columna, tanto para el conjunto test como el train.

```{r}
datos_train = datos_train[-8] # Eliminar columna para el commentsReview en el train
datos_test = datos_test[-8] # Eliminar columna para el commentsReview en el test
```

<!-------------------------------------------------------------------------------------------->

### 2.2.2. Eliminar filas

Además de eliminar las columnas innecesarias, se han localizado tres filas que aportan información irrelevante a nuestro análisis, las cuales estaban perjudicando la realización del preprocesamiento.

- Se elimina la fila 387, porque no dispone de información alguna ni en _benefitsReview_ y _sideEffectsReview_. 
- Se elimina la fila 928, porque en la columna _condition_ dispone de un carácter raro. 
- Se elimina la fila 3105, porque no tienen información en _benefitsReview_ ("---").

```{r}
datos_train = datos_train[-c(387,928, 3105),] # Eliminar filas en el train
datos_test = datos_test[-c(387,928, 3105),] # Eliminar filas en el test
```

<!-------------------------------------------------------------------------------------------->

### 2.2.3. Eliminar elementos repetidos

<!---------HAY UN ERROR DE CODIFICACION EN ESTE APARTADO QUE NO VEMOS--------->

No se contabiliza elimar medicamentos repetidos, debido a que hacen faltan las opiniones. Por ejemplo vamos a extraer el medicamentos que más veces se repite en el conjunto test.

```{r}
# duplicated(datos_test$urlDrugName)

#df <- data.frame(datos_test$urlDrugName)
#new_df <- aggregate(datos_test$urlDrugName, df, length)
#colnames(new_df)[2]<-"Repeticiones"
#new <- new_df[order(new_df$Repeticiones, decreasing = TRUE),]

#df %>%                       
#  group_by(datos_test$urlDrugName) %>%       #Luego indico que quiero un grupo por cada valor unico en Estados, podria agupar por mas variables si las tuviera/quisiera.
#  tally()  
```

```{r}
#new[1,]
```


```{r}
#datos_test[datos_test$urlDrugName == "paxil",]
```

<!-------------------------------------------------------------------------------------------->

### 2.2.4. Cuantificación de variables

Para poder analizar y trabajar más fácilmente con la información de *sideEffects* y  *effectiveness*, se va a realizar una conversión de dichas columnas a forma cuantitativa, es decir, vamos asignar una etiqueta numérica a cada valor pertinente, tanto para para _train_ como _test_. 

A continuación, vamos a cuantificar la columna de *sideEffects*, para ello se añade una nueva columna a nuestro conjunto de datos denominada *sideEffectsNumber* que nos clasifica los posibles valores de la columna *sideEffects* en un rango numérico, comprendido entre 1 y 5. Dicha columna hace referencia a la clasificación de los efectos secundarios del medicamento según el paciente, en donde la etiqueta con valor 1 hará referencia a que no haya ningún efecto secundario y la etiqueta con valor 5 a que tiene efectos secundarios extremadamente graves:

- Extremely Severe Side Effects (efectos secundarios extremadamente graves) : 5
- Severe Side Effects (efectos secundarios graves): 4
- Moderate Side Effects (efectos secundarios moderados) : 3
- Mild Side Effects (efectos secundarios leves) : 2
- No Side Effects (sin efectos secundarios) : 1

```{r}
# Datos Train
datos_train$sideEffectsNumber[datos_train$sideEffects=="Extremely Severe Side Effects"]<-5
datos_train$sideEffectsNumber[datos_train$sideEffects=="Severe Side Effects"]<-4
datos_train$sideEffectsNumber[datos_train$sideEffects=="Moderate Side Effects"] <- 3
datos_train$sideEffectsNumber[datos_train$sideEffects=="Mild Side Effects"]<- 2
datos_train$sideEffectsNumber[datos_train$sideEffects=="No Side Effects"]<- 1

# Datos Test
datos_test$sideEffectsNumber[datos_test$sideEffects=="Extremely Severe Side Effects"]<-5
datos_test$sideEffectsNumber[datos_test$sideEffects=="Severe Side Effects"]<-4
datos_test$sideEffectsNumber[datos_test$sideEffects=="Moderate Side Effects"]<-3
datos_test$sideEffectsNumber[datos_test$sideEffects=="Mild Side Effects"]<-2
datos_test$sideEffectsNumber[datos_test$sideEffects=="No Side Effects"]<-1
```

Podemos comprobar que se ha creado la nueva columna *sideEffectsNumber*, y que se han añadido los cambios comentados anteriormente.

```{r}
head(datos_train$sideEffectsNumber, 10) 
```

Volvemos a aplicar el mismo procedimiento para la columna de *effectiveness*, creándonos para ello una columna denominada *effectivenessNumber*. Dicha columna, hace referencia a la clasificación de la efectividad del medicamento según el paciente, en donde la etiqueta con valor 1 hace referencia a que el medicamente es ineficaz y la etiqueta con valor 5 a que el medicamente es altamente eficaz:

- Highly Effective (altamente efectivo): 5
- Considerably Effective (considerablemente efectivo) : 4
- Moderately Effective (moderadamente efectivo) : 3
- Marginally Effective (marginalmente efectivo) : 2
- Ineffective (ineficaz) : 1

```{r}
# Datos de entrenamiento
datos_train$effectivenessNumber[datos_train$effectiveness=="Highly Effective"]<-5
datos_train$effectivenessNumber[datos_train$effectiveness=="Considerably Effective"]<-4
datos_train$effectivenessNumber[datos_train$effectiveness=="Moderately Effective"]<-3
datos_train$effectivenessNumber[datos_train$effectiveness=="Marginally Effective"]<-2
datos_train$effectivenessNumber[datos_train$effectiveness=="Ineffective"]<- 1

# Datos de test
datos_test$effectivenessNumber[datos_test$effectiveness=="Highly Effective"]<-5
datos_test$effectivenessNumber[datos_test$effectiveness=="Considerably Effective"]<-4
datos_test$effectivenessNumber[datos_test$effectiveness=="Moderately Effective"]<-3
datos_test$effectivenessNumber[datos_test$effectiveness=="Marginally Effective"]<-2
datos_test$effectivenessNumber[datos_test$effectiveness=="Ineffective"]<-1
```

Comprobamos que se ha creado la nueva columna *effectivenessNumber*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$effectivenessNumber, 10) 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.5. Cálculo de rating ponderado

En esta sección se va a realizar una valoración general de la medicina, teniendo en cuenta los efectos secundarios y efectividad de ésta. Para ello, se va a realizar una ponderación entre estos dos valores, considerando en este caso una ponderación del 70\% para los efectos secundarios y un 30\% para la efectividad de la medicina.

El motivo de esta ponderación es que se considera que es peor tener efectos secundarios severos en una medicina, a que sea más efectiva o no.

Tras haber cuantificado las variables que miden la efectividad y efectos secundarios de una medicina, se ha añadido una nueva columna llamada "weightedRating", cuyo resultado se podrá utilizar como valoración general de la medicina, e incluso poder compararlo con las propias valoraciones de los usuarios.

```{r}
# Ponderaciones
sideEffectstWeight <- 0.7
effectivenessWeight <- 0.3

# Recorremos el dataframe
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_train$sideEffectsNumber[i]
  
  # Obtenemos el valor de efectiveness
  effectivenessRating <- datos_train$effectivenessNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, ya que 
  # sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para 
  # ello realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
  # Obtenemos el resultado ponderado en tipo float
  floatResult <- effectivenessRating * effectivenessWeight + sideEffectRating * sideEffectstWeight
  
  # Convertimos el resultado a valor entero.
  integerResult <- as.integer(floatResult)
  
  # Calculamos la parte decimal y redondeamos
  if(floatResult - integerResult < 0.5)
    result <- integerResult
  else
    result <- integerResult+1
  
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a escala (1-10)
  datos_train$weightedRating[i] <- result * 2
}
```

Comprobamos que se ha creado la nueva columna *weightedRating*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$weightedRating, 10) 
```

Ahora hacemos lo mismo en test:

```{r}
# Ponderaciones
sideEffectstWeight <- 0.7
effectivenessWeight <- 0.3

# Recorremos el dataframe
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_test$sideEffectsNumber[i]
  
  # Obtenemos el valor de efectiveness
  effectivenessRating <- datos_test$effectivenessNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, 
  # ya que sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para ello 
  # realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
  # Obtenemos el resultado ponderado en tipo float
  floatResult <- effectivenessRating * effectivenessWeight + sideEffectRating * sideEffectstWeight
  
  # Convertimos el resultado a valor entero.
  integerResult <- as.integer(floatResult)
  
  # Calculamos la parte decimal y redondeamos
  if(floatResult - integerResult < 0.5)
    result <- integerResult
  else
    result <- integerResult+1
  
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a escala (1-10)
  datos_test$weightedRating[i] <- result * 2
}
```

Comprobamos que se ha creado la nueva columna *weightedRating*, y que se han añadido los nuevos cambios.

```{r}
head(datos_train$weightedRating, 10) 
```


<!-------------------------------------------------------------------------------------------->

### 2.2.5. Convertir a etiquetas 0 y 1 la columna rating

La columna rating, está entre 0 y 10, pero en algunos casos, cuando queramos aplicar técnicas, deberemos tener una variable binaria, por eso, los numeros que están entre 1 a 4 son 0 y los que estan entre 5 y 10 son 1.

Lo hacemos en train

```{r}
# Recorremos el dataframe
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de rating
  rating <- datos_train$rating[i]
 
  if (datos_train$rating[i] < 5) # 1 a 2 - no favorable
    result <- 0
  else if (datos_train$rating[i] >= 5) # 3 a 5 - favorable
    result <- 1
  
  datos_train$ratingLabel[i]  <- result
}
```

Ahora en test

```{r}
# Recorremos el dataframe
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de rating
  rating <- datos_test$rating[i]
 
  if (datos_test$rating[i] < 5) # 1 a 2 - no favorable
    result <- 0
  else if (datos_test$rating[i] >= 5) # 3 a 5 - favorable
    result <- 1
  
  datos_test$ratingLabel[i]  <- result
}
```

<!-------------------------------------------------------------------------------------------->

### 2.2.6. Cambiar el orden de la columna sideEffectsNumber

Cuando queremos comparar la columna sideEffectsNumber con effectivenesNumber, ambas siguen distinto orden:

Ya que el 5 en sideEffectsNumber es efectos secundarios extremadamente graves y el 5 en effectivenesNumber es altamente efectivo, es por eso que se ha decidido cambiar el orden de sideEffectsNumber.

Para train

```{r}
# Recorremos el dataframe
for (i in 1:length(datos_train[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_train$sideEffectsNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, ya que 
  # sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para ello 
  # realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
 
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a escala (1-10)
  datos_train$sideEffectsInverse[i] <- sideEffectRating
}
```

Para test

```{r}
# Recorremos el dataframe
for (i in 1:length(datos_test[[1]])){
  
  # Obtenemos el valor de sideEffect
  sideEffectNumber <- datos_test$sideEffectsNumber[i]
  
  # Inicializamos la variable
  sideEffectRating <- 0
  # Convertimos el valor de sideEffect a la misma escala que efectiveness, ya que 
  # sideEffect == 1 significa que no tiene efectos secundarios (lo cual es bueno), 
  # y efecctiveness == 1 significa que no es efectivo (lo cual no es bueno). Para 
  # ello realizamos la siguiente conversión:
  if(sideEffectNumber == 1)
     sideEffectRating <- 5
  else if(sideEffectNumber == 2)
    sideEffectRating <- 4
  else if(sideEffectNumber == 3)
    sideEffectRating <- 3
  else if(sideEffectNumber == 4)
    sideEffectRating <- 2
  else if(sideEffectNumber == 5)
    sideEffectRating <- 1
 
  # Añadimos el resultado obtenido y lo multiplicamos por dos para pasarlo a escala (1-10)
  datos_test$sideEffectsInverse[i] <- sideEffectRating
}
```

<!-------------------------------------------------------------------------------------------->

### 2.2.7. Representación gráfica de los datos

Antes de comenzar con el análisis exploratorio, vamos realizar distintas gráfica de barras con el fin de comprender mejor los datos, antes del procesamiento. Primero realizaremos un gráfico de barras de las clasificaciones del medicamente por parte del paciente.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(rating) %>%
    ggplot(aes(x = factor(rating), y = n, fill = factor(rating))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación del medicamento por parte del paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold"))
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{imagenes/grafica_rating.png}
    \caption{Clasificación del medicamento por parte del paciente}
    \label{grafica_rating}
\end{figure}

En la figura \ref{grafica_rating}, se observa como más del 50% de los medicamentos obtienen una nota superior 6 por parte del paciente. Esto nos sugiere que el paciente, tiene una buena opinión sobre un alto porcentaje de los medicamentos, lo que puede dar lugar a opiniones más positivas.

Por otro lado, vamos a mostrar gráficamente los efectos secundarios del medicamento según el paciente. En donde el 1 significa que el medicamento tiene pocos efectos secundarios y el 5 que tiene muchos efectos secundarios. Como se aprecia en la figura \ref{grafica_sideEffectsNumber}, un alto porcentaje de los medicamentos no tiene efectos secundarios, de acuerdo a las valoraciones de los pacientes.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(sideEffectsNumber) %>%
    ggplot(aes(x = factor(sideEffectsNumber), y = n, fill = factor(sideEffectsNumber))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación de los efectos secundarios del medicamento según el paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold"))
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{imagenes/grafica_sideEffectsNumber.png}
    \caption{Clasificación de los efectos secundarios del medicamento según el paciente}
    \label{grafica_sideEffectsNumber}
\end{figure}

Por último, vamos a visualizar gráficamente, la efectividad del medicamentoe según del paciente. En donde el 1 significa que el medicamento tiene poca efectividad y el 5 que tiene mucha efectividad. De acuerdo a la figura \ref{grafica_sideEffectsNumber} y sabiendo que los pacientes aseguran que los medicamentos tienen pocos efectos secundarios, no es de extrañar que también tengan una alta efectividad.

```{r, include=FALSE, eval=FALSE}
datos_train %>% 
  count(effectivenessNumber) %>%
    ggplot(aes(x = factor(effectivenessNumber), y = n, fill = factor(effectivenessNumber))) +
        geom_col(color = "black") +
        geom_text(aes(label = n), position = position_stack(vjust = 0.5)) +
        scale_fill_brewer(palette="Paired") +
        labs(x = "Puntuación del medicamento", y = "Número de medicamentos") +
        ggtitle("Clasificación de la efectividad del medicamento según el paciente") +
        theme(legend.position = "none", plot.title = element_text(hjust = 0.5, face = "bold")) 
```

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{imagenes/grafica_effectivenessNumber.png}
    \caption{Clasificación de la efectividad del medicamento según el paciente}
    \label{grafica_sideEffectsNumber}
\end{figure}

Acabamos de comprobar, como las valoraciones de los medicamentos por parte de los pacientes son mayormente positivas.

Por tanto, una vez comprendidos los datos y eliminadas las columnas anteriores y modificadas las necesarias, ya podemos continuar con el procesamiento de los datos. Para ello, lo primero tenemos que hacer es cargar la librería que procesa los datos de tipo texto en R, para la construcción y manipulación del corpus. La librería más conocida se llama \textbf{tm}, aunque también haremos uso del paquete \textbf{SnowballC} para realizar el _Stemming_. Si no tenemos instaladas las librerías:

<!-------------------------------------------------------------------------------------------->

### 2.2.8. Creación del corpus

Para poder obtener la estructura con la que vamos a procesar nuestra información, debemos obtener un vector con documentos. En nuestro caso, cada uno de los documentos se corresponde con una opinión sobre un fármaco (*benefitsReview*) y los efectos que tiene (*sideEffectsReview*). Para ello, primero debemos de construir un vector con todas los opiniones del _dataframe_ y convertir cada elemento del vector al formato de documento. Podemos usar la función _VectorSource_ para hacer esta conversión. Se deberán realizar todas las modificaciones tanto para el conjunto train como test. 

```{r}
# Datos train

# Nos quedamos con la única columna del dataset que nos interesa. 
# Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, 
# por lo que usamos as.vector para hacer la conversión
benefits_train_review_data = as.vector(datos_train$benefitsReview)
effects_train_review_data = as.vector(datos_train$sideEffectsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus 
# que lo vamos a utilizar
benefits_train_corpus = (VectorSource(benefits_train_review_data))
effects_train_corpus = (VectorSource(effects_train_review_data))

# Creamos el propio corpus
benefits_train_corpus <- Corpus(benefits_train_corpus)
effects_train_corpus <- Corpus(effects_train_corpus)
``` 

```{r}
# Datos test

# Nos quedamos con la única columna del dataset que nos interesa. 
# Necesitamos obtenerla en forma de vector, y no como un dataframe de una columna, 
# por lo que usamos as.vector para hacer la conversión
benefits_test_review_data = as.vector(datos_test$benefitsReview)
effects_test_review_data = as.vector(datos_test$sideEffectsReview)

# Lo convertimos en la estructura de documento, y lo guardamos ya en el corpus 
# que lo vamos a utilizar
benefits_test_corpus = (VectorSource(benefits_test_review_data))
effects_test_corpus = (VectorSource(effects_test_review_data))

# Creamos el propio corpus
benefits_test_corpus <- Corpus(benefits_test_corpus)
effects_test_corpus <- Corpus(effects_test_corpus)
``` 

Podemos ver que funciona accediendo a uno cualquiera, de la forma `inspect(benefits_train_corpus[4])`:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_train_corpus1.png}
    \caption{Contenido de benefits\_train\_corpus I}
    \label{benefits1}
\end{figure}

O de la forma `benefits_train_corpus[[4]]$content`:

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_train_corpus2.png}
    \caption{Contenido de benefits\_train\_corpus II}
    \label{benefits2}
\end{figure}

Y si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación.

```{r, include=FALSE}
# Si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación
inspect(benefits_train_corpus[4])

benefits_train_corpus[[4]]$content
```

```{r, include=FALSE}
# Si nos fijamos en el contenido, vemos que tiene signos de puntuación y exclamación
inspect(effects_train_corpus[7])
effects_train_corpus[[7]]$content
```

<!-------------------------------------------------------------------------------------------->

### 2.2.9. Representación gráfica de las frecuencias

Una vez creado el corpus y antes de aplicar las técnicas, vamos a visualizar las frecuencias, para las dos columnas (*benefitsReview* y *sideEffectsReview*) de textos a las que vamos aplicar el preprocesamiento. Para ello, debemos calcular la matriz de términos y obtener los términos con mayor frecuencia.

```{r, echo=FALSE}
# Frecuencias para benefits en train
# https://rstudio-pubs-static.s3.amazonaws.com/40817_63c8586e26ea49d0a06bcba4e794e43d.html

# Cargamos la librería

# Calculamos la matriz de términos
dtm <- DocumentTermMatrix(benefits_train_corpus)

# Calculamos la frecuencia
freq <- sort(colSums(as.matrix(dtm)), decreasing=FALSE)
wf <- data.frame(word=names(freq), freq=freq)

# Dibujamos el histograma
subset(wf, freq>350)    %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat="identity", fill="darkred", colour="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  ggtitle("Frecuencias para benefits en train sin preprocesamiento") 

```

A continuación, mostramos los términos para la columna *sideEffects*, realizando el mismo procedimiento que antes.

```{r, echo=FALSE}
# Frecuencias para sideEffects en train
# https://rstudio-pubs-static.s3.amazonaws.com/40817_63c8586e26ea49d0a06bcba4e794e43d.html

# Calculamos la matriz de términos
dtm <- DocumentTermMatrix(effects_train_corpus)

# Calculamos la frecuencia
freq <- sort(colSums(as.matrix(dtm)), decreasing=FALSE)
wf <- data.frame(word=names(freq), freq=freq)

# Dibujamos el histograma
subset(wf, freq>350)    %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat="identity", fill="darkred", colour="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  ggtitle("Frecuencias para sideEffects en train sin preprocesamiento") 
```

<!-------------------------------------------------------------------------------------------->

### 2.2.10. Correlación

Una forma de medir la distancia es calcular la correlación entre un término y todos los demás de la matriz. Como en este caso, estamos usando variables textuales, no se recomienda hacer la correlación. Ya que está pensada para variables cuantitativas, y nosotgros disponemos de variables categóricas. Por otro lado, la correlación está relacionada con el análisis de componentes principales (PCA), por tanto, tampoco sería posible la realización de dicha técnica. 

<!-------------------------------------------------------------------------------------------->

### 2.2.11. Eliminar signos de puntuación

Como hemos podido ver en el documento que se ha mostrado por pantalla, en él se aprecia el uso de signos de puntuación y exclamación. En un principio, no tiene sentido en \textit{Data Mining} contemplar los signos de puntuación, ya que no nos van a aportar información. Por ello, los quitamos, como se puede ver a continuación. Con `tm_map(corpus, removePunctuation)`, se eliminan los símbolos: ! " $ % & ' () * + , - . / : ; < = > ? @ [ \ ] ^ _ ' { | } ~ 

```{r, warning=FALSE}
# Una vez que tenemos el corpus creado, continuamos con el procesamiento para datos train
benefits_train_corpus <- tm_map(benefits_train_corpus,
                                content_transformer(removePunctuation))
effects_train_corpus <- tm_map(effects_train_corpus, 
                               content_transformer(removePunctuation))

# Una vez que tenemos el corpus creado, continuamos con el procesamiento para datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, 
                               content_transformer(removePunctuation))
effects_test_corpus <- tm_map(effects_test_corpus, 
                              content_transformer(removePunctuation))
```

Si volvemos a mostrar la opinión número cuatro, vemos como todos los signos han desaparecido. De hecho, podemos inspeccionar el corpus, y se ve como todos los signos de puntuación, exclamación y derivados ya no están.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_signos_puntuacion.png}
    \caption{Contenido de benefits\_train\_corpus con inspect(benefits\_train\_corpus[4])}
    \label{benefits2}
\end{figure}

```{r, include=FALSE}
inspect(benefits_train_corpus[4])
```

Ocurre lo mismo con el comentario de efectos número siete.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_signos_puntuacion.png}
    \caption{Contenido de effects\_train\_corpus con inspect(effects\_train\_corpus[7])}
    \label{benefits2}
\end{figure}

```{r, include=FALSE}
inspect(effects_train_corpus[7])
```

<!-------------------------------------------------------------------------------------------->

### 2.2.12. Conversión de las mayúsculas en minúsculas

Para poder hacer uso de los términos por igual, debemos convertir las mayúsculas en minúsculas. Ya que normalmente se convierte en minúsculas todas las letras para que los comienzos de oración no sean tratados de manera diferente por los algoritmos.

```{r, warning=FALSE}
# Datos train
benefits_train_corpus <- tm_map(benefits_train_corpus, content_transformer(tolower))
effects_train_corpus <- tm_map(effects_train_corpus, content_transformer(tolower))

# Datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, content_transformer(tolower))
effects_test_corpus <- tm_map(effects_test_corpus, content_transformer(tolower))
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_mayusculas.png}
    \caption{inspect(benefits\_train\_corpus[4])}
    \label{benefits2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_mayusculas.png}
    \caption{inspect(effects\_train\_corpus[7])}
    \label{benefits2}
\end{figure}

<!-------------------------------------------------------------------------------------------->

### 2.2.13. Eliminación de Stopwords

En cualquier idioma, hay palabras que son tan comunes o muy utilizadas que no aportan información relevante, a dichas palabras se las conoce como _stopwords_ o palabras _stop_. Por ejemplo, en español, las palabras "la", "a", "en", "de" son ejemplos de _stopwords_. Este tipo de palabras debemos de suprimirlas de nuestro corpus. Como, en nuestro caso, el contenido del corpus está en inglés, debemos especificar el idioma correcto para que nos elimine del corpus las palabras adecuadas en dicho idioma.

```{r, warning=FALSE}
# Datos train
benefits_train_corpus <- tm_map(benefits_train_corpus, content_transformer(removeWords), 
                                stopwords("english"))
effects_train_corpus <- tm_map(effects_train_corpus, content_transformer(removeWords), 
                               stopwords("english"))

# Datos test
benefits_test_corpus <- tm_map(benefits_test_corpus, content_transformer(removeWords), 
                               stopwords("english"))
effects_test_corpus <- tm_map(effects_test_corpus, content_transformer(removeWords), 
                              stopwords("english"))
```

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/benefits_stopwords.png}
    \caption{inspect(benefits\_train\_corpus[4])}
    \label{benefits2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{imagenes/effects_stopwords.png}
    \caption{inspect(effects\_train\_corpus[7])}
    \label{benefits2}
\end{figure}

Ahora ya hemos eliminado las stopwords de forma correcta.

<!-------------------------------------------------------------------------------------------->

### 2.2.14. Agrupación de sinónimos

Con el fin de disminuir la dimensión del espacio a trabajar, se pueden identificar palabras distintas con el mismo significado y reemplazarlas por una sola palabra. Para ello se toman los sinónimos de dicha palabra. Dentro de las librerías que podemos usar para agrupar sinónimos, destacamos dos: `wordnet` y `rword2vec`. Sin embargo, por su sencillez se va hacer uso de `rword2vec`. Previamente, se obtendrán que palabras son las que mayor frecuencia presentan en nuestro texto, para ello nos quedamos con las 100 más representativas tanto para *benefitsReview* como *sideEffectsReview* del conjunto train y test:

```{r}
# Columna benefitsReview del conjunto train

# Obtenemos su matriz de términos
matrix_train_benefits_corpus <- TermDocumentMatrix(benefits_train_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_train_benefits_corpus <- as.matrix(matrix_train_benefits_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_train_benefits_corpus <- rowSums(matrix_train_benefits_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_benefits_train_corpus <- sort(matrix_train_benefits_corpus, decreasing = TRUE)
terms_frecuency_benefits_train_corpus <- terms_frecuency_benefits_train_corpus[1:length(benefits_train_corpus)]
# terms_frecuency_benefits_train_corpus
```

```{r}
# Columna benefitsReview del conjunto test

# Obtenemos su matriz de términos
matrix_test_benefits_corpus <- TermDocumentMatrix(benefits_test_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_test_benefits_corpus <- as.matrix(matrix_test_benefits_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_test_benefits_corpus <- rowSums(matrix_test_benefits_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_benefits_test_corpus <- sort(matrix_test_benefits_corpus, decreasing = TRUE)
terms_frecuency_benefits_test_corpus <- terms_frecuency_benefits_test_corpus[1:length(benefits_test_corpus)]
# terms_frecuency_benefits_test_corpus
```

```{r}
# Columna sideEffectsReview del conjunto train

# Obtenemos su matriz de términos
matrix_train_effects_corpus <- TermDocumentMatrix(effects_train_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_train_effects_corpus <- as.matrix(matrix_train_effects_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_train_effects_corpus <- rowSums(matrix_train_effects_corpus)
# Ordenamos de mayor a menor los términos y nos quedamos con lso 100 primeros
terms_frecuency_effects_train_corpus <- sort(matrix_train_effects_corpus, decreasing = TRUE)
terms_frecuency_effects_train_corpus <- terms_frecuency_effects_train_corpus[1:length(effects_train_corpus)]
# terms_frecuency_effects_train_corpus
```

```{r}
# Columna benefitsReview del conjunto test

# Obtenemos su matriz de términos
matrix_test_effects_corpus <- TermDocumentMatrix(effects_test_corpus)
# No tenemos los datos en la matriz que buscamos, sino en un vector
# por tanto, lo convertimos en matriz
matrix_test_effects_corpus <- as.matrix(matrix_test_effects_corpus)
# Sumamos las filas para obtener la frecuencia de una palabra en benefitsReview
matrix_test_effects_corpus <- rowSums(matrix_test_effects_corpus)
# Ordenamos de mayor a menor los términos
terms_frecuency_effects_test_corpus <- sort(matrix_test_effects_corpus, decreasing = TRUE)
terms_frecuency_effects_test_corpus <- terms_frecuency_effects_test_corpus[1:length(effects_test_corpus)]
# terms_frecuency_effects_test_corpus
```

Y visualizamos dichos términos gráficamente:

```{r}
par(mfrow=c(2,2))

graph_terms_frecuency_benefits_train_corpus <- as.matrix(terms_frecuency_benefits_train_corpus)
barplot(graph_terms_frecuency_benefits_train_corpus[1:5,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=5, name="Zissou1"))
title(main = list("benefits_train", font = 2))

graph_terms_frecuency_benefits_test_corpus <- as.matrix(terms_frecuency_benefits_test_corpus)
barplot(graph_terms_frecuency_benefits_test_corpus[1:5,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=5, name="Zissou1"))
title(main = list("benefits_test", font = 2))

graph_terms_frecuency_effects_train_corpus <- as.matrix(terms_frecuency_effects_train_corpus)
barplot(graph_terms_frecuency_effects_train_corpus[1:5,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=5, name="Zissou1"))
title(main = list("effects_train", font = 2))

graph_terms_frecuency_effects_test_corpus <- as.matrix(terms_frecuency_effects_test_corpus)
barplot(graph_terms_frecuency_effects_test_corpus[1:5,],  xlab="Términos", ylab="Número de frecuencia",
        col=wes_palette(n=5, name="Zissou1"))
title(main = list("effects_test", font = 2))
```

Una vez que tenemos los términos con mayor frecuencia en nuestra columna *benefitsReview* y su frecuencia asociada, pasamos a matriz dichos datos, con el fin de obtener solo las palabras y descartar su frecuencia.

```{r}
# Columna benefitsReview del conjunto train

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_benefits_train_corpus <- as.matrix(terms_frecuency_benefits_train_corpus)
# terms_frecuency_benefits_train_corpus

# Me quedo solo con los términos
terms_benefits_train_corpus <- rownames(terms_frecuency_benefits_train_corpus)
# terms_benefits_train_corpus
```

```{r}
# Columna benefitsReview del conjunto test

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_benefits_test_corpus <- as.matrix(terms_frecuency_benefits_test_corpus)
# terms_frecuency_benefits_test_corpus

# Me quedo solo con los términos
terms_benefits_test_corpus <- rownames(terms_frecuency_benefits_test_corpus)
# terms_benefits_test_corpus
```

```{r}
# Columna sideEffectsReview del conjunto train

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_effects_train_corpus <- as.matrix(terms_frecuency_effects_train_corpus)
# terms_frecuency_effects_train_corpus

# Me quedo solo con los términos
terms_effects_train_corpus <- rownames(terms_frecuency_effects_train_corpus)
# terms_effects_train_corpus
```

```{r}
# Columna sideEffectsReview del conjunto test

# Convertimos a matriz "terms_frecuency_benefits_corpus_100"
terms_frecuency_effects_test_corpus <- as.matrix(terms_frecuency_effects_test_corpus)
# terms_frecuency_effects_test_corpus

# Me quedo solo con los términos
terms_effects_test_corpus <- rownames(terms_frecuency_effects_test_corpus)
# terms_effects_test_corpus
```

Como ya sabemos las palabras a usar, es decir, los términos que más se repite, procedemos a la agrupación por sinónimos. En donde, mediante la función *distance(...)* de la libería *rword2vec*, obtendremos todas palabras más similares de nuestro conjunto, en nuestro caso nos vamos a quedar con las 2 primeras:

```{r}
# http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/
# https://github.com/mukul13/rword2vec
# http://www.rpubs.com/mukul13/rword2vec
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto train

# Escribo en un fichero la columna "benefitsReview"
# write.table(datos_train$benefitsReview, "benefitsTrainReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_benefits_train = word2vec(train_file = "benefitsTrainReview.txt", output_file = "benefitsTrainReview.bin", binary=1)

#dist_terms_benefits_train_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_benefits_train_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_benefits_train_corpus[i] = distance(file_name = "benefitsTrainReview.bin", 
#                                                 search_word = terms_benefits_train_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_benefits_train_corpus, 'datos/ficheros-sinonimos/benefits/dist_terms_benefits_train_corpus.RData')
dist_terms_benefits_train_corpus_new <- list.load('datos/ficheros-sinonimos/benefits/dist_terms_benefits_train_corpus.RData')
```

```{r, include=FALSE}
# Columna benefitsReview del conjunto test

# Escribo en un fichero la columna "benefitsReview"
# write.table(datos_test$benefitsReview, "benefitsTestReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_benefits_test = word2vec(train_file = "benefitsTestReview.txt", output_file = "benefitsTestReview.bin", binary=1)

#dist_terms_benefits_test_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_benefits_test_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_benefits_test_corpus[i] = distance(file_name = "benefitsTestReview.bin", 
#                                                 search_word = terms_benefits_test_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_benefits_test_corpus, 'datos/ficheros-sinonimos/benefits/dist_terms_benefits_test_corpus.RData')
dist_terms_benefits_test_corpus_new <- list.load('datos/ficheros-sinonimos/benefits/dist_terms_benefits_test_corpus.RData')
```

```{r, include=FALSE}
# Columna sideEffects del conjunto train

# Escribo en un fichero la columna "sideEffectsReview"
# write.table(datos_train$sideEffectsReview, "effectsTrainReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_effects_train = word2vec(train_file = "effectsTrainReview.txt", output_file = "effectsTrainReview.bin", binary=1)

#dist_terms_effects_train_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_effects_train_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_effects_train_corpus[i] = distance(file_name = "effectsTrainReview.bin", 
#                                                 search_word = terms_effects_train_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_effects_train_corpus, 'datos/ficheros-sinonimos/effects/dist_terms_effects_train_corpus.RData')
dist_terms_effects_train_corpus_new <- list.load('datos/ficheros-sinonimos/effects/dist_terms_effects_train_corpus.RData')
```

```{r, include=FALSE}
# Columna sideEffects del conjunto test

# Escribo en un fichero la columna "sideEffectsReview"
# write.table(datos_test$sideEffectsReview, "effectsTestReview.txt", sep = "\t", quote = F, row.names = F)

# Entreno los datos del texto para obtener los vectores de palabras
# model_effects_test = word2vec(train_file = "effectsTestReview.txt", output_file = "effectsTestReview.bin", binary=1)

#dist_terms_effects_test_corpus = c()
# Obtengo la distancia de las 100 palabras con mayor frecuencia
#for (i in 1:length(terms_effects_test_corpus)){ # calculamos la distancia de la palabra a sus sinónimos
#  dist_terms_effects_test_corpus[i] = distance(file_name = "effectsTestReview.bin", 
#                                                 search_word = terms_effects_test_corpus[i], num = 2)
#}

# guardamos en un fichero
#list.save(dist_terms_effects_test_corpus, 'datos/ficheros-sinonimos/effects/dist_terms_effects_test_corpus.RData')
dist_terms_effects_test_corpus_new <- list.load('datos/ficheros-sinonimos/effects/dist_terms_effects_test_corpus.RData')
```

Una vez, que tenemos todas las palabras con los 2 términos más similares, procedemos a sustituir todos esos términos por el término general, es decir:

```{r}
# Obtenemos el tercer término -> "drug"
terms_benefits_train_corpus[3]

# Vamos a sustituir "pain" por sus dos palabras más similares
dist_terms_benefits_train_corpus_new[[3]]
```

Por último, ya solo nos queda hacer el reemplazamiento, para ello se usará la función *gsub(...)* sobre el corpus (benefits_corpus). Para sustituir las palabras en el texto, se ha uso de la función `gsub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE, fixed = FALSE, useBytes = FALSE)`. 

```{r, warning=FALSE}
# Para la columna benefitsReview del conjunto train

#dist_terms_benefits_train_corpus_new <- list.remove(dist_terms_benefits_train_corpus_new, c(446, 506))
# dist_terms_benefits_train_corpus_new <- list.remove(dist_terms_benefits_train_corpus_new, c(447, 508, 651, 678, 686, 815, 982, 996))
# dist_terms_benefits_train_corpus <- list.remove(dist_terms_benefits_train_corpus, c(1049, 1077, 1103, 1123, 1186, 1229, 1562, 1617,1659))

#View(dist_terms_benefits_train_corpus)

#for (i in 1:640) # iteramos sobre los terminos, hasta el 1797, porque si vemos el fichero, ya no hay más palabras
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    benefits_train_corpus_new <- tm_map(benefits_train_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_benefits_train_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_benefits_train_corpus[i]))

# guardar "benefits_train_corpus_new"
#saveRDS(benefits_train_corpus_new, file = "datos/ficheros-sinonimos/benefits/benefits_train_corpus_new.rds")
benefits_train_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/benefits/benefits_train_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(benefits_train_corpus$content, "datos/ficheros-sinonimos/benefits/benefitsTrainSinSinonimos.txt")
write.table(benefits_train_corpus_new_load$content, "datos/ficheros-sinonimos/benefits/benefitsTrainConSinonimos.txt")
```

```{r, warning=FALSE}
# Para la columna benefitsReview del conjunto test

# dist_terms_benefits_test_corpus_new <- list.remove(dist_terms_benefits_test_corpus_new, c(171, 470))

#for (i in 1:450) # iteramos sobre los terminos 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    benefits_test_corpus_new <- tm_map(benefits_test_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_benefits_test_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_benefits_test_corpus[i]))

# guardar "benefits_train_corpus_new"
#saveRDS(benefits_test_corpus_new, file = "datos/ficheros-sinonimos/benefits/benefits_test_corpus_new.rds")
benefits_test_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/benefits/benefits_test_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(benefits_test_corpus$content, "datos/ficheros-sinonimos/benefits/benefitsTestSinSinonimos.txt")
write.table(benefits_test_corpus_new_load$content, "datos/ficheros-sinonimos/benefits/benefitsTestConSinonimos.txt")
```

```{r, warning=FALSE}
# Para la columna sideEffectsReview del conjunto train

#dist_terms_effects_train_corpus_new <- list.remove(dist_terms_effects_train_corpus_new, c(318, 504, 654, 706, 734, 991))

#for (i in 1:710) # iteramos sobre los terminos, hasta el 1539, porque si vemos el fichero, ya no hay más palabras 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    effects_train_corpus_new <- tm_map(effects_train_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_effects_train_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_effects_train_corpus[i]))

# guardar "effects_train_corpus_new"
# saveRDS(effects_train_corpus_new, file = "effects_train_corpus_new.rds")
effects_train_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/effects/effects_train_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(effects_train_corpus$content, "datos/ficheros-sinonimos/effects/effectsTrainSinSinonimos.txt")
write.table(effects_train_corpus_new_load$content, "datos/ficheros-sinonimos/effects/effectsTrainConSinonimos.txt")
```


```{r, warning=FALSE}
# Para la columna sideEffectsReview del conjunto test


#for (i in 1:450) # iteramos sobre los terminos 
#  for (j in 1:2) # iteramos sobre los sinónimos, en este caso solo tenemos 2
#    effects_test_corpus_new <- tm_map(effects_test_corpus, content_transformer(gsub), 
#                                  pattern = tolower(as.character(dist_terms_effects_test_corpus_new[[i]][j])), 
#                                  replacement = as.character(terms_effects_test_corpus[i]))

# guardar "effects_train_corpus_new"
#saveRDS(effects_test_corpus_new, file = "datos/ficheros-sinonimos/effects/effects_test_corpus_new.rds")
effects_test_corpus_new_load <- readRDS(file = "datos/ficheros-sinonimos/effects/effects_test_corpus_new.rds")

# Comprobamos que efectivamente se han producido cambios, por ejemplo al revisar el término "medication""
write.table(effects_test_corpus$content, "datos/ficheros-sinonimos/effects/effectsTestSinSinonimos.txt")
write.table(effects_test_corpus_new_load$content, "datos/ficheros-sinonimos/effects/effectsTestConSinonimos.txt")
```












<!---------->

# Arboles de decision y clasificacion

## Arboles de decision

El árbol de decisión es una técnica clásica de clasificación en la que se realizan particiones binarias
de los datos de forma recursiva. El resultado se puede representar con un árbol.

Para la construcción del árbol también se puede utilizar la función **rpart**.El principal parámetro de esta función es la complejidad, **cp**. Éste permite
simplificar los modelos ajustados mediante la poda de las divisiones que no merecen la pena. Otros
parámetros importantes son **minsplit**, número mínimo de observaciones que debe haber en un nodo
para que se intente una partición, y **minbucket**, número mínimo de observaciones de un nodo terminal.
Por defecto minsplit= 20, minbucket=round(minsplit/3) y cp= 0,01.

A la hora de determinar los parámetros, el procedimiento habitual para determinar los parámetros del modelo consiste en dejar que el árbol crezca hasta que cada nodo terminal tenga menos de un número mínimo de observaciones, ya que
en algunas divisiones puede que apenas mejore y en las siguientes sí lo haga. Para determinar *cp* se
considera como 0, para que el árbol crezca lo máximo posible.

A continuación se va aplicar dicha técnica para realizar las siguientes predicciones:

### Predicción de efectivenessNumber en función del rating

En esta sección se va a predecir la efectividad (de 1 a 5, siendo 1 menos efectiva y 5 más efectiva) en función del rating. Para ello se va a seguir con el procedimiento que se ha descrito en la introdución.

A continuación se va a mostrar el árbol de decisión que se ha generado utilizando **rpart**.

```{r}

library("rattle")
library("rpart")
library("rpart.plot")

seed <- 42

set.seed(seed)

rpart <- rpart(effectivenessNumber ~ rating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.00,
                usesurrogate=0,
                maxsurrogate=0)
              )

fancyRpartPlot(rpart, main="Decision Tree effectivenessNumber $ ratingLabel")

```

Como el árbol que se obtiene es muy grande, se podaría considerando una función de coste basada
en la complejidad. Para esto, se calcula el error de la validación cruzada y se elige el menor.

```{r}
plotcp(rpart)
              
```


```{r}
printcp(rpart)
```


Tal y como se puede ver en la tabla anterior, el mínimo error se alcanza en el nodo 6.

    6 0.000000      6   0.67362 0.67644 0.015294
    
Típicamente se considera que hasta la línea discontinua de la figura anterior no hay diferencias significativas. Esta línea es la suma del mínimo error y la desviación típica, es decir:

    0.67644 + 0.015294 = 0.691734
    
Observamos en el gráfico anterior que dicho error tiene un cp de 0.023, por lo que se va a volver a generar el árbol con rpart utilizando ahora como valor de cp 0,023.

```{r}
set.seed(seed)
rpart <- rpart(effectivenessNumber ~ rating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.023,
                usesurrogate=0,
                maxsurrogate=0)
              )
# Vista textual del modelo árbol de decisión:
print(rpart)

fancyRpartPlot(rpart, main="Árbol de decisión effectivenessNumber $ rating")

```

A continuación se lleva a cabo la predicción del conjunto de prueba y se calcula la matriz de confusión.

Para cada uno de los datos del conjunto de prueba se sigue el árbol según el valor de sus variables
hasta llegar a los nodos terminales, allí, se clasifica con la categoría más probable de ese nodo terminal,
como se vio en el árbol anterior.

La denominada matriz de confusión permite la visualización de los resultados del clasificador. Las
filas muestran los valores reales y las columnas las predicciones del modelo. A partir de esta tabla se
calcula la precisión del modelo.

```{r}

pred <- predict(rpart, newdata=datos_test, type="class")

# Matriz de confusión
tabla <-table(datos_test$effectivenessNumber, pred, useNA="ifany",
dnn=c("Real", "Predicho" ))

tabla

```

Esta tabla es la denominada matriz de confusión, que permite la visualización de los resultados del
clasificador. Las filas muestran los valores reales y las columnas las predicciones del modelo. A partir
de esta tabla se calcula la precisión del modelo.

```{r}
sum(diag(tabla))/nrow(datos_test)

```

La precisión de este modelo es del **57,44%** aproximadamente.

El poder de predicción de los árboles de decisión no suele ser muy bueno, pero el algoritmo es
sencillo y los modelos resultantes tienen una fácil interpretación. 


### Predicción de sideEffectsNumber en función del rating

Siguiendo el mismo proceso que se ha seguido para la obtención del árbol generado anteriormente, se va a predecir el valor de efectos secundarios en función del rating del medicamento.

```{r}

library("rattle")
library("rpart")
library("rpart.plot")

seed <- 42

set.seed(seed)

rpart <- rpart(sideEffectsNumber ~ rating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.01,
                usesurrogate=0,
                maxsurrogate=0)
              )


print(rpart)

fancyRpartPlot(rpart, main="Decision Tree sideEffectsNumberr $ ratingLabel")

```

```{r}
set.seed(seed)

rpart <- rpart(sideEffectsNumber ~ rating, data=datos_test,
                  method="class",
                  parms=list(split="information"),
                  control=rpart.control(minsplit=30,
                  minbucket=10,
                  cp=0.0,
                  usesurrogate=0,
                  maxsurrogate=0)
              )
plotcp(rpart)

              
```


```{r}
set.seed(seed)
rpart <- rpart(sideEffectsNumber ~ rating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.0,
                usesurrogate=0,
                maxsurrogate=0)
              )
# Vista textual del modelo árbol de decisión:
print(rpart)

fancyRpartPlot(rpart, main="Árbol de decisión sideEffectsNumber $ rating")

```




```{r}
pred <- predict(rpart, newdata=datos_test, type="class")

# Matriz de confusión
tabla <-table(datos_test$sideEffectsNumber, pred, useNA="ifany",
dnn=c("Real", "Predicho" ))

tabla
```


```{r}

sum(diag(tabla))/nrow(datos_test)

```

La precisión de este modelo es del **50,58%** aproximadamente.


### Predicción de effectivenessNumber en función del weightedRating

Siguiendo el mismo proceso que se ha seguido para la obtención del árbol generado anteriormente, se va a predecir el valor de efectos secundarios del medicamento en función del rating ponderado que se ha generado durante el procesamiento ( 70% efectos secundarios, 30% efectividad).

```{r}
seed <- 42

set.seed(seed)

rpart <- rpart(effectivenessNumber ~ weightedRating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.03,
                usesurrogate=0,
                maxsurrogate=0)
              )


print(rpart)

fancyRpartPlot(rpart, main="Decision Tree effectivenessNumber $ weightedRating")

```

```{r}
set.seed(seed)

rpart <- rpart(effectivenessNumber ~ weightedRating, data=datos_test,
                  method="class",
                  parms=list(split="information"),
                  control=rpart.control(minsplit=30,
                  minbucket=10,
                  cp=0.0,
                  usesurrogate=0,
                  maxsurrogate=0)
              )
plotcp(rpart)

              
```


```{r}

pred <- predict(rpart, newdata=datos_test, type="class")

# Matriz de confusión
tabla <-table(datos_test$effectivenessNumber, pred, useNA="ifany",
dnn=c("Real", "Predicho" ))

tabla
```

```{r}
sum(diag(tabla))/nrow(datos_test)

```



### Predicción de sideEffectsNumber en función del weightedRating

```{r}

library("rattle")
library("rpart")
library("rpart.plot")

seed <- 42

set.seed(seed)

rpart <- rpart(sideEffectsNumber ~ weightedRating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.01,
                usesurrogate=0,
                maxsurrogate=0)
              )


print(rpart)

fancyRpartPlot(rpart, main="Decision Tree sideEffectsNumberr $ weightedRatingl")

```

```{r}
set.seed(seed)

rpart <- rpart(sideEffectsNumber ~ weightedRating, data=datos_test,
                  method="class",
                  parms=list(split="information"),
                  control=rpart.control(minsplit=30,
                  minbucket=10,
                  cp=0.0,
                  usesurrogate=0,
                  maxsurrogate=0)
              )
plotcp(rpart)

              
```


```{r}
set.seed(seed)
rpart <- rpart(sideEffectsNumber ~ weightedRating, data=datos_train,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.05,
                usesurrogate=0,
                maxsurrogate=0)
              )
# Vista textual del modelo árbol de decisión:
print(rpart)

fancyRpartPlot(rpart, main="Árbol de decisión sideEffectsNumber $ rating")

```



```{r}

pred <- predict(rpart, newdata=datos_test, type="class")

# Matriz de confusión
tabla <-table(datos_test$sideEffectsNumber, pred, useNA="ifany",
dnn=c("Real", "Predicho" ))

tabla

sum(diag(tabla))/nrow(datos_test)

```


```{r}
set.seed(seed)
rpart <- rpart(rating ~ benefitsReview , data=datos_test,
                method="class",
                parms=list(split="information"),
                control=rpart.control(minsplit=30,
                minbucket=10,
                cp=0.05,
                usesurrogate=0,
                maxsurrogate=0)
              )
# Vista textual del modelo árbol de decisión:
print(rpart)

fancyRpartPlot(rpart, main="Árbol de decisión sideEffectsNumber $ rating")

```


Con el fin de mejorar esta predicción, se puede seguir la idea del bagging de combinar muchos métodos sencillos, como se verá en el método
de bosques aleatorios.







## Clasificación Bayesiona: algoritmo clasico

## Clasificación Bayesiona: clasificador Naive Bayes                

```{r}
# https://rpubs.com/jboscomendoza/naive_nayes_con_r_clasificacion_texto

library(tidyverse)
library(tidytext)
library(naivebayes)
library(tm)
library(caret)
```

## Random Forest

```{r}
# Proyecto_1475.pdf (esto es un ejemplo, adaptarko al nuestro)

# Establecemos una semilla por defecto
set.seed(127)

train <- datos_train
test <- datos_test

# Obtenemos el modelo
library(randomForest)
modelo_rf <- randomForest(rating  ~ effectivenessNumber, data = train)
modelo_rf

# Comprobación del modelo con los datos del test:
pred <- predict(modelo_rf, newdata = test)

# Matriz de confusión:
tabla <- table(pred, datos_test$rating); 
tabla

# Dice la precisión
sum(diag(tabla)) / nrow(test)
```


```{r}
# usar la curva ROC
library("ROCR")

# Función que dibuja una curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, main="Curva ROC", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}

# Para hacer la curva ROC dben etar en probabildiad entre 0 y 1
```


## Clasificacores basados en RRNN

## Suuport Vector Machine SVM

```{r}
# Proyecto_1475.pdf

library("kernlab")

# Se aplica el SVM a los datos de entrenamiento:
ksvmTrain <- ksvm (rating  ~ effectivenessNumber, data = train)

# Se clasifica el conjunto de datos de prueba a partir del SVM entrenado, # para ello, se elimina la columna donde está la clasificación original: 
svmClass <- predict (ksvmTrain, datos_test$rating)

# Matriz de confusión:
svmTabla <- table(SVM = svmClass, Reuters = trueClass); 
svmTabla

# La precisión de este método es aproximadamente de
sum(diag(svmTabla))/nrow(test)

```


