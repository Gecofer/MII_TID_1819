---
title: "extraccion_reglas_asociacion"
author: "Andrea Morales Garzón"
date: "6 de diciembre de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Lectura de los conjuntos train y test
```{r, warning=FALSE}
# Lectura de datos train
datos_train <- read.table("datos/drugLibTrain_raw.tsv", sep="\t", comment.char="",
                          quote = "\"", header=TRUE)
```

Primero leemos los datos de train.
```{r, warning=FALSE}
# Visualizar las 5 primeras filas para los datos train
head(datos_train, 5) 
# Resumen sobre los datos train
summary(datos_train) 
```

A continuación leemos los datos de test.
```{r, warning=FALSE}
# Lectura de datos test
datos_test <- read.table("./datos/drugLibTest_raw.tsv", sep="\t", comment.char="",
                         quote = "\"", header=TRUE)
```

Nos interesa quedarnos con la columna que se corresponde con benefits_review, por tanto vamos a quedarnos únicamente con esa columna. El proceso es un poco distinto, ya que no es tanto quitar las columnas que no nos interesan del dataset, sino únicamente copiar en una estructura separada aquella con la que queremos trabajar.
```{r}
benefits_review_data = as.vector(datos_train$benefitsReview)

```


Primero, para hacer la prueba del funcionamiento de n-gramas, vamos a utilizar un único documento. Es decir, con un documento, nos referimos a un único comentario de la base de datos, por ejemplo, vamos a quedarnos con uno cualquiera
```{r}
document_ngramas = benefits_review_data[3]
print(document_ngramas)
```

A continuación, vamos a intentar aplicarle la técnica de n-gramas. Lo primero es instalar y cargar todas las librerías necesarias. 
```{r, warning=FALSE}
library(dplyr)
library(tidytext)
```

```{r}
tidy_document <- data_frame(line = 1:3107, text = datos_train$benefitsReview)

document_bigrama <- tidy_document %>%
  unnest_tokens(word, text, token = "ngrams", n = 1) 

head(document_bigrama)
```

Pasos siguientes:

1. Quitar los stops words, que no lo consigo.
2. Sacar un recuento.

```{r}
# Cogemos los stopwords que ya quitamos (hacer el corpus)
library("tm")

benefits_review_data = as.vector(datos_train$benefitsReview)
benefits_corpus = (VectorSource(benefits_review_data))
benefits_corpus <- Corpus(benefits_corpus)

benefits_corpus <- tm_map(benefits_corpus, content_transformer(removeWords), stopwords("english"))

# -----------

tidy_dat <- tidyr::gather(dat, key, word) %>% select(word)

tokens <- tidy_dat %>% 
  unnest_tokens(word, word) %>% 
  dplyr::count(word, sort = TRUE) %>% 
  ungroup()


data(stop_words) # stop_words de la librería de tidytext

# We can remove stop words (kept in the tidytext dataset stop_words) with an anti_join().
document_bigrama_stopwords <- document_bigrama %>% anti_join(stop_words)
document_bigrama_stopwords

# Para solucionar el error de los stopowords: 
# https://github.com/duttashi/text-analysis/issues/4
# https://github.com/r-spatial/sf/issues/412
# Both tidy_document and stop_words have a list of words listed under a column named word; however, the columns are inverted: in stop_words, it's the first column, while in your dataset it's the second column. That's why the command is unable to "match" the two columns and compare the words. Try this:

# Para que funcione tienen que ser anagramas, y no bigramas.
```

```{r}
document_bigrama_stopwords %>%
  count(word, sort = TRUE) 
```



```{r}
document_bigrama %>%
  # anti_join(stop_words)
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```


Estoy utilizando los enlaces:
https://www.tidytextmining.com/tidytext.html#word-frequencies
https://www.tidytextmining.com/ngrams.html#tokenizing-by-n-gram 

Y en menor medida:
https://uc-r.github.io/word_relationships#ngram 

```{r}

series %>%
        separate(document_bigrama, c("word1", "word2"), sep = " ") %>%
        filter(!word1 %in% stop_words$word,
               !word2 %in% stop_words$word) %>%
        count(word1, word2, sort = TRUE)
```

