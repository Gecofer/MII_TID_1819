---
title: "regresion"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
source("librerias.R")
```

```{r, include=FALSE}
# Lectura de los datos train preprocesados
datos_train_preprocesados <- read.csv(file="datos/datos_train_preprocesado.csv")

# Lectura de los datos test preprocesados
datos_test_preprocesados <- read.csv(file="datos/datos_test_preprocesado.csv")
```

# 5. Regresión

En este apartado se va hacer uso de la técnica de **regresión**, con el objetivo de describir dependencias significativas entre las variables incluidas en la base de datos. La regresión es un modelo de predicción de variables continuas, en donde las variables independientes tambien son continuas o al menos numéricas. Dicho proceso viene caracterizado por aprender una función que aplica un conjunto de atributos $X_1..X_n$ en otro atributo $Y$. En nuestro caso, vamos a hacer uso de las columnas:

- **ratingLabel**: etiqueta de 0 ó 1, que contempla la opinión del paciente sobre el medicamento si es favorable (1) o no es favorable (0).
- **effectivenessNumber**: clasificación de la efectividad del medicamento según el paciente (5 posibles valores), en donde el 1 significa que es ineficaz y el 5 que es altamente eficaz.
- **sideEffectsInverse**: clasificación de los efectos secundarios del medicamento según el paciente (5 posibles valores), en donde el 1 significa que teine efectos secundarios extremadamente graves y el 5 que es sin efectos secundarios.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{imagenes/regresion/1.png}
    \caption{Visualización de las columnas a las que aplica regresión}
    \label{1}
\end{figure}

Como se observa en la gráfica \ref{1}, se va hacer uso de variables discretas. El objetivo de aplicar regresión, es obtener la curva ROC, la matriz de confusión y el error en el conjunto test, para obtener así la precisión de nuestro modelo y saber según el paciente qué medicamentos favorables o no, tienen efectos secundarios o son efectivos. 

Como se ha comentado, se va hacer uso de la matriz de confusión, la cual es una herramienta que permite la visualización del desempeño de un algoritmo, en donde cada columna de la matriz representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real. Una de sus ventajas es que permite ver si la predicción falla o no. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{imagenes/regresion/2.png}
    \caption{Matriz de confusión para clasificador binario.}
    \label{2}
\end{figure}

De esta forma, se observa como en la figura \ref{2}, la diagonal principal contiene la suma de todas las predicciones correctas (el modelo dice “S” y acierta, tiene efectos secundarios, o dice “N” y acierta también, no tiene efectos secundarios). La otra diagonal refleja los errores del clasificador: los falsos positivos o “true positives” (dice que es tiene efectos secundarios “S”, pero en realidad no tiene “n”), o los falsos negativos o “false negatives” (dice que es no tiene efectos secundarios “N”, pero en realidad los tiene “p”). Además, otra de las medidas a usar, será la curva ROC, para caracterizar el comportamiento de la predicción.

Pero previo a la realización de las técnicas, se ha optado por eliminar los fármacos repetidos, para así obtener una predicción más acertada. Para dicha eliminación, se han cogido todos los medicamentos duplicados y eliminados los necesarios. Así que si tenemos 5 filas de un mismo medicamentos, se eliminan las 4 consecutivas al primero.

```{r, include=FALSE}
# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r

# Cogemos las columnas que queremos del train
datos_train2 <- datos_train_preprocesados[c(11,9,12)]

# Cogemos los farmacos
nombres_farmacos <- unique(datos_train_preprocesados[,1])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. 
# En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" 
# y "effectivenessNumber".
datos_procesados_train <- matrix(ncol=3, nrow=length(nombres_farmacos))

# Recorremos la lista de fármacos
for(i in 1:length(nombres_farmacos)) {
  
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_train2[which(datos_train_preprocesados$urlDrugName == nombres_farmacos[i]),]
  datos_farmaco = filas_farmaco[1,]
  datos_procesados_train[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_train_procesado <- data.frame(datos_procesados_train)
rownames(data_train_procesado) <- nombres_farmacos
colnames(data_train_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")
# A partir de ahora "data_train_procesado"
```

```{r, include=FALSE}
# https://stackoverflow.com/questions/40003028/extracting-unique-values-from-data-frame-using-r

# Cogemos las columnas que queremos del test
datos_test2 <- datos_test_preprocesados[c(11,9,12)]

# Cogemos los farmacos
nombres_farmacos <- unique(datos_test_preprocesados[,1])

# Creamos una matriz con tantas filas como fármacos, y columnas como datos queramos utilizar. 
# En este caso son 3 columnas porque necesitamos guardar la info de "rating", "sideEffectNumber" 
# y "effectivenessNumber".
datos_procesados_test <- matrix(ncol=3, nrow=length(nombres_farmacos))

# Recorremos la lista de fármacos
for(i in 1:length(nombres_farmacos)){
  
  # https://stackoverflow.com/questions/24831580/return-row-of-data-frame-based-on-value-in-a-column-r
  filas_farmaco <- datos_test2[which(datos_test_preprocesados$urlDrugName == nombres_farmacos[i]),]
  datos_farmaco = filas_farmaco[1,]
  datos_procesados_test[i,] <- c(datos_farmaco$ratingLabel, datos_farmaco$effectivenessNumber, datos_farmaco$sideEffectsInverse)
}

data_test_procesado <- data.frame(datos_procesados_test)
rownames(data_test_procesado) <- nombres_farmacos
colnames(data_test_procesado) <- c("ratingLabel", "effectivenessNumber", "sideEffectsInverse")
# A partir de ahora "data_test_procesado"
```

## 5.1. Regresión Lineal

La regresión lineal simple consiste en generar un modelo de regresión (ecuación de una recta) que permita explicar la relación lineal que existe entre dos variables. A la variable dependiente o respuesta se le identifica como $Y$ y a la variable predictora o independiente como $X$. Con el comando `lm()` podemos ajustar el modelo. Algunos parámetros importantes de esta función son:
 
`lm(formula, data, subset, weights)`

- _formula_: definimos el modelo como: $Y \sim X$.
    - Regresion Múltiple: $y \sim X_1+X_2+...X_n$.
    - Regresión Polinómica: $y \sim poly(x = X, degree = k)$
    - Interacción de variables: $y \sim X_1 \cdot X_2$. Si sólo queremos el término de interacción: $X1:X2$
- _data_ : especificamos el dataset a utilizar
- _subset_ : si dividimos la muestra en training y testing, podemos indicar el subconjunto de entrenamiento con un vector que indique sus números de fila.


### 5.1.1. Regresión Lineal Simple

Se pretende predecir el valor del rating (etiqueta 0-1) en función de la puntuación de los medicamentos y, por otro lado para los efectos secundarios del mismo. Para ello se va a emplear la función `lm()`, la cual genera un modelo de regresión lineal por mínimos cuadrados en el que la variable respuesta es ratingLabel y el predictor sideEffectsInverse, y por otro lado, la variable respuesta será ratingLabel y el predictor effectivenessNumber. 

El modelo de regresión lineal simple se describe de acuerdo a la siguiente ecuación:

$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$$

Siendo $\beta_0$ la ordenada en el origen, $\beta_1$ la pendiente y $\epsilon$ el error aleatorio. Este último representa la diferencia entre el valor ajustado por la recta y el valor real y recoge el efecto de todas aquellas variables que influyen en $Y$ pero que no se incluyen en el modelo como predictores. Al error aleatorio también se le conoce como residuo.

A continuación, se realiza una función con la cual obtener los errores dentro y fuera de la muestra, y la matriz de confusión. 

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_lineal <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  # Calculamos Etest y mostramos la matriz de confusión
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) 
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  # Devolvemos el eror para el conjunto train y test
  list(Etrain=Etrain*100, Etest=Etest*100)
}
```

Primero vamos a obtener un modelo en donde la variable respuesta es ratingLabel y el predictor sideEffectsInverse. Con el fin de obtener, que medicamentos favorables tienen efectos secundarios. Por lo que tendremos que hacer caso a la otra dioganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
lm_effects = lm(data = data_train_procesado, formula = ratingLabel ~ sideEffectsInverse)
summary(lm_effects)
# Evaluamos el modelo
errorres_regresion_lineal(lm_effects)
```

Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05). El valor de R^2 indica que el modelo calculado explica el 26.91% de la variabilidad presente en la variable respuesta (ratingLabel) mediante la variable independiente (sideEffectsInverse). Como se observa se obtiene que hay 11 falsos positivos, es decir, medicamentos que se dicen que tienen efectos secundarios pero no los tienen. Y existen 27 falsos negativos, es decir, medicamentos que se dicen que no tienen efectos secundarios pero que los tienen. Dichos resultados son los obtenidos según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

A continuación, vamos a crear el modelo para la variable respuesta ratingLabel y el predictor effectivenessNumber. Con el fin de obtener, que medicamentos favorables son efectivos. Por lo que tendremos que hacer caso a la otra dioganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
lm_effectiveness = lm(data = data_train_procesado, formula = ratingLabel ~ effectivenessNumber)
summary(lm_effectiveness)
# Evaluamos el modelo
errorres_regresion_lineal(lm_effectiveness)
```

Para el modelo generado, tanto la ordenada en el origen como la pendiente son significativas (p-values < 0.05). El valor de R^2 indica que el modelo calculado explica el 36.98% de la variabilidad presente en la variable respuesta (ratingLabel) mediante la variable independiente (effectivenessNumber). Como se observa se obtiene que hay 3 falsos positivos, es decir, medicamentos que se dicen que son efectivos pero que no lo son. Y existen 35 falsos negativos, es decir, medicamentos que se dicen que no son efectivos pero los son Dichos resultados, según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

Una vez que hemos obtenidos las prediciones para nuestro modelo, vamos a obtener las probabilidades para el mismo con el fin de obtener la curva ROC.

```{r}
# Función que dibuja una curva ROC
plotROC <- function(modelo, etiq_real, adicionar=FALSE,color="red") { 
  
  # Realizamos la predicción con la función de RORCR
  pred <- prediction(modelo, etiq_real)
  perf <- performance(pred,"tpr","fpr")
  plot(perf, col=color, add=adicionar, 
       main="Curva ROC - Regresión Lineal - Efectos secundarios", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
}
```

```{r, echo=FALSE}
# Obtenemos las probabilidades para effects
prob_LM_effects = predict(lm_effects, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_LM_effects, data_test_procesado$ratingLabel)

# Obtenemos las probabilidades para effectiveness
prob_LM_effectiveness = predict(lm_effectiveness, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_LM_effectiveness, data_test_procesado$ratingLabel)
```


#### 5.1.1.1. Casos atípicos

A continuación para el modelo lineal simple, vamos a obtener los casos atípicos, una forma rápida de identificarlos es usando la función `influencePlot()` del paquete `car`. Esta función produce un gráfico que señala a los casos atípicos influyentes. 

Una de las fuentes de violaciones de los supuestos en el modelado lineal es la presencia de casos atípicos. Un caso atípico es aquel que, dados ciertos valores de $x \sim 1$, $x \sim 2$, $x \sim n$ tiene valores de $y$ muy diferentes a los demás y por lo tanto producen un residuo muy alto. Estos casos atípicos pueden tener gran influencia sobre el modelo, ya que el criterio de mínimos cuadrados buscará minimizar el error y cambiará la pendiente para dar cuenta de estos casos.

Primero vamos a obtener los casos atípicos para el modelo de los efectos secundarios del medicamento.

```{r}
# Detección y visualización de observaciones influyentes para effects
influencePlot(lm_effects, xlab="Hat-Values", ylab="Studentized Residuals")
```

Para dicho modelo, los medicamentos _claritin_, _lipitor_, _ultram-er_, _metronidazole_, _toradol_ y _bactroban_ aparecen como casos atípicos. A continuación, vamos a obtener los casos atípicos para el modelo de la efectividad del medicamento.

```{r}
# Detección y visualización de observaciones influyentes para effectivenessNumber
influencePlot(lm_effectiveness, xlab="Hat-Values", ylab="Studentized Residuals")
```

Para dicho modelo, los medicamentos _propecia_, _claritin_, _depakote_, _anafranil_ y _fluvoxamine_ aparecen como casos atípicos.

#### 5.1.1.2. Regresión Robusta

Una alternativa para controlar los casos atípicos es ajustar un modelo lineal robusto. El modelo lineal robusto utiliza criterios diferentes al de los mínimos cuadrados y pondera la influencia de los casos atípicos, por lo que producen coeficientes y sobre todo errores estándar más confiables. El paquete `MASS` incluye la función `rlm()`, de sintaxis similar a `lm()` que implementa el método para el ajuste de los coeficientes y cálculo de los errores estándar.

Primero, calcularemos el modelo en donde la variable respuesta es ratingLabel y el predictor sideEffectsInverse. Con el fin de obtener, que medicamentos favorables tienen efectos secundarios. Por lo que tendremos que hacer caso a la otra dioganal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
rlm_effects = MASS::rlm(ratingLabel ~ sideEffectsInverse, data = data_train_procesado)
stargazer(lm_effects, rlm_effects, type = "text", model.numbers = FALSE, title="Comparación de modelo OLS y Robusto")
```

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
rlm_effectiveness = MASS::rlm(ratingLabel ~ effectivenessNumber, data = data_train_procesado)
stargazer(lm_effectiveness, rlm_effectiveness, type = "text", model.numbers = FALSE, title="Comparación de modelo OLS y Robusto")
```

El modelo robusto aumenta los coeficientes y reduce los errores estándar, aunque no en gran cuantía. En este caso interpretamos que los casos atípicos no son un problema grave.

### 5.1.2. Regresión Lineal Múltiple

Una vez que hemos la regresión lineal simple, vamos a intentar predecir el valor del ratingLabel en función de la puntuación de los medicamentos y de los efectos secundarios del mismo. Para ello se va a emplear la misma (`lm()`), la cual genera un modelo de regresión lineal por mínimos cuadrados en el que la variable respuesta es ratingLabel y los predictores son sideEffectsInverse y effectivenessNumber. Previamenete a la realización del modelo, vamos a comprobar que que las variables a usar pueden ser aplicadas juntas con la función `step()`, para así determinar la calidad del modelo.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber + sideEffectsInverse 
lm_multiple <- lm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)

# https://rpubs.com/Cristina_Gil/Regresion_Lineal_Multiple
# Nos dice si existe alguna variable que estamos usando que no nos hace falta
step(lm_multiple, direction = "both", trace = 1)

# Obtenemos el error d
errorres_regresion_lineal(lm_multiple)
```

Como se aprecia en salida de la función `step(lm_multiple, direction = "both", trace = 1)`, las dos variables deben ser incluidas en el proceso de selección. 

Por tanto, se observa se obtiene que hay 5 falsos positivos, es decir, medicamentos que se dicen que son favorables pero que no lo son. Y existen 24 falsos negativos, es decir, medicamentos que se dicen que no favorables pero los son. Se debe tener en cuenta que dichos resultados obtenidos han sido según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 9.265176, un buen error si tenemos en cuenta, los obtenidos con la regresión simple.


## 5.2. Regresión Logística

A continuación, vamos a ajustar un modelo con Regresión Logística binario sin regularización. De este modo vamos a comprobar, si se puede intentar encontrar un buen modelo lineal para nuestro problema. Además, discutiremos las necesidades de regularización, para ver si de esta forma conseguimos mejorarlo en cuanto a resultados. 

Para la obtención de la regresión, vamos hacer uso del comando `glm()`.

### 5.2.1. Regresión Logística Simple

La regresión logística simple, es un método de regresión que permite estimar la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. Una de las principales aplicaciones de la regresión logística es la de clasificación binaria, en el que las observaciones se clasifican en un grupo u otro dependiendo del valor que tome la variable empleada como predictor. Es decir para predecir la probabilidad de pertenencia o no a una determinada clase (efectividad - no efectividad).

Para ello, vamos a utilizar la función `glm(..)` que en base al conjunto de muestras de entrenamiento suministrado, es capaz de calcular una probabilidad para cada dato. Si esta probabilidad sobrepasa el valor 0.5, entonces consideramos que dicha muestra pertence a la clase 1, sin embargo, si su probabilidad es menor que 0.5, entonces consideramos que se encuentra en la clase con etiqueta 0. Una vez tengamos las etiquetas predichas a partir de las probabilidades que calcula el modelo, vamos a calcular el error dentro de la muestra y el error fuera de la muestra. Para ello, vamos a especificar como primer argumento, la variable respuesta denominada ratingLabel y a continuación, la variable en la que nos vamos a fijar para ajustar el modelo. 

```{r}
# Función que calcula los errores y E_test para regresión logística
errorres_regresion_logistica <- function(m){ 
  probTr = predict(m, type="response")
  probTst = predict(m, data.frame(data_test_procesado), type="response") 
  
  predTst = rep(0, length(probTst)) # predicciones por defecto 0
  predTst[probTst >= 0.5] = 1 # >= 0.5 clase 1

  predTr = rep(0, length(probTr)) # predicciones por defecto 0
  predTr[probTr >= 0.5] = 1 # >= 0.5 clase 1 # Para el calculo del Etest
  
  print(table(pred=predTst, real=data_test_procesado$ratingLabel)) # Calculamos Etest
  
  Etrain = mean(predTr != data_train_procesado$ratingLabel) 
  Etest = mean(predTst != data_test_procesado$ratingLabel) 
  
  list(Etrain=Etrain*100, Etest=Etest*100)
}
```

Primero vamos a obtener el modelo, que predice la variable sideEffectsInverse a partir del ratingLabel.

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse
gml_effects = glm(ratingLabel ~ sideEffectsInverse, family = binomial(logit), data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(gml_effects)
```

Como se observa se obtiene que hay 11 falsos positivos, es decir, medicamentos que se dicen que tienen efectos secundarios pero no los tienen. Y existen 27 falsos negativos, es decir, medicamentos que se dicen que no tienen efectos secundarios pero que los tienen. Dichos resultados son los obtenidos según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero se ha comprobado, que se obtiene un mejor error con la regresión lineal múltiple.

A continuación, vamos a crear el modelo para la variable respuesta ratingLabel y el predictor effectivenessNumber. Con el fin de obtener, que medicamentos favorables son efectivos. Por lo que tendremos que hacer caso a la otra diagonal de la matriz de confusión.

```{r}
# Creamos el modelo para ratingLabel ~ effectivenessNumber
gml_effectiveness = glm(ratingLabel ~ effectivenessNumber, family = binomial(logit), data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(gml_effectiveness)
```

Como se observa se obtiene que hay 3 falsos positivos, es decir, medicamentos que se dicen que son efectivos pero que no lo son. Y existen 35 falsos negativos, es decir, medicamentos que se dicen que no son efectivos pero los son Dichos resultados, según los comentarios de los pacientes. Como podemos apreciar, el error del test nos devuelve un valor de 12.14058, un error aceptable teniendo en cuenta los resultados obtenidos en la matriz de confusión. Pero posiblemente dicho error se pueda reducir aplicando sobre los datos otros modelos que veremos más adelante.

Una vez que hemos obtenidos las prediciones para nuestro modelo, vamos a obtener las probabilidades para el mismo con el fin de obtener la curva ROC.
```{r, echo=FALSE}
# Obtenemos las probabilidades para effects
prob_GLM_effects = predict(gml_effects, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo logística
plotROC(prob_GLM_effects, data_test_procesado$ratingLabel)
```

```{r, echo=FALSE}
# Obtenemos las probabilidades para effectiveness
prob_GLM_effectiveness = predict(gml_effectiveness, data.frame(data_test_procesado), type=c("response"))
# Cruva ROC para el modelo lineal
plotROC(prob_GLM_effectiveness, data_test_procesado$ratingLabel)
```

### 5.2.2. Regresión Logística Multiple

Una vez que hemos la regresión logística simple, vamos a intentar predecir el valor del ratingLabel en función de la puntuación de los medicamentos y de los efectos secundarios del mismo. Para ello se va a emplear la misma (`glm()`).

```{r}
# Creamos el modelo para ratingLabel ~ sideEffectsInverse + effectivenessNumber
modelo_glm_multiple <- glm(ratingLabel ~ sideEffectsInverse + effectivenessNumber, data = data_train_procesado)
# Evaluamos el modelo
errorres_regresion_logistica(modelo_glm_multiple)
```


### 5.2.3. Regularización en Regresión Logística

En este apartado vamos a ajustar un modelo a través de la regresión logística con regularización meidante la técnica Lasso Regression.

#### 5.2.3.1. Rigde Regression

Esta ténica, en esencia, es la regresión lineal con Weight Decay que utilizamos en la Práctica 2, y cuya fórmula es: $(XTX + lambdaI)-1 *XˆT$. Es el parámetro lambda, el que en función de su valor, marca el equilibrio entre los componentes de sesgo y varianza. Cuanto mayor sea su valor, mayor sesgo pero menor varianza. Es decir, cuanto mayor valor tenga lambda, mayor penalización y mayor reducción se les aplica a los valores de los coeficientes.


#### 5.2.3.2. Lasso Regression

Esta técnica, además de realizar la misma tarea que la anterior, pero con una fórmula distinta para aplicar la penalización. Aún así, también utiliza el parámetro lambda para concretar el equilibrio entre sesgo y varianza. Además, también es capaz de realizar una selección de variables, anulando algunos coeficientes. Por lo que además de la reducción de los valores de estos coeficientes también reduce el número de estos necesarios para ajustar el modelo.

Por tanto, para aplicar la regularización, primero debemos averiguar el valor de alpha, que representa la técnica a utilizar. Si alpha=0 entonces la regularización se aplica con la técnica Ridge Regression. Si por el contrario alpha=1, entonces la técnica a utilizar será Lasso Regression. Una vez sabemos qué técnica aplicar a través del valor de alpha, tendremos que concretar el valor de lambda, para
que dicha técnica pueda ajustar el modelo con su respectiva penalización.

Para ello, vamos a usar la función `train(..)` que es capaz de probar distintos valores para alpha y lambda a través del ajuste de varios modelos, de modo que devuelve el mejor valor de lambda y el mejor valor de alpha. Para ello, como primer argumento debemos indicarle los valores de las etiquetas, que se corresponden con los valores de la variable explicativa. A continuación, vamos a darle la oportunidad de explorar con las columnas sideEffectsInverse + effectivenessNumber. Como segundo argumento le proporcionamos el conjunto de entrenamiento. El tercer argumento especifica el tipo de técnica a utilizar para explorar todos los modelos posibles. Con `glmnet`(), le concretamos que
queremos que ajuste dichos modelos a través de la Lasso Regression y de Ridge Regression. Y por último, como cuarto argumento le especificamos la clase de funciones que debe utilizar para ajustar un modelo a través de regresión logística.

```{r}
library(glmnet)
# Ajustamos un modelo a través de Regresión Logística multiclase
modelbest = train(form=as.factor(ratingLabel) ~ sideEffectsInverse + effectivenessNumber, 
                  data=data_train_procesado, method="glmnet", family="binomial")

modelbest$bestTune$alpha
modelbest$bestTune$lambda
```

Como se puede observar, la función nos dice que el mejor modelo que podemos ajustar para nuestro conjunto de entrenamiento, es el que tiene el valor de alpha 0.1. Con este valor tan cercano a 0 podemos intuir que la técnica que va a emplear es Ridge Regression, ya que esta se representa a través de alpha = 0.

En cuanto al valor de lambda, podemos comprobar que es bastante próximo a 0, y que por tanto, la penalización que va a aplicar Ridge Regression no es demasiado agresiva. Por lo que podemos intuir que el modelo ajustado tendrá un cierto grado de flexibilidad en referencia a las muestras mal clasificadas. También indica, que el modelo que va a ajustar, por el valor pequeño de lambda, se puede caracterizar por un
bajo sesgo pero una alta varianza. Lo que puede desembocar en un modelo sobreajustado a los datos de entrenamiento, con una capacidad de generalización bastante escasa.

Para ajustar este modelo hemos utilizado la función `glmnet(..)`. Como primer argumento especificamos una matriz con las muestras de entrenamiento pero sin sus etiquetas, las cuales se le proporcionan a la función en el segundo argumento. Como tercer argumento le volvemos a indicar la familia de funciones que debe utilizar para que sea un modelo ajustado a partir de regresión logística. Los dos siguientes parámetros se corresponden con el mejor alpha y el mejor lambda que hemos obtenido en el proceso anterior.

```{r}
# Conjunto Train

# Primero generamos una matriz con el conjunto de train separando las etiquetas de los datos
x = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, data_train_procesado)[,-ncol(data_train_procesado)]
y = data_train_procesado$ratingLabel

# Conjunto Test
x.test = model.matrix(ratingLabel~sideEffectsInverse + effectivenessNumber, data_test_procesado)[,-ncol(data_test_procesado)]
y.test = data_test_procesado$ratingLabel

# Reproducimos el modelo ajustado con el mejor lambda y el mejor alpha
ridge.mod = glmnet(x=x, y=y, family="binomial", alpha=modelbest$bestTune$alpha,lambda=modelbest$bestTune$lambda,thresh=1e-12)

# Calculamos la predicción
predicciones.ridge = predict(ridge.mod, s=ridge.mod$lambda, newx=x.test, type="response")

# Error de regresión con penalización Ridge
error.ridge = mean (( predicciones.ridge - y.test)^2)
cat("Error con la técnica Ridge Regression: ",error.ridge*100,"%\n")
```

Como se observa, se obtiene un error similar a los anteriores.

## 5.3. Regresión Polinomial

En algunos casos, la verdadera relación entre la variable respuesta y los predictores puede no ser lineal, por lo que podemos aplicar por ejemplo una regresión polinomial. Una forma simple de incorporar asociaciones no lineales en un modelo lineal es incluir versiones transformadas de los predictores, elevándolos a distintas potencias, evitando un exceso de grados para evitar el sobreajuste o overfitting.

La forma más sencilla de incorporar flexibilidad a un modelo lineal es introduciendo nuevos predictores obtenidos al elevar a distintas potencias el predictor original.

Partiendo del modelo lineal: $Y_i = \beta_0 + \beta_1 X_i + \epsilon$

Se obtiene un modelo polinómico de grado d a partir de la ecuación:

$$Y_i = \beta_0 + \beta_1 x_i + \beta_2 x^2_i + \beta_3 x^3_i + ... + \beta_d x^d_i + \epsilon_i$$

```{r}
# Hacemos uso del poly para 2
lm_poly = lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2) + effectivenessNumber)
summary(lm_poly)
errorres_regresion_lineal(lm_poly)
```

Los p-values individuales de sideEffectsInverse, apuntan a que un polinomio de grado 2 es suficiente para modelar el ratingLabel en función de sideEffectsInverse.

```{r}
# Calculo del polinomio de grado 2
modelo_poli2 <- lm(data = data_train_procesado, formula = ratingLabel ~ poly(sideEffectsInverse, 2))
summary(modelo_poli2)

# Interpolacion de puntos dentro del rango predictos
limites <- range(data_train_procesado$sideEffectsInverse)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos <- data.frame(sideEffectsInverse = nuevos_puntos)

# Predicción de la variable respuesta y del error estándar
predicciones <- predict(modelo_poli2, newdata = nuevos_puntos, se.fit = TRUE,
                        level = 0.95)

# Cálculo del intervalo de confianza superior e inferior 95%
intervalo_conf <- data.frame(inferior = predicciones$fit -
                                        1.96*predicciones$se.fit,
                             superior = predicciones$fit +
                                        1.96*predicciones$se.fit)

attach(data_train_procesado)
plot(x = sideEffectsInverse, y = ratingLabel, pch = 20, col = "darkgrey")
title("Polinomio de grado 2: ratingLabel ~ sideEffectsInverse")
lines(x = nuevos_puntos$sideEffectsInverse, predicciones$fit, col = "red", pch = 20)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$inferior, col = "blue", pch = 4)
lines(x = nuevos_puntos$sideEffectsInverse, intervalo_conf$superior, col = "blue", pch = 4)
```

## 5.4. Conclusiones